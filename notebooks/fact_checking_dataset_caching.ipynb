{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load calinet probing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/calinet_probing_data_original/probing_data_trex_500each.json', 'r') as f:\n",
    "    data_calinet = json.load(f)\n",
    "    starter_df = pd.DataFrame(list(data_calinet['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fact_id</th>\n",
       "      <th>relation</th>\n",
       "      <th>triplet</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>P47</td>\n",
       "      <td>{'sub_label': 'Norfolk', 'obj_label': 'Suffolk'}</td>\n",
       "      <td>[[Norfolk shares border with &lt;extra_id_0&gt;., &lt;e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>P47</td>\n",
       "      <td>{'sub_label': 'Jordan', 'obj_label': 'Israel'}</td>\n",
       "      <td>[[&lt;extra_id_0&gt; shares border with Israel., &lt;ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>P47</td>\n",
       "      <td>{'sub_label': 'Kenya', 'obj_label': 'Ethiopia'}</td>\n",
       "      <td>[[Kenya shares border with &lt;extra_id_0&gt;., &lt;ext...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>P47</td>\n",
       "      <td>{'sub_label': 'Egypt', 'obj_label': 'Israel'}</td>\n",
       "      <td>[[&lt;extra_id_0&gt; shares border with Israel., &lt;ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>P47</td>\n",
       "      <td>{'sub_label': 'Tanzania', 'obj_label': 'Uganda'}</td>\n",
       "      <td>[[Tanzania shares border with &lt;extra_id_0&gt;., &lt;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fact_id relation                                           triplet  \\\n",
       "0        1      P47  {'sub_label': 'Norfolk', 'obj_label': 'Suffolk'}   \n",
       "1        2      P47    {'sub_label': 'Jordan', 'obj_label': 'Israel'}   \n",
       "2        3      P47   {'sub_label': 'Kenya', 'obj_label': 'Ethiopia'}   \n",
       "3        4      P47     {'sub_label': 'Egypt', 'obj_label': 'Israel'}   \n",
       "4        5      P47  {'sub_label': 'Tanzania', 'obj_label': 'Uganda'}   \n",
       "\n",
       "                                           sentences  \n",
       "0  [[Norfolk shares border with <extra_id_0>., <e...  \n",
       "1  [[<extra_id_0> shares border with Israel., <ex...  \n",
       "2  [[Kenya shares border with <extra_id_0>., <ext...  \n",
       "3  [[<extra_id_0> shares border with Israel., <ex...  \n",
       "4  [[Tanzania shares border with <extra_id_0>., <...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# starter df\n",
    "starter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Norfolk shares border with <extra_id_0>.',\n",
       " '<extra_id_0> Suffolk <extra_id_1>',\n",
       " '<extra_id_0> Upper Macungie Township <extra_id_1>']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all of these have to do with fact id 1\n",
    "# the sentences are formed in this format...\n",
    "# the start of a factual sentence, involving the subject\n",
    "# and then two possibilities: one true and one false?\n",
    "# storing these, then, we should do something like\n",
    "# sentence stem | correct | incorrect\n",
    "# and we can strip out the <extra_id_x> parts\n",
    "# to keep it model agnostic\n",
    "starter_df['sentences'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create containers to hold our clean data\n",
    "sentence_stems = []\n",
    "correct = []\n",
    "incorrect = []\n",
    "fact_ids = []\n",
    "relations = []\n",
    "subjects = []\n",
    "objects = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in starter_df.iterrows():\n",
    "    sentence_list = row['sentences']\n",
    "    for entry in sentence_list:\n",
    "        \n",
    "        # minor cleanup \n",
    "        cleaned_stem = entry[0].replace(\"<extra_id_0>\", \"[BLANK]\").strip()\n",
    "        cleaned_correct = entry[1].replace(\"<extra_id_0>\", \"\").replace(\"<extra_id_1>\", \"\").strip()\n",
    "        cleaned_incorrect = entry[2].replace(\"<extra_id_0>\", \"\").replace(\"<extra_id_1>\", \"\").strip()\n",
    "        \n",
    "        # grab sub<->obj\n",
    "        subjects_and_objects = pd.json_normalize(row['triplet'])\n",
    "        subjects.append(subjects_and_objects.sub_label.values[0])\n",
    "        objects.append(subjects_and_objects.obj_label.values[0])\n",
    "        \n",
    "        # commit \n",
    "        sentence_stems.append(cleaned_stem)\n",
    "        correct.append(cleaned_correct)\n",
    "        incorrect.append(cleaned_incorrect)\n",
    "        fact_ids.append(row['fact_id'])\n",
    "        relations.append(row['relation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "assert(len(sentence_stems) ==\n",
    "       len(correct) ==\n",
    "       len(incorrect) ==\n",
    "       len(fact_ids) ==\n",
    "       len(relations) ==\n",
    "      len(subjects) ==\n",
    "      len(objects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge into big df\n",
    "trex_df = pd.DataFrame({'fact_id': fact_ids,\n",
    "                        'relation': relations, 'subject': subjects,\n",
    "                        'object': objects, 'stem': sentence_stems, 'true': correct,\n",
    "                        'false': incorrect})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fact_id</th>\n",
       "      <th>relation</th>\n",
       "      <th>subject</th>\n",
       "      <th>object</th>\n",
       "      <th>stem</th>\n",
       "      <th>true</th>\n",
       "      <th>false</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>P47</td>\n",
       "      <td>Norfolk</td>\n",
       "      <td>Suffolk</td>\n",
       "      <td>Norfolk shares border with [BLANK].</td>\n",
       "      <td>Suffolk</td>\n",
       "      <td>Upper Macungie Township</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>P47</td>\n",
       "      <td>Norfolk</td>\n",
       "      <td>Suffolk</td>\n",
       "      <td>Norfolk borders with [BLANK].</td>\n",
       "      <td>Suffolk</td>\n",
       "      <td>Vadena</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>P47</td>\n",
       "      <td>Norfolk</td>\n",
       "      <td>Suffolk</td>\n",
       "      <td>[BLANK] shares the border with Suffolk.</td>\n",
       "      <td>Norfolk</td>\n",
       "      <td>Northern Cape province</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>P47</td>\n",
       "      <td>Norfolk</td>\n",
       "      <td>Suffolk</td>\n",
       "      <td>[BLANK] shares its border with Suffolk.</td>\n",
       "      <td>Norfolk</td>\n",
       "      <td>Sunamganj District</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>P47</td>\n",
       "      <td>Norfolk</td>\n",
       "      <td>Suffolk</td>\n",
       "      <td>Norfolk shares a common border with [BLANK].</td>\n",
       "      <td>Suffolk</td>\n",
       "      <td>Anabar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fact_id relation  subject   object  \\\n",
       "0        1      P47  Norfolk  Suffolk   \n",
       "1        1      P47  Norfolk  Suffolk   \n",
       "2        1      P47  Norfolk  Suffolk   \n",
       "3        1      P47  Norfolk  Suffolk   \n",
       "4        1      P47  Norfolk  Suffolk   \n",
       "\n",
       "                                           stem     true  \\\n",
       "0           Norfolk shares border with [BLANK].  Suffolk   \n",
       "1                 Norfolk borders with [BLANK].  Suffolk   \n",
       "2       [BLANK] shares the border with Suffolk.  Norfolk   \n",
       "3       [BLANK] shares its border with Suffolk.  Norfolk   \n",
       "4  Norfolk shares a common border with [BLANK].  Suffolk   \n",
       "\n",
       "                     false  \n",
       "0  Upper Macungie Township  \n",
       "1                   Vadena  \n",
       "2   Northern Cape province  \n",
       "3       Sunamganj District  \n",
       "4                   Anabar  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full df\n",
    "trex_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fact_id</th>\n",
       "      <th>relation</th>\n",
       "      <th>subject</th>\n",
       "      <th>object</th>\n",
       "      <th>stem</th>\n",
       "      <th>true</th>\n",
       "      <th>false</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142995</th>\n",
       "      <td>13000</td>\n",
       "      <td>P264</td>\n",
       "      <td>X&amp;Y</td>\n",
       "      <td>Parlophone</td>\n",
       "      <td>[BLANK] label : Parlophone.</td>\n",
       "      <td>X&amp;Y</td>\n",
       "      <td>Junior Hanson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142996</th>\n",
       "      <td>13000</td>\n",
       "      <td>P264</td>\n",
       "      <td>X&amp;Y</td>\n",
       "      <td>Parlophone</td>\n",
       "      <td>[BLANK], released by Parlophone.</td>\n",
       "      <td>X&amp;Y</td>\n",
       "      <td>Doo-Wops &amp; Hooligans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142997</th>\n",
       "      <td>13000</td>\n",
       "      <td>P264</td>\n",
       "      <td>X&amp;Y</td>\n",
       "      <td>Parlophone</td>\n",
       "      <td>Parlophone recording artist [BLANK].</td>\n",
       "      <td>X&amp;Y</td>\n",
       "      <td>Atlas Genius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142998</th>\n",
       "      <td>13000</td>\n",
       "      <td>P264</td>\n",
       "      <td>X&amp;Y</td>\n",
       "      <td>Parlophone</td>\n",
       "      <td>Parlophone artists such as [BLANK].</td>\n",
       "      <td>X&amp;Y</td>\n",
       "      <td>untitled 2008 album</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142999</th>\n",
       "      <td>13000</td>\n",
       "      <td>P264</td>\n",
       "      <td>X&amp;Y</td>\n",
       "      <td>Parlophone</td>\n",
       "      <td>[BLANK] artists including X&amp;Y.</td>\n",
       "      <td>Parlophone</td>\n",
       "      <td>ATCO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fact_id relation subject      object  \\\n",
       "142995    13000     P264     X&Y  Parlophone   \n",
       "142996    13000     P264     X&Y  Parlophone   \n",
       "142997    13000     P264     X&Y  Parlophone   \n",
       "142998    13000     P264     X&Y  Parlophone   \n",
       "142999    13000     P264     X&Y  Parlophone   \n",
       "\n",
       "                                        stem        true                 false  \n",
       "142995           [BLANK] label : Parlophone.         X&Y         Junior Hanson  \n",
       "142996      [BLANK], released by Parlophone.         X&Y  Doo-Wops & Hooligans  \n",
       "142997  Parlophone recording artist [BLANK].         X&Y          Atlas Genius  \n",
       "142998   Parlophone artists such as [BLANK].         X&Y   untitled 2008 album  \n",
       "142999        [BLANK] artists including X&Y.  Parlophone                  ATCO  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trex_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143000, 7)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trex_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in trex_df is 143000\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of rows in trex_df is {trex_df.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out initial df to json if desired\n",
    "# trex_df.to_json('../data/calinet_probing_data_original/calinet_trex_full_data.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50451\n"
     ]
    }
   ],
   "source": [
    "# how many stems end in [BLANK]? -> 50451, or about 1/3.\n",
    "c = 0\n",
    "for stem in trex_df['stem']:\n",
    "    if stem.endswith(\"[BLANK].\"):\n",
    "        c+=1\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_causal_compatibility(stem):\n",
    "    return stem.endswith(\"[BLANK].\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_stem(stem):\n",
    "    if stem.endswith(\"[BLANK].\"):\n",
    "        return stem[0: len(stem)-9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trex_causal_df = trex_df[trex_df.apply(lambda x: check_for_causal_compatibility(x.stem), axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trex_causal_df = trex_causal_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_stems = trex_causal_df.apply(lambda x: trim_stem(x.stem), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trex_causal_df['stem'] = list(trimmed_stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11960"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only about 20% of the calinet data is 'unique' knowledge, since they used paraphrases to calibrate\n",
    "len(trex_causal_df['fact_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before sampling, attach arbitrary counter ID, to then track who gets removed\n",
    "trex_causal_df['calibra_id'] = range(50451)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trex_causal_subset = trex_causal_df.groupby('fact_id').apply(lambda x: x.sample(1, random_state=42)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(trex_causal_subset.shape[0] == len(trex_causal_df['fact_id'].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fact_id</th>\n",
       "      <th>relation</th>\n",
       "      <th>subject</th>\n",
       "      <th>object</th>\n",
       "      <th>stem</th>\n",
       "      <th>true</th>\n",
       "      <th>false</th>\n",
       "      <th>calibra_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>P47</td>\n",
       "      <td>Norfolk</td>\n",
       "      <td>Suffolk</td>\n",
       "      <td>Norfolk borders with</td>\n",
       "      <td>Suffolk</td>\n",
       "      <td>Vadena</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>P47</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>Israel</td>\n",
       "      <td>Jordan shares a common border with</td>\n",
       "      <td>Israel</td>\n",
       "      <td>Simbach</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>P47</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>Kenya shares border with</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>Yixing</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>P47</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>Israel</td>\n",
       "      <td>Egypt shares its border with</td>\n",
       "      <td>Israel</td>\n",
       "      <td>Montréal, Quebec</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>P47</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Uganda</td>\n",
       "      <td>Tanzania borders with</td>\n",
       "      <td>Uganda</td>\n",
       "      <td>La Pampa</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fact_id relation   subject    object                                stem  \\\n",
       "0        1      P47   Norfolk   Suffolk                Norfolk borders with   \n",
       "1        2      P47    Jordan    Israel  Jordan shares a common border with   \n",
       "2        3      P47     Kenya  Ethiopia            Kenya shares border with   \n",
       "3        4      P47     Egypt    Israel        Egypt shares its border with   \n",
       "4        5      P47  Tanzania    Uganda               Tanzania borders with   \n",
       "\n",
       "       true             false  calibra_id  \n",
       "0   Suffolk            Vadena           1  \n",
       "1    Israel           Simbach           6  \n",
       "2  Ethiopia            Yixing           7  \n",
       "3    Israel  Montréal, Quebec          14  \n",
       "4    Uganda          La Pampa          19  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trex_causal_subset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fact_id</th>\n",
       "      <th>relation</th>\n",
       "      <th>subject</th>\n",
       "      <th>object</th>\n",
       "      <th>stem</th>\n",
       "      <th>true</th>\n",
       "      <th>false</th>\n",
       "      <th>calibra_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11955</th>\n",
       "      <td>12996</td>\n",
       "      <td>P264</td>\n",
       "      <td>Cody Wise</td>\n",
       "      <td>Interscope Records</td>\n",
       "      <td>The music label that is representing Cody Wise is</td>\n",
       "      <td>Interscope Records</td>\n",
       "      <td>Heads Up International</td>\n",
       "      <td>50411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11956</th>\n",
       "      <td>12997</td>\n",
       "      <td>P264</td>\n",
       "      <td>Amy Ray</td>\n",
       "      <td>Daemon Records</td>\n",
       "      <td>Daemon Records artists such as</td>\n",
       "      <td>Amy Ray</td>\n",
       "      <td>Hello Rockview</td>\n",
       "      <td>50426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11957</th>\n",
       "      <td>12998</td>\n",
       "      <td>P264</td>\n",
       "      <td>Martin Sorrondeguy</td>\n",
       "      <td>Lengua Armada Discos</td>\n",
       "      <td>Martin Sorrondeguy, which is represented by</td>\n",
       "      <td>Lengua Armada Discos</td>\n",
       "      <td>Modern Day Escape</td>\n",
       "      <td>50428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11958</th>\n",
       "      <td>12999</td>\n",
       "      <td>P264</td>\n",
       "      <td>Madlib</td>\n",
       "      <td>Stones Throw</td>\n",
       "      <td>Stones Throw artists such as</td>\n",
       "      <td>Madlib</td>\n",
       "      <td>Bix Beiderbecke</td>\n",
       "      <td>50441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11959</th>\n",
       "      <td>13000</td>\n",
       "      <td>P264</td>\n",
       "      <td>X&amp;Y</td>\n",
       "      <td>Parlophone</td>\n",
       "      <td>X&amp;Y's label is</td>\n",
       "      <td>Parlophone</td>\n",
       "      <td>Re-Constriction Records</td>\n",
       "      <td>50444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fact_id relation             subject                object  \\\n",
       "11955    12996     P264           Cody Wise    Interscope Records   \n",
       "11956    12997     P264             Amy Ray        Daemon Records   \n",
       "11957    12998     P264  Martin Sorrondeguy  Lengua Armada Discos   \n",
       "11958    12999     P264              Madlib          Stones Throw   \n",
       "11959    13000     P264                 X&Y            Parlophone   \n",
       "\n",
       "                                                    stem  \\\n",
       "11955  The music label that is representing Cody Wise is   \n",
       "11956                     Daemon Records artists such as   \n",
       "11957        Martin Sorrondeguy, which is represented by   \n",
       "11958                       Stones Throw artists such as   \n",
       "11959                                     X&Y's label is   \n",
       "\n",
       "                       true                    false  calibra_id  \n",
       "11955    Interscope Records   Heads Up International       50411  \n",
       "11956               Amy Ray           Hello Rockview       50426  \n",
       "11957  Lengua Armada Discos        Modern Day Escape       50428  \n",
       "11958                Madlib          Bix Beiderbecke       50441  \n",
       "11959            Parlophone  Re-Constriction Records       50444  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trex_causal_subset.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_ids = {}\n",
    "removed_counterfacts = {}\n",
    "for c_id in trex_causal_df['calibra_id']:\n",
    "    if c_id not in trex_causal_subset['calibra_id'].values:\n",
    "        fact_id = trex_causal_df[trex_causal_df['calibra_id'] == c_id]['fact_id'].values[0]\n",
    "        counterfact = trex_causal_df[trex_causal_df['calibra_id'] == c_id]['false'].values[0]\n",
    "        removed_ids[str(c_id)] = int(fact_id)\n",
    "        if str(fact_id) in removed_counterfacts:\n",
    "            removed_counterfacts[str(fact_id)].append(counterfact)\n",
    "        else:\n",
    "            removed_counterfacts[str(fact_id)] = [counterfact]\n",
    "\n",
    "# did we remove as many rows as eq to the difference between the full calinet dataset row number and the unique count?\n",
    "assert(len(removed_ids) == trex_causal_df.shape[0] - len(trex_causal_df['fact_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['Upper Macungie Township', 'Anabar', 'Riau', 'Bologna']\n",
      "2 ['Mpumalanga']\n",
      "3 ['James City County, Virginia', 'Portneuf', 'Rockingham County, Virginia', 'Giridih', 'Canazei']\n",
      "4 ['Sestriere', 'Nitra District', 'Acerra', 'Le Havre']\n",
      "5 ['Ukrainians', 'First Czechoslovak Republic', 'Ziburu']\n",
      "6 ['Oliver, British Columbia', 'Kapurthala', 'ASEAN']\n",
      "7 ['Vinnytsia Oblast', 'Laveno-Mombello', 'Orbassano', 'Arnhem', 'Santa Cristina Gela']\n",
      "8 ['North America', 'Mogilev Region', 'New Zealand/Aotearoa', 'Phasi Charoen']\n",
      "9 ['Castile La Mancha', 'Chikballapur district', 'Brewster County']\n",
      "10 ['Chaumont-Gistoux', 'Magadan Oblast']\n",
      "11 ['Bulakan', 'East Flanders', 'Arenys de Munt']\n",
      "12 ['First Czechoslovak Republic', 'South West Africa', 'Churchill, Manitoba']\n",
      "13 ['Oak Park', 'Rabun County', 'Rio de Janeiro (RJ)', 'Lower Hutt']\n",
      "14 ['Liberty Village', 'Civitacampomarano', 'Sorano']\n",
      "15 ['Western region', 'Sheridan Hollow']\n"
     ]
    }
   ],
   "source": [
    "# these are essentially the extra false things we can test against\n",
    "# that are still worth keeping\n",
    "c = 0\n",
    "for k, v in removed_counterfacts.items():\n",
    "    print(k, v)\n",
    "    c+=1\n",
    "    if c == 15:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop extraneous calibra_id column \n",
    "trex_causal_subset.drop(['calibra_id'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11960, 7)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there are some fact_id's that only have 1 row\n",
    "# since we did pull stuff out based on our left to right requirement\n",
    "trex_causal_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10563"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(removed_counterfacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10563\n"
     ]
    }
   ],
   "source": [
    "full_falses = {}\n",
    "for k, v in removed_counterfacts.items():\n",
    "    subset_false = trex_causal_subset[trex_causal_subset['fact_id'] == int(k)].false.values[0]\n",
    "    full_falses[k] = v\n",
    "    full_falses[k].append(subset_false)\n",
    "\n",
    "print(len(full_falses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['Upper Macungie Township', 'Anabar', 'Riau', 'Bologna', 'Vadena']\n"
     ]
    }
   ],
   "source": [
    "for k, v in full_falses.items():\n",
    "    print(k,v)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_false_column(fact_id, false_val, full_false_dict=full_falses):\n",
    "    if str(fact_id) in full_false_dict:\n",
    "        return full_false_dict[str(fact_id)]\n",
    "    else:\n",
    "        return [false_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaced_falses = list(trex_causal_subset.apply(lambda x: replace_false_column(x.fact_id, x.false), axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11960"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(replaced_falses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Upper Macungie Township', 'Anabar', 'Riau', 'Bologna', 'Vadena'],\n",
       " ['Mpumalanga', 'Simbach'],\n",
       " ['James City County, Virginia',\n",
       "  'Portneuf',\n",
       "  'Rockingham County, Virginia',\n",
       "  'Giridih',\n",
       "  'Canazei',\n",
       "  'Yixing'],\n",
       " ['Sestriere', 'Nitra District', 'Acerra', 'Le Havre', 'Montréal, Quebec'],\n",
       " ['Ukrainians', 'First Czechoslovak Republic', 'Ziburu', 'La Pampa'],\n",
       " ['Oliver, British Columbia', 'Kapurthala', 'ASEAN', 'Kodanad']]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replaced_falses[:6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "trex_causal_subset['false'] = replaced_falses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fact_id</th>\n",
       "      <th>relation</th>\n",
       "      <th>subject</th>\n",
       "      <th>object</th>\n",
       "      <th>stem</th>\n",
       "      <th>true</th>\n",
       "      <th>false</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>P47</td>\n",
       "      <td>Norfolk</td>\n",
       "      <td>Suffolk</td>\n",
       "      <td>Norfolk borders with</td>\n",
       "      <td>Suffolk</td>\n",
       "      <td>[Upper Macungie Township, Anabar, Riau, Bologn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>P47</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>Israel</td>\n",
       "      <td>Jordan shares a common border with</td>\n",
       "      <td>Israel</td>\n",
       "      <td>[Mpumalanga, Simbach]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>P47</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>Kenya shares border with</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>[James City County, Virginia, Portneuf, Rockin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>P47</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>Israel</td>\n",
       "      <td>Egypt shares its border with</td>\n",
       "      <td>Israel</td>\n",
       "      <td>[Sestriere, Nitra District, Acerra, Le Havre, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>P47</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Uganda</td>\n",
       "      <td>Tanzania borders with</td>\n",
       "      <td>Uganda</td>\n",
       "      <td>[Ukrainians, First Czechoslovak Republic, Zibu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fact_id relation   subject    object                                stem  \\\n",
       "0        1      P47   Norfolk   Suffolk                Norfolk borders with   \n",
       "1        2      P47    Jordan    Israel  Jordan shares a common border with   \n",
       "2        3      P47     Kenya  Ethiopia            Kenya shares border with   \n",
       "3        4      P47     Egypt    Israel        Egypt shares its border with   \n",
       "4        5      P47  Tanzania    Uganda               Tanzania borders with   \n",
       "\n",
       "       true                                              false  \n",
       "0   Suffolk  [Upper Macungie Township, Anabar, Riau, Bologn...  \n",
       "1    Israel                              [Mpumalanga, Simbach]  \n",
       "2  Ethiopia  [James City County, Virginia, Portneuf, Rockin...  \n",
       "3    Israel  [Sestriere, Nitra District, Acerra, Le Havre, ...  \n",
       "4    Uganda  [Ukrainians, First Czechoslovak Republic, Zibu...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trex_causal_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fact_id</th>\n",
       "      <th>relation</th>\n",
       "      <th>subject</th>\n",
       "      <th>object</th>\n",
       "      <th>stem</th>\n",
       "      <th>true</th>\n",
       "      <th>false</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11955</th>\n",
       "      <td>12996</td>\n",
       "      <td>P264</td>\n",
       "      <td>Cody Wise</td>\n",
       "      <td>Interscope Records</td>\n",
       "      <td>The music label that is representing Cody Wise is</td>\n",
       "      <td>Interscope Records</td>\n",
       "      <td>[Holy Records, Heads Up International, Disney,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11956</th>\n",
       "      <td>12997</td>\n",
       "      <td>P264</td>\n",
       "      <td>Amy Ray</td>\n",
       "      <td>Daemon Records</td>\n",
       "      <td>Daemon Records artists such as</td>\n",
       "      <td>Amy Ray</td>\n",
       "      <td>[So So Def Recordings, Universal Music Japan, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11957</th>\n",
       "      <td>12998</td>\n",
       "      <td>P264</td>\n",
       "      <td>Martin Sorrondeguy</td>\n",
       "      <td>Lengua Armada Discos</td>\n",
       "      <td>Martin Sorrondeguy, which is represented by</td>\n",
       "      <td>Lengua Armada Discos</td>\n",
       "      <td>[Frontiers Records, Barnaby Records, Aggro Ber...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11958</th>\n",
       "      <td>12999</td>\n",
       "      <td>P264</td>\n",
       "      <td>Madlib</td>\n",
       "      <td>Stones Throw</td>\n",
       "      <td>Stones Throw artists such as</td>\n",
       "      <td>Madlib</td>\n",
       "      <td>[Green Linnet Records, Mute records, Vee Jay R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11959</th>\n",
       "      <td>13000</td>\n",
       "      <td>P264</td>\n",
       "      <td>X&amp;Y</td>\n",
       "      <td>Parlophone</td>\n",
       "      <td>X&amp;Y's label is</td>\n",
       "      <td>Parlophone</td>\n",
       "      <td>[Angular Recording Corporation, SPV GmbH, Abac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fact_id relation             subject                object  \\\n",
       "11955    12996     P264           Cody Wise    Interscope Records   \n",
       "11956    12997     P264             Amy Ray        Daemon Records   \n",
       "11957    12998     P264  Martin Sorrondeguy  Lengua Armada Discos   \n",
       "11958    12999     P264              Madlib          Stones Throw   \n",
       "11959    13000     P264                 X&Y            Parlophone   \n",
       "\n",
       "                                                    stem  \\\n",
       "11955  The music label that is representing Cody Wise is   \n",
       "11956                     Daemon Records artists such as   \n",
       "11957        Martin Sorrondeguy, which is represented by   \n",
       "11958                       Stones Throw artists such as   \n",
       "11959                                     X&Y's label is   \n",
       "\n",
       "                       true                                              false  \n",
       "11955    Interscope Records  [Holy Records, Heads Up International, Disney,...  \n",
       "11956               Amy Ray  [So So Def Recordings, Universal Music Japan, ...  \n",
       "11957  Lengua Armada Discos  [Frontiers Records, Barnaby Records, Aggro Ber...  \n",
       "11958                Madlib  [Green Linnet Records, Mute records, Vee Jay R...  \n",
       "11959            Parlophone  [Angular Recording Corporation, SPV GmbH, Abac...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trex_causal_subset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_calinet_input_information = {}\n",
    "trex_list = trex_causal_subset.to_dict('records')\n",
    "for i, entry in enumerate(trex_list):\n",
    "    data_calinet_input_information[i] = trex_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pairs = 0\n",
    "for x, y in data_calinet_input_information.items():\n",
    "    data_calinet_input_information[x] = y \n",
    "    data_calinet_input_information[x]['false'] = list(set(y['false']))\n",
    "    \n",
    "    num_pairs += len(data_calinet_input_information[x]['false'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in calinet_input_info is 50386\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of rows in calinet_input_info is {num_pairs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out initial df to json if desired\n",
    "\n",
    "\n",
    "# write out cleaned/formatted df\n",
    "#with open(\n",
    "#    f\"../data/ingestion_tmp_data/calinet_input_information.json\", \"w\"\n",
    "#) as outfile:\n",
    "#    json.dump(output_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P495     4172\n",
       "P138     3729\n",
       "P264     3533\n",
       "P1376    3509\n",
       "P101     3279\n",
       "P740     3246\n",
       "P36      3215\n",
       "P449     2794\n",
       "P47      2265\n",
       "P20      2046\n",
       "P19      1760\n",
       "P159     1729\n",
       "P27      1717\n",
       "P530     1506\n",
       "P106     1497\n",
       "P407     1492\n",
       "P364     1457\n",
       "P176     1277\n",
       "P39      1268\n",
       "P37      1000\n",
       "P937      995\n",
       "P178      995\n",
       "P136      967\n",
       "P463      758\n",
       "P413      245\n",
       "Name: relation, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# out of curiosity, which relation templates persist in the cleaned, 'causal friendly' set...\n",
    "trex_causal_df['relation'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in ROME counterfact data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/rome_counterfact_original/counterfact.json', 'r') as f:\n",
    "    data_rome = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in calinet_input_info is 21919\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'Number of rows in calinet_input_info is {len(data_rome)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rome_input_information = {}\n",
    "\n",
    "for i in range(len(data_rome)):\n",
    "    stem = data_rome[i]['requested_rewrite']['prompt'].replace('{}', data_rome[i]['requested_rewrite']['subject'])\n",
    "    \n",
    "    data_rome_input_information[str(i)] = {\n",
    "        \"stem\": stem,\n",
    "        \"true\": data_rome[i]['requested_rewrite']['target_true']['str'],\n",
    "        \"false\": [data_rome[i]['requested_rewrite']['target_new']['str']],\n",
    "        \"case_id\":  data_rome[i]['case_id']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_rome_input_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\n",
    "#    f\"../data/ingestion_tmp_data/rome_counterfact_input_information.json\", \"w\"\n",
    "#) as outfile:\n",
    "#    json.dump(data_rome_input_information, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rome = copy.deepcopy(data_rome_input_information)\n",
    "data_calinet = copy.deepcopy(data_calinet_input_information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_calinet\n",
    "#data_rome\n",
    "\n",
    "mixed_itr = 0\n",
    "mixed_df = {}\n",
    "\n",
    "for x, y in data_calinet.items():\n",
    "    y['dataset_original'] = 'calinet_input_information'\n",
    "    mixed_df[str(mixed_itr)] = y\n",
    "\n",
    "    mixed_itr+=1\n",
    "\n",
    "for x, y in data_rome.items():\n",
    "    y['dataset_original'] = 'rome_counterfact_input_information'\n",
    "    mixed_df[str(mixed_itr)] = y\n",
    "    mixed_itr+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in mixed_df is 33879\n"
     ]
    }
   ],
   "source": [
    "itrs = 0\n",
    "for x, y in mixed_df.items():\n",
    "    itrs += 1\n",
    "\n",
    "print(f'Number of rows in mixed_df is {itrs}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optionally write the mixed json to file\n",
    "\n",
    "#with open(\n",
    "    #f\"../data/ingestion_tmp_data/fact_checking_full_input_information.json\", \"w\"\n",
    "#) as outfile:\n",
    "    #json.dump(mixed_df, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert json to pandas, then upload to huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test load of mixed json\n",
    "\n",
    "#with open(\n",
    "#    f\"../data/ingestion_tmp_data/fact_checking_full_input_information.json\", \"r\"\n",
    "#) as outfile:\n",
    "#    mixed_df = json.load(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of [stem + fact + counterfact] trios in mixed_df is 72305\n",
      "The number of [stem + fact] pairs in mixed_df is 33879\n"
     ]
    }
   ],
   "source": [
    "pairs_list = []\n",
    "for x, y in mixed_df.items():\n",
    "    for itr in range(len(y['false'])):\n",
    "        pairs = [y['stem'] + ' ' + y['true'] + ' ' + y['false'][itr]]\n",
    "        pairs_list.append(pairs)\n",
    "\n",
    "print(f'The number of [stem + fact + counterfact] trios in mixed_df is {len(pairs_list)}')\n",
    "\n",
    "x_list = []\n",
    "pairs_list = []\n",
    "for x, y in mixed_df.items():\n",
    "    pairs = [y['stem'] + ' ' + y['true']]\n",
    "    pairs_list.append(pairs)\n",
    "\n",
    "print(f'The number of [stem + fact] pairs in mixed_df is {len(pairs_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update mixed_df to have all info for rome then write that out. \n",
    "mixed_df = pd.DataFrame.from_dict(mixed_df).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rome info to look at:\n",
    "with open('../data/rome_counterfact_original/counterfact.json', 'r') as f:\n",
    "    data_rome_original = json.load(f)\n",
    "    rome_df = pd.DataFrame.from_dict(data_rome_original)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3/20 data frame cleanup\n",
    "rome_df.head()\n",
    "\n",
    "rome_subjects = {}\n",
    "rome_objects = {}\n",
    "rome_relations = {}\n",
    "\n",
    "for i, rewrite in enumerate(rome_df['requested_rewrite']):\n",
    "    rome_subjects[i] = rewrite['subject']\n",
    "    rome_objects[i] = rewrite['target_true']['str']\n",
    "    rome_relations[i] = rewrite['relation_id']\n",
    "\n",
    "assert(len(rome_subjects) == len(rome_objects) == len(rome_relations) == rome_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = []\n",
    "objects = []\n",
    "ids = []\n",
    "relations = []\n",
    "\n",
    "for row in mixed_df.iterrows():\n",
    "    if row[1]['dataset_original'] == 'calinet_input_information':\n",
    "        subjects.append(row[1]['subject'])\n",
    "        objects.append(row[1]['object'])\n",
    "        relations.append(row[1]['relation'])\n",
    "        ids.append('calinet_' + str(row[1]['fact_id']))\n",
    "    if row[1]['dataset_original'] == 'rome_counterfact_input_information':\n",
    "        # get case id\n",
    "        case_id = row[1]['case_id']\n",
    "        \n",
    "        # get subject\n",
    "        subjects.append(rome_subjects[case_id])\n",
    "        # get object\n",
    "        objects.append(rome_objects[case_id])\n",
    "        # get relation\n",
    "        relations.append(rome_relations[case_id])\n",
    "        ids.append('rome_' + str(case_id))\n",
    "\n",
    "assert(len(subjects) == len(objects) == len(ids) == len(relations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_df['subject'] = subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_df['object'] = objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_df['relation'] = relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_df['dataset_id'] = ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_df.drop(['fact_id', 'case_id', 'dataset_original'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(not mixed_df.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-arrange cols\n",
    "mixed_df = mixed_df[['dataset_id', 'stem', 'true', 'false', 'relation', 'subject', 'object' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to file as .csv\n",
    "mixed_df.to_csv('../data/ingestion_tmp_data/fact_checking_full_input_information_3_20_23.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>stem</th>\n",
       "      <th>true</th>\n",
       "      <th>false</th>\n",
       "      <th>relation</th>\n",
       "      <th>subject</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>calinet_1</td>\n",
       "      <td>Norfolk borders with</td>\n",
       "      <td>Suffolk</td>\n",
       "      <td>[Vadena, Upper Macungie Township, Anabar, Riau...</td>\n",
       "      <td>P47</td>\n",
       "      <td>Norfolk</td>\n",
       "      <td>Suffolk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>calinet_2</td>\n",
       "      <td>Jordan shares a common border with</td>\n",
       "      <td>Israel</td>\n",
       "      <td>[Simbach, Mpumalanga]</td>\n",
       "      <td>P47</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>Israel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>calinet_3</td>\n",
       "      <td>Kenya shares border with</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>[Portneuf, Giridih, Canazei, Rockingham County...</td>\n",
       "      <td>P47</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Ethiopia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>calinet_4</td>\n",
       "      <td>Egypt shares its border with</td>\n",
       "      <td>Israel</td>\n",
       "      <td>[Le Havre, Sestriere, Nitra District, Montréal...</td>\n",
       "      <td>P47</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>Israel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>calinet_5</td>\n",
       "      <td>Tanzania borders with</td>\n",
       "      <td>Uganda</td>\n",
       "      <td>[First Czechoslovak Republic, Ukrainians, Zibu...</td>\n",
       "      <td>P47</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Uganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33874</th>\n",
       "      <td>rome_21914</td>\n",
       "      <td>Georges Bernier, speaker of</td>\n",
       "      <td>French</td>\n",
       "      <td>[Russian]</td>\n",
       "      <td>P103</td>\n",
       "      <td>Georges Bernier</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33875</th>\n",
       "      <td>rome_21915</td>\n",
       "      <td>The language used by Jean-Pierre Dionnet is</td>\n",
       "      <td>French</td>\n",
       "      <td>[Spanish]</td>\n",
       "      <td>P1412</td>\n",
       "      <td>Jean-Pierre Dionnet</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33876</th>\n",
       "      <td>rome_21916</td>\n",
       "      <td>Which position does Bong Jung-keun play? They ...</td>\n",
       "      <td>pitcher</td>\n",
       "      <td>[outfielder]</td>\n",
       "      <td>P413</td>\n",
       "      <td>Bong Jung-keun</td>\n",
       "      <td>pitcher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33877</th>\n",
       "      <td>rome_21917</td>\n",
       "      <td>Umayyad Caliphate's capital,</td>\n",
       "      <td>Damascus</td>\n",
       "      <td>[Athens]</td>\n",
       "      <td>P36</td>\n",
       "      <td>Umayyad Caliphate</td>\n",
       "      <td>Damascus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33878</th>\n",
       "      <td>rome_21918</td>\n",
       "      <td>Subair works as</td>\n",
       "      <td>actor</td>\n",
       "      <td>[composer]</td>\n",
       "      <td>P106</td>\n",
       "      <td>Subair</td>\n",
       "      <td>actor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33879 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       dataset_id                                               stem  \\\n",
       "0       calinet_1                               Norfolk borders with   \n",
       "1       calinet_2                 Jordan shares a common border with   \n",
       "2       calinet_3                           Kenya shares border with   \n",
       "3       calinet_4                       Egypt shares its border with   \n",
       "4       calinet_5                              Tanzania borders with   \n",
       "...           ...                                                ...   \n",
       "33874  rome_21914                        Georges Bernier, speaker of   \n",
       "33875  rome_21915        The language used by Jean-Pierre Dionnet is   \n",
       "33876  rome_21916  Which position does Bong Jung-keun play? They ...   \n",
       "33877  rome_21917                       Umayyad Caliphate's capital,   \n",
       "33878  rome_21918                                    Subair works as   \n",
       "\n",
       "           true                                              false relation  \\\n",
       "0       Suffolk  [Vadena, Upper Macungie Township, Anabar, Riau...      P47   \n",
       "1        Israel                              [Simbach, Mpumalanga]      P47   \n",
       "2      Ethiopia  [Portneuf, Giridih, Canazei, Rockingham County...      P47   \n",
       "3        Israel  [Le Havre, Sestriere, Nitra District, Montréal...      P47   \n",
       "4        Uganda  [First Czechoslovak Republic, Ukrainians, Zibu...      P47   \n",
       "...         ...                                                ...      ...   \n",
       "33874    French                                          [Russian]     P103   \n",
       "33875    French                                          [Spanish]    P1412   \n",
       "33876   pitcher                                       [outfielder]     P413   \n",
       "33877  Damascus                                           [Athens]      P36   \n",
       "33878     actor                                         [composer]     P106   \n",
       "\n",
       "                   subject    object  \n",
       "0                  Norfolk   Suffolk  \n",
       "1                   Jordan    Israel  \n",
       "2                    Kenya  Ethiopia  \n",
       "3                    Egypt    Israel  \n",
       "4                 Tanzania    Uganda  \n",
       "...                    ...       ...  \n",
       "33874      Georges Bernier    French  \n",
       "33875  Jean-Pierre Dionnet    French  \n",
       "33876       Bong Jung-keun   pitcher  \n",
       "33877    Umayyad Caliphate  Damascus  \n",
       "33878               Subair     actor  \n",
       "\n",
       "[33879 rows x 7 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete erroneous entries in the dataset\n",
    "# these were not exhaustively searched for, some\n",
    "# errors could still exist in the data\n",
    "\n",
    "rows_to_delete = [\n",
    "\n",
    "# llama-33b:\n",
    "'rome_19765',\n",
    "'calinet_9087',\n",
    "'rome_9674',\n",
    "'rome_13669',\n",
    "'rome_17792',\n",
    "'calinet_469',\n",
    "'calinet_12945', \n",
    "'rome_17452', \n",
    "'rome_597',\n",
    "'calinet_7656', \n",
    "'rome_16474', \n",
    "'rome_6020', \n",
    "'rome_9479', \n",
    "'calinet_5834', \n",
    "'rome_9414', \n",
    "'rome_6487', \n",
    "'rome_10852', \n",
    "'rome_14709', \n",
    "'rome_4358', \n",
    "'rome_10342', \n",
    "'calinet_12839', \n",
    "'rome_19963', \n",
    "'rome_5757', \n",
    "'rome_3604', \n",
    "'rome_8710', \n",
    "'calinet_2551', \n",
    "'rome_20688', \n",
    "'rome_15441', \n",
    "'calinet_12842', \n",
    "'calinet_9348', \n",
    "'calinet_2516', \n",
    "'calinet_12777', \n",
    "'rome_13682', \n",
    "'calinet_29',\n",
    "\n",
    "# flan-t5-xl:\n",
    "'calinet_3198',\n",
    "'rome_10178',\n",
    "'rome_19495',\n",
    "'rome_9674',\n",
    "'rome_13028',\n",
    "'calinet_5452',\n",
    "'rome_19963',\n",
    "'calinet_2568',\n",
    "'calinet_5475',\n",
    "'calinet_9555',\n",
    "'rome_19788',\n",
    "'rome_12483',\n",
    "'rome_14334',\n",
    "'calinet_10778',\n",
    "'rome_612',\n",
    "'rome_8416',\n",
    "'calinet_5133',\n",
    "'calinet_5185',\n",
    "'rome_1525',\n",
    "\n",
    "# roberta-large:\n",
    "\n",
    "# random finds\n",
    "'calinet_9032',\n",
    "\n",
    "\n",
    "]\n",
    "\n",
    "# delete these rows\n",
    "for i in list(mixed_df.index):\n",
    "    if mixed_df.loc[i].dataset_id in list(set(rows_to_delete)):\n",
    "        # print(mixed_df.loc[i].dataset_id)\n",
    "        mixed_df.drop(i, axis=0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete stems that end with \"a\" or \"an\"\n",
    "itr = 0\n",
    "for i in list(mixed_df.index):\n",
    "\n",
    "    if (mixed_df.loc[i].stem[-2:] == ' a') or (mixed_df.loc[i].stem[-3:] == ' an'):\n",
    "        itr+=1\n",
    "        #print(mixed_df.loc[i].stem, \":\", mixed_df.loc[i].true, mixed_df.loc[i].false)\n",
    "        mixed_df.drop(i, axis=0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify erroneous errors when sandwitched with correct data\n",
    "# dictionary: dataset_id and new counterfact list, with the error removed\n",
    "\n",
    "rows_to_alter = {\n",
    "\n",
    "# llama-33b:\n",
    "'calinet_7809': {'false': \"['Gaulish', 'Georgian']\"},\n",
    "'calinet_1917': {'false': \"['theology', 'free software', 'accounting']\"},\n",
    "'calinet_7790': {'false': ['Hebrew', 'Swahili']},\n",
    "'rome_11311': {'false': ['Russian'], 'true': 'French', 'object': 'French'},\n",
    "\n",
    "# flan-t5-xl:\n",
    "\n",
    "# roberta-large:\n",
    "\n",
    "}\n",
    "\n",
    "for key, dictionary in rows_to_alter.items():\n",
    "    for column, edit in dictionary.items():\n",
    "        row_ind = mixed_df[mixed_df.dataset_id==key].false.index[0]\n",
    "        mixed_df.loc[row_ind, column] = edit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix small syntax and grammatical errors:\n",
    "\n",
    "# context: \"shares border with\" / \"shares the border with\"-> \"shares a border with\"\n",
    "\n",
    "for i in range(len(mixed_df)):\n",
    "    if 'shares border with' in mixed_df.loc[i].stem:\n",
    "        mixed_df.loc[i, \"stem\"] = mixed_df.loc[i].stem.replace('shares border with', 'shares a border with')\n",
    "\n",
    "    elif 'shares the border with' in mixed_df.loc[i].stem:\n",
    "        mixed_df.loc[i, \"stem\"] = mixed_df.loc[i].stem.replace('shares the border with', 'shares a border with')\n",
    "\n",
    "    elif 'borders with' in mixed_df.loc[i].stem:\n",
    "        mixed_df.loc[i, \"stem\"] = mixed_df.loc[i].stem.replace('borders with', 'shares a border with')\n",
    "    \n",
    "    elif 'premiered' in mixed_df.loc[i].stem:\n",
    "        mixed_df.loc[i, \"stem\"] = mixed_df.loc[i].stem.replace('premiered', 'originally aired')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in mixed_df is 33456\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of rows in mixed_df is {len(mixed_df)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicate: ('Austria shares a border with', 'Switzerland')\n",
      "duplicate: ('Japan shares a border with', 'Taiwan')\n",
      "duplicate: ('Bangladesh shares a border with', 'India')\n",
      "duplicate: ('Afghanistan shares a border with', 'Pakistan')\n",
      "duplicate: ('Sichuan shares a border with', 'Guizhou')\n",
      "duplicate: ('Europe shares a border with', 'Asia')\n",
      "duplicate: ('Seoul is the capital of', 'South Korean')\n",
      "duplicate: ('The capital city of Scotland is', 'Edinburgh')\n",
      "duplicate: ('Harare is the capital city of', 'Zimbabwe')\n",
      "duplicate: ('London is the capital of', 'England')\n",
      "duplicate: ('Northern Ireland, which has the capital', 'Belfast')\n",
      "duplicate: ('Poland, which has the capital', 'Warsaw')\n",
      "duplicate: (\"Israel's capital city is\", 'Jerusalem')\n",
      "duplicate: ('The capital city of Russia is', 'Moscow')\n",
      "duplicate: ('The capital city of Colorado is', 'Denver')\n",
      "duplicate: ('Edinburgh is the capital of', 'Scottish')\n",
      "duplicate: ('The capital city of Belarus is', 'Minsk')\n",
      "duplicate: ('The capital city of Jiangsu Province is', 'Nanjing')\n",
      "duplicate: ('Vilnius is the capital of', 'Lithuania')\n",
      "duplicate: ('Cardiff, that is the capital city of', 'Wales')\n",
      "duplicate: ('Athens is the capital of', 'Greece')\n",
      "duplicate: ('The capital city of Afghanistan is', 'Kabul')\n",
      "duplicate: ('The capital city of Namibia is', 'Windhoek')\n",
      "duplicate: ('The language of TY.O is', 'English')\n",
      "duplicate: ('United States ties diplomatic relations with', 'Germany')\n",
      "duplicate: ('United States maintains diplomatic relations with', 'Argentina')\n",
      "duplicate: ('Mongolia ties diplomatic relations with', 'China')\n",
      "duplicate: ('Brazil ties diplomatic relations with', 'Venezuela')\n",
      "duplicate: ('Brazil maintains diplomatic relations with', 'India')\n",
      "duplicate: ('Colombia maintains diplomatic relations with', 'Brazil')\n",
      "duplicate: ('Germany maintains diplomatic relations with', 'Switzerland')\n",
      "duplicate: ('Germany maintains diplomatic relations with', 'Israel')\n",
      "duplicate: ('Italy ties diplomatic relations with', 'Germany')\n",
      "duplicate: ('Philippines maintains diplomatic relations with', 'Australia')\n",
      "duplicate: ('Zambia has diplomatic relations with', 'South Africa')\n",
      "duplicate: ('Italy maintains diplomatic relations with', 'Switzerland')\n",
      "duplicate: ('Italy maintains diplomatic relations with', 'Turkey')\n",
      "duplicate: ('Australia maintains diplomatic relations with', 'United States')\n",
      "duplicate: ('Australia maintains diplomatic relations with', 'Brazil')\n",
      "duplicate: ('China maintains diplomatic relations with', 'Australia')\n",
      "duplicate: ('Japan maintains diplomatic relations with', 'Korea')\n",
      "duplicate: ('Netherlands maintains diplomatic relations with', 'Australia')\n",
      "duplicate: ('Netherlands has diplomatic relations with', 'Italy')\n",
      "duplicate: ('Japan maintains diplomatic relations with', 'American')\n",
      "duplicate: ('Slovenia ties diplomatic relations with', 'Germany')\n",
      "duplicate: ('USA ties diplomatic relations with', 'India')\n",
      "duplicate: ('Belgium maintains diplomatic relations with', 'Luxembourg')\n",
      "duplicate: ('Italy maintains diplomatic relations with', 'Slovakia')\n",
      "duplicate: ('Canada maintains diplomatic relations with', 'Ukraine')\n",
      "duplicate: ('Italy maintains diplomatic relations with', 'Russia')\n",
      "duplicate: ('US maintains diplomatic relations with', 'Australia')\n",
      "duplicate: ('Windows 8, created by', 'Microsoft')\n",
      "duplicate: ('Raymond Flynn was employed in', 'Boston')\n",
      "duplicate: ('Windows NT 3.1, developed by', 'Microsoft')\n",
      "duplicate: ('The official language of Mari El Republic is', 'Russian')\n",
      "duplicate: ('The official language of United Nations is', 'French')\n",
      "duplicate: ('Fiat Ritmo, created by', 'Fiat')\n",
      "duplicate: ('The language of Sendiri is', 'Indonesian')\n",
      "duplicate: ('Hasekura Tsunenaga took up work in', 'Rome')\n",
      "duplicate: ('Law & Order debuted on', 'NBC')\n",
      "duplicate: ('Daniele Capezzone was employed in', 'Rome')\n",
      "duplicate: ('Great Performances was originally aired on', 'PBS')\n",
      "duplicate: ('Tibetan Terrier is named after', 'Tibet')\n",
      "duplicate: ('The official language of Armenia is', 'Armenian')\n",
      "duplicate: ('The language of Le Devoir was', 'French')\n",
      "duplicate: ('The official language of Paraguay is', 'Spanish')\n",
      "duplicate: ('The official language of Suriname is', 'Dutch')\n",
      "duplicate: ('Scott Allan plays in the position of', 'midfielder')\n",
      "duplicate: ('Bob Rusch plays', 'jazz')\n",
      "duplicate: ('Athanase David was employed in', 'Montreal')\n",
      "duplicate: ('Fiat Albea is created by', 'Fiat')\n",
      "duplicate: ('Yes Minister was originally aired on', 'BBC')\n",
      "duplicate: ('Raymond Hains expired at', 'Paris')\n",
      "duplicate: ('Pentium II was developed by', 'Intel')\n",
      "duplicate: ('Arsenio Lacson passed away in', 'Manila')\n",
      "duplicate: ('The Rerun Show debuted on', 'NBC')\n",
      "duplicate: ('The language of Zero Motivation was', 'Hebrew')\n",
      "duplicate: ('Honda Accord is developed by', 'Honda')\n",
      "duplicate: ('Francisco Franco worked in', 'Madrid')\n",
      "duplicate: ('The language of Le Gaulois was', 'French')\n",
      "duplicate: ('Bergens Tidende was written in', 'Norwegian')\n",
      "duplicate: ('Ooberman formed in', 'Liverpool')\n",
      "duplicate: ('The language of Le Temps is', 'French')\n",
      "duplicate: ('The language of Power Unlimited was', 'Dutch')\n",
      "duplicate: ('MTV Cribs was originally aired on', 'MTV')\n",
      "duplicate: ('Secretos is written in', 'Spanish')\n",
      "duplicate: ('Rock Plaza Central was founded in', 'Toronto')\n",
      "duplicate: ('Chad Hutchinson plays in the position of', 'quarterback')\n",
      "duplicate: ('The language of Le Monde is', 'French')\n",
      "duplicate: (\"Spain's capital city,\", 'Madrid')\n",
      "duplicate: (\"L'Officiel was written in\", 'French')\n",
      "duplicate: ('Urania specializes in', 'astronomy')\n",
      "duplicate: ('Bill Ranford plays in the position of', 'goaltender')\n",
      "duplicate: ('The official language of Cuba is', 'Spanish')\n",
      "duplicate: ('The official language of India is', 'English')\n",
      "duplicate: ('The language of Mo Li Hua was', 'Chinese')\n",
      "duplicate: ('Odakyu Electric Railway, that was created in', 'Tokyo')\n",
      "duplicate: ('The official language of Bulgaria is', 'Bulgarian')\n",
      "duplicate: ('The capital city of Libya is', 'Tripoli')\n",
      "duplicate: ('Johan Arneng plays in the position of', 'midfielder')\n",
      "duplicate: ('Karl Marx took up work in', 'Cologne')\n",
      "duplicate: ('John Frederick Maurice is originally from', 'London')\n",
      "duplicate: ('The original language of Hrvatska revija was', 'Croatian')\n",
      "duplicate: ('Jonah Jones, who plays', 'jazz')\n",
      "duplicate: ('Gary Stills plays in the position of', 'linebacker')\n",
      "duplicate: ('Howard Ferguson passed away at', 'Toronto')\n",
      "duplicate: ('Renata Polverini worked in', 'Rome')\n",
      "duplicate: ('Ty Conklin plays in the position of', 'goaltender')\n",
      "duplicate: ('Rezonance Q, founded in', 'Liverpool')\n",
      "duplicate: ('Suzuki Escudo is a product of', 'Suzuki')\n",
      "duplicate: ('The capital of Denmark is', 'Copenhagen')\n",
      "duplicate: ('Johnny Vander Meer plays in the position of', 'pitcher')\n",
      "duplicate: ('The Wire was originally aired on', 'HBO')\n",
      "duplicate: ('The original language of Paul Clifford was', 'English')\n",
      "duplicate: ('Jewish Publication Society was founded in', 'Philadelphia')\n",
      "duplicate: ('Windows Phone, created by', 'Microsoft')\n",
      "duplicate: ('BMW 3 Series, produced by', 'BMW')\n",
      "duplicate: ('Dodge Charger, produced by', 'Dodge')\n",
      "duplicate: ('Turkey is a member of', 'NATO')\n",
      "duplicate: ('Zeroman was developed in', 'Canada')\n",
      "duplicate: ('The Dean Martin Show was originally aired on', 'NBC')\n",
      "duplicate: ('Henrik Lundqvist plays in the position of', 'goaltender')\n",
      "duplicate: ('Jaguar Love, that was started in', 'Seattle')\n",
      "duplicate: ('The domain of work of Log Cabin Republicans is', 'LGBT')\n",
      "duplicate: ('Kevin Lalande plays in the position of', 'goaltender')\n",
      "duplicate: ('The original language of The Caretaker was', 'English')\n",
      "duplicate: ('The capital of Philippines is', 'Manila')\n",
      "duplicate: ('Anna Karenina was written in', 'Russian')\n",
      "duplicate: ('The original language of Kanda Naal Mudhal was', 'Tamil')\n",
      "duplicate: ('Airbus Beluga, created by', 'Airbus')\n",
      "duplicate: ('Unus pro omnibus, omnes pro uno is written in', 'Latin')\n",
      "duplicate: ('Gustav Stresemann found employment in', 'Berlin')\n",
      "duplicate: ('Moritz von Schwind took up work in', 'Vienna')\n",
      "duplicate: ('Just Shoot Me! was released on', 'NBC')\n",
      "duplicate: ('Suntribe was founded in', 'Estonia')\n",
      "duplicate: ('The official language of Mexico is', 'Spanish')\n",
      "duplicate: ('Xeon is produced by', 'Intel')\n",
      "duplicate: ('The original language of The Three Musketeers was', 'French')\n",
      "duplicate: (\"Israel's capital city is\", 'Jerusalem')\n",
      "duplicate: (\"John Calvin's domain of work is\", 'theology')\n",
      "duplicate: ('The official language of Hailuoto is', 'Finnish')\n",
      "duplicate: ('Fraunces Tavern is located in', 'Manhattan')\n",
      "duplicate: ('Joseph Roth was employed in', 'Berlin')\n",
      "duplicate: ('The official language of Mozambique is', 'Portuguese')\n",
      "duplicate: ('The language of Qzone was', 'Chinese')\n",
      "duplicate: ('Lithuania is affiliated with', 'NATO')\n",
      "duplicate: ('Antonio Gava worked in', 'Rome')\n",
      "duplicate: ('Toyota Innova is created by', 'Toyota')\n",
      "duplicate: ('The original language of 36 China Town is', 'Hindi')\n",
      "duplicate: ('The official language of Ireland is', 'English')\n",
      "duplicate: ('BMW 3 Series is created by', 'BMW')\n",
      "duplicate: ('Le Journal de Mickey is written in', 'French')\n",
      "duplicate: ('Greta Garbo took up work in', 'Hollywood')\n",
      "duplicate: ('Xbox Live is developed by', 'Microsoft')\n",
      "duplicate: ('The 9th Company is written in', 'Russian')\n",
      "duplicate: ('The official language of Odessa Oblast is', 'Ukrainian')\n",
      "duplicate: ('Gary Hogeboom plays in the position of', 'quarterback')\n",
      "duplicate: ('Chuck Howley plays in the position of', 'linebacker')\n",
      "duplicate: ('John Pye was employed in', 'London')\n",
      "duplicate: ('Emergency! debuted on', 'NBC')\n",
      "duplicate: ('BMW 7 Series is developed by', 'BMW')\n",
      "\n",
      "The number of [stem + fact] duplicates is 161\n"
     ]
    }
   ],
   "source": [
    "# find any duplicates resulting from above fixes\n",
    "# start with [stem + fact] pairs\n",
    "\n",
    "pairs_list = []\n",
    "pairs_list_duplicated = []\n",
    "itrs_duplicated = []\n",
    "for i in range(len(mixed_df)):\n",
    "    pairs_print = mixed_df.loc[i].stem + \" {true: \" + mixed_df.loc[i].true +\"}\"\n",
    "    pairs = (mixed_df.loc[i].stem, mixed_df.loc[i].true)\n",
    "    if pairs in pairs_list:\n",
    "        print('duplicate:', pairs)\n",
    "        pairs_list_duplicated.append(pairs)\n",
    "        itrs_duplicated.append(i)\n",
    "    pairs_list.append(pairs)\n",
    "\n",
    "print(f'\\nThe number of [stem + fact] duplicates is {len(pairs_list) - len(list(set(pairs_list)))}')\n",
    "\n",
    "# repair any duplicates resulting from above fixes\n",
    "pairs_list_collect = []\n",
    "for i in range(len(mixed_df)):\n",
    "    pairs_print = mixed_df.loc[i].stem + \" {true: \" + mixed_df.loc[i].true +\"}\"\n",
    "    pairs = (mixed_df.loc[i].stem, mixed_df.loc[i].true)\n",
    "    if pairs in pairs_list_duplicated:\n",
    "        pairs_list_collect.append((mixed_df.loc[i].stem, mixed_df.loc[i].true, mixed_df.loc[i].false))\n",
    "\n",
    "new_counterfacts = {}\n",
    "for element in pairs_list_collect:   \n",
    "    try:\n",
    "        new_counterfacts[element[0] + \" \" + element[1]].extend(element[2])\n",
    "    except KeyError:\n",
    "        new_counterfacts[element[0] + \" \" + element[1]] = element[2]\n",
    "\n",
    "new_counterfacts_2 = {}\n",
    "for x, y in new_counterfacts.items():\n",
    "    # print(x,y)\n",
    "    new_counterfacts_2[x] = list(set(y))\n",
    "\n",
    "#new_counterfacts_2\n",
    "\n",
    "for i in range(len(mixed_df)):\n",
    "    key_item = mixed_df.loc[i].stem + \" \" + mixed_df.loc[i].true\n",
    "    if key_item in list(new_counterfacts_2.keys()):\n",
    "\n",
    "        mixed_df.loc[i, 'false'] = new_counterfacts_2[key_item]\n",
    "\n",
    "mixed_df.drop_duplicates(subset=['stem', 'true'], inplace=True)\n",
    "mixed_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The number of [stem + fact] duplicates is 0\n"
     ]
    }
   ],
   "source": [
    "# find any duplicates remaining\n",
    "pairs_list = []\n",
    "for i in range(len(mixed_df)):\n",
    "    pairs = (mixed_df.loc[i].stem, mixed_df.loc[i].true)\n",
    "    pairs_list.append(pairs)\n",
    "\n",
    "print(f'\\nThe number of [stem + fact] duplicates is {len(pairs_list) - len(list(set(pairs_list)))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure all counterfacts are sets\n",
    "pairs_list = []\n",
    "for i in range(len(mixed_df)):\n",
    "    mixed_df.loc[i, 'false'] = list(set(mixed_df.loc[i, 'false']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The number of duplicate [stem + fact + false] trios is 0\n"
     ]
    }
   ],
   "source": [
    "# find any trio duplicates remaining\n",
    "pairs_list = []\n",
    "for i in range(len(mixed_df)):\n",
    "    for item in mixed_df.loc[i].false:\n",
    "        pairs = (mixed_df.loc[i].stem, mixed_df.loc[i].true, item)\n",
    "        pairs_list.append(pairs)\n",
    "\n",
    "print(f'\\nThe number of duplicate [stem + fact + false] trios is {len(pairs_list) - len(list(set(pairs_list)))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of [stem + fact + counterfact] trios in mixed_df is 71700\n",
      "The number of [stem + fact] pairs in mixed_df is 33295\n"
     ]
    }
   ],
   "source": [
    "# print numbers of pairs and trios in the dataset again\n",
    "\n",
    "pairs_list = []\n",
    "for i in range(len(mixed_df)):\n",
    "    for item in mixed_df.loc[i].false:\n",
    "        pairs = (mixed_df.loc[i].stem, mixed_df.loc[i].true, item)\n",
    "        pairs_list.append(pairs)\n",
    "print(f'The number of [stem + fact + counterfact] trios in mixed_df is {len(pairs_list)}')\n",
    "\n",
    "pairs_list = []\n",
    "for i in range(len(mixed_df)):\n",
    "    pairs = (mixed_df.loc[i].stem, mixed_df.loc[i].true)\n",
    "    pairs_list.append(pairs)\n",
    "\n",
    "print(f'The number of [stem + fact] pairs in mixed_df is {len(pairs_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in mixed_df is 33295\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of rows in mixed_df is {len(mixed_df)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>stem</th>\n",
       "      <th>true</th>\n",
       "      <th>false</th>\n",
       "      <th>relation</th>\n",
       "      <th>subject</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rome_18789</td>\n",
       "      <td>Suzuki Aerio is developed by</td>\n",
       "      <td>Suzuki</td>\n",
       "      <td>[Dodge]</td>\n",
       "      <td>P176</td>\n",
       "      <td>Suzuki Aerio</td>\n",
       "      <td>Suzuki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>calinet_6880</td>\n",
       "      <td>American Wrestling Association's headquarters ...</td>\n",
       "      <td>Minneapolis, Minnesota</td>\n",
       "      <td>[Wheeling, Illinois, Mongomo, México, OneChica...</td>\n",
       "      <td>P159</td>\n",
       "      <td>American Wrestling Association</td>\n",
       "      <td>Minneapolis, Minnesota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rome_15269</td>\n",
       "      <td>The Two Babylons was created in</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>[France]</td>\n",
       "      <td>P495</td>\n",
       "      <td>The Two Babylons</td>\n",
       "      <td>Scotland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>calinet_8045</td>\n",
       "      <td>The Smashing Pumpkins, who plays</td>\n",
       "      <td>rock</td>\n",
       "      <td>[detective film, cookbook]</td>\n",
       "      <td>P136</td>\n",
       "      <td>The Smashing Pumpkins</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>calinet_8671</td>\n",
       "      <td>Aero Commander 500 family is produced by</td>\n",
       "      <td>Aero Commander</td>\n",
       "      <td>[Mars Confectionery, Apple computer, ATARI]</td>\n",
       "      <td>P176</td>\n",
       "      <td>Aero Commander 500 family</td>\n",
       "      <td>Aero Commander</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33290</th>\n",
       "      <td>rome_5138</td>\n",
       "      <td>In Nicaragua, the language spoken is</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>[German]</td>\n",
       "      <td>P37</td>\n",
       "      <td>Nicaragua</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33291</th>\n",
       "      <td>calinet_7237</td>\n",
       "      <td>Elio Fiorucci, that was started in</td>\n",
       "      <td>Milan</td>\n",
       "      <td>[Madrid, England, Waltham, Massachusetts, Deni...</td>\n",
       "      <td>P740</td>\n",
       "      <td>Elio Fiorucci</td>\n",
       "      <td>Milan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33292</th>\n",
       "      <td>calinet_12481</td>\n",
       "      <td>Diocletian, who has the position of</td>\n",
       "      <td>Roman Emperor</td>\n",
       "      <td>[Strategos, North Carolina Attorney General, p...</td>\n",
       "      <td>P39</td>\n",
       "      <td>Diocletian</td>\n",
       "      <td>Roman Emperor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33293</th>\n",
       "      <td>calinet_871</td>\n",
       "      <td>Claude Flight was born in</td>\n",
       "      <td>London</td>\n",
       "      <td>[Lebrija, Lebanon, Oregon, Lauterburg]</td>\n",
       "      <td>P19</td>\n",
       "      <td>Claude Flight</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33294</th>\n",
       "      <td>rome_4062</td>\n",
       "      <td>The original language of Turner &amp; Hooch is</td>\n",
       "      <td>English</td>\n",
       "      <td>[Croatian]</td>\n",
       "      <td>P364</td>\n",
       "      <td>Turner &amp; Hooch</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33295 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          dataset_id                                               stem  \\\n",
       "0         rome_18789                       Suzuki Aerio is developed by   \n",
       "1       calinet_6880  American Wrestling Association's headquarters ...   \n",
       "2         rome_15269                    The Two Babylons was created in   \n",
       "3       calinet_8045                   The Smashing Pumpkins, who plays   \n",
       "4       calinet_8671           Aero Commander 500 family is produced by   \n",
       "...              ...                                                ...   \n",
       "33290      rome_5138               In Nicaragua, the language spoken is   \n",
       "33291   calinet_7237                 Elio Fiorucci, that was started in   \n",
       "33292  calinet_12481                Diocletian, who has the position of   \n",
       "33293    calinet_871                          Claude Flight was born in   \n",
       "33294      rome_4062         The original language of Turner & Hooch is   \n",
       "\n",
       "                         true  \\\n",
       "0                      Suzuki   \n",
       "1      Minneapolis, Minnesota   \n",
       "2                    Scotland   \n",
       "3                        rock   \n",
       "4              Aero Commander   \n",
       "...                       ...   \n",
       "33290                 Spanish   \n",
       "33291                   Milan   \n",
       "33292           Roman Emperor   \n",
       "33293                  London   \n",
       "33294                 English   \n",
       "\n",
       "                                                   false relation  \\\n",
       "0                                                [Dodge]     P176   \n",
       "1      [Wheeling, Illinois, Mongomo, México, OneChica...     P159   \n",
       "2                                               [France]     P495   \n",
       "3                             [detective film, cookbook]     P136   \n",
       "4            [Mars Confectionery, Apple computer, ATARI]     P176   \n",
       "...                                                  ...      ...   \n",
       "33290                                           [German]      P37   \n",
       "33291  [Madrid, England, Waltham, Massachusetts, Deni...     P740   \n",
       "33292  [Strategos, North Carolina Attorney General, p...      P39   \n",
       "33293             [Lebrija, Lebanon, Oregon, Lauterburg]      P19   \n",
       "33294                                         [Croatian]     P364   \n",
       "\n",
       "                              subject                  object  \n",
       "0                        Suzuki Aerio                  Suzuki  \n",
       "1      American Wrestling Association  Minneapolis, Minnesota  \n",
       "2                    The Two Babylons                Scotland  \n",
       "3               The Smashing Pumpkins                    rock  \n",
       "4           Aero Commander 500 family          Aero Commander  \n",
       "...                               ...                     ...  \n",
       "33290                       Nicaragua                 Spanish  \n",
       "33291                   Elio Fiorucci                   Milan  \n",
       "33292                      Diocletian           Roman Emperor  \n",
       "33293                   Claude Flight                  London  \n",
       "33294                  Turner & Hooch                 English  \n",
       "\n",
       "[33295 rows x 7 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle the df's rows (without replacement)\n",
    "mixed_df = mixed_df.sample(frac=1, replace=False, random_state=42, ignore_index=True)\n",
    "mixed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to file as .csv\n",
    "mixed_df.to_csv('../data/ingestion_tmp_data/fact_checking_full_input_information_3_21_23.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load final csv to HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-83934004a9df2b56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /Users/danielfurman/.cache/huggingface/datasets/csv/default-83934004a9df2b56/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80feb5c7facd4a4d986f2aaab0ee7076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "149118b0a48049eeac62d0e723b94d6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba9725186774cc2bb1eae6c0cbab9d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /Users/danielfurman/.cache/huggingface/datasets/csv/default-83934004a9df2b56/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0aca4f446214bc1894e980cdfed6f6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    English: Dataset({\n",
       "        features: ['dataset_id', 'stem', 'true', 'false', 'relation', 'subject', 'object'],\n",
       "        num_rows: 33295\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "data_files = {\n",
    "    \"English\": \"../data/ingestion_tmp_data/fact_checking_full_input_information_3_21_23.csv\", \n",
    "}\n",
    "dataset = load_dataset(\"csv\", data_files=data_files)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    English: Dataset({\n",
       "        features: ['dataset_id', 'stem', 'true', 'false', 'relation', 'subject', 'object'],\n",
       "        num_rows: 33295\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid.\n",
      "Your token has been saved to /Users/danielfurman/.huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# This reads the environment variables inside .env\n",
    "load_dotenv() \n",
    "# Logs into HF hub\n",
    "login(os.getenv('HF_TOKEN')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split English to the Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "274721143f474a93a3a155dffb7aa8d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd26907b7a704641a7e0be672e7a3dcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Deleting unused files from dataset repository:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# push to hub\n",
    "dataset.push_to_hub(\"CalibraGPT/Fact_Checking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e1e620721c8463db94dcd6f3af871d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/4.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration CalibraGPT--Fact_Checking-e858a583b1d7a600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/None to /Users/danielfurman/.cache/huggingface/datasets/CalibraGPT___parquet/CalibraGPT--Fact_Checking-e858a583b1d7a600/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb07b842affe4d62bcd93ff993a3153a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e56fa80828c94cfd80f6198adc7ddd2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/2.41M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e76299ddb443108ea1d40ab8424220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc3ce0a173f94fd7996e51ad089628be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /Users/danielfurman/.cache/huggingface/datasets/CalibraGPT___parquet/CalibraGPT--Fact_Checking-e858a583b1d7a600/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e629e0199024ab1b1f8b363bd1e7a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    English: Dataset({\n",
       "        features: ['dataset_id', 'stem', 'true', 'false', 'relation', 'subject', 'object'],\n",
       "        num_rows: 33295\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test loading from hub\n",
    "load_dataset(\"CalibraGPT/Fact_Checking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "301faebbd5cea7fd4466786a19f1bea9d8baf657aaca95ef39840c46b8697603"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
