{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94f71ad4",
   "metadata": {
    "id": "94f71ad4"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!git clone https://github.com/daniel-furman/Capstone.git\n",
    "!pip install -r /content/Capstone/requirements.txt"
   ],
   "metadata": {
    "id": "iZIgDGhwVBWA"
   },
   "id": "iZIgDGhwVBWA",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install geopy\n",
    "!pip install pycountry-convert"
   ],
   "metadata": {
    "id": "Cuk2NXDdXZGT"
   },
   "id": "Cuk2NXDdXZGT",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc63c4d",
   "metadata": {
    "id": "fcc63c4d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import chi2\n",
    "\n",
    "import time\n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "from pycountry_convert import country_alpha2_to_continent_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa36919e",
   "metadata": {
    "id": "fa36919e"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "os.chdir(\"/content/Capstone/notebooks/error_analysis/\")"
   ],
   "metadata": {
    "id": "cSpL1-kOXndJ"
   },
   "id": "cSpL1-kOXndJ",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ede8e4f",
   "metadata": {
    "id": "9ede8e4f"
   },
   "outputs": [],
   "source": [
    "wiki_data = pd.read_csv(\"../../data/wikidata/wikidata-property-list.csv\")\n",
    "wiki_data = wiki_data[[\"Title\", \"ID\", \"Datatype\", \"Description\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1d4cb5",
   "metadata": {
    "id": "1e1d4cb5"
   },
   "outputs": [],
   "source": [
    "code_to_lang_dict = {\n",
    "    \"bg\": \"Bulgarian\",\n",
    "    \"ca\": \"Catalan\",\n",
    "    \"cs\": \"Czech\",\n",
    "    \"da\": \"Danish\",\n",
    "    \"de\": \"German\",\n",
    "    \"en\": \"English\",\n",
    "    \"es\": \"Spanish\",\n",
    "    \"fr\": \"French\",\n",
    "    \"hr\": \"Croatian\",\n",
    "    \"hu\": \"Hungarian\",\n",
    "    \"it\": \"Italian\",\n",
    "    \"nl\": \"Dutch\",\n",
    "    \"pl\": \"Polish\",\n",
    "    \"pt\": \"Portuguese\",\n",
    "    \"ro\": \"Romanian\",\n",
    "    \"ru\": \"Russian\",\n",
    "    \"sl\": \"Slovenian\",\n",
    "    \"sr\": \"Serbian\",\n",
    "    \"sv\": \"Swedish\",\n",
    "    \"uk\": \"Ukrainian\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d61967",
   "metadata": {
    "id": "89d61967"
   },
   "outputs": [],
   "source": [
    "lang_to_code_dict = {v: k for k, v in code_to_lang_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4216b098",
   "metadata": {
    "id": "4216b098"
   },
   "outputs": [],
   "source": [
    "results_dict = {}\n",
    "results_dict[\"language\"] = []\n",
    "results_dict[\"relation\"] = []\n",
    "results_dict[\"percentage change\"] = []\n",
    "results_dict[\"new ratio of rows\"] = []\n",
    "results_dict[\"old ratio of rows\"] = []\n",
    "\n",
    "hf_df = datasets.load_dataset(\"CalibraGPT/Fact-Completion\")\n",
    "file_names = glob.glob(\"../../data/result_logs/llama-30b/error-analysis/*.csv\")\n",
    "\n",
    "# confirm grabbing data correctly against LLaMa figure\n",
    "# uncomment print statement at end of for loop to see\n",
    "results_dfs = []\n",
    "count = 0\n",
    "for file in file_names:\n",
    "    language = file.split(\".csv\")[0].split(\"-\")[-1].capitalize()\n",
    "    error_df = pd.read_csv(file)\n",
    "    full_hf_df = hf_df[file.split(\".csv\")[0].split(\"-\")[-1].capitalize()]\n",
    "    full_hf_df = full_hf_df.to_pandas()\n",
    "\n",
    "    # stem is in both\n",
    "    # dataset id is in both\n",
    "    # to see if the model got something wrong, see if the dataset id in the full df is in the error\n",
    "    error_ids = list(error_df[\"dataset_id\"])\n",
    "    correct = []\n",
    "    counts = []\n",
    "    relation_names = []\n",
    "    for row in full_hf_df.iterrows():\n",
    "        # track counts\n",
    "        count += 1\n",
    "        counts.append(count)\n",
    "        # track errors\n",
    "        correct.append(False) if row[1][\"dataset_id\"] in error_ids else correct.append(\n",
    "            True\n",
    "        )\n",
    "        # track relation titles\n",
    "        relation_id = int(row[1].relation[1:])\n",
    "        relation_title = list(wiki_data[wiki_data[\"ID\"] == relation_id][\"Title\"])[0]\n",
    "        relation_names.append(relation_title)\n",
    "\n",
    "    # append result to full df\n",
    "    full_hf_df[\"correct\"] = correct\n",
    "    # append language to full df\n",
    "    full_hf_df[\"language\"] = [language] * full_hf_df.shape[0]\n",
    "    # append language code to full df\n",
    "    lang_code = lang_to_code_dict[language]\n",
    "    full_hf_df[\"lang_code\"] = [lang_code] * full_hf_df.shape[0]\n",
    "    # append relation title to full df\n",
    "    full_hf_df[\"relation_title\"] = relation_names\n",
    "    # also append an arbitrary id to have unique val for each row\n",
    "    full_hf_df[\"analysis_id\"] = counts\n",
    "\n",
    "    results_dfs.append(full_hf_df)\n",
    "\n",
    "results_df = pd.concat(results_dfs)\n",
    "assert results_df.shape[0] == count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1d4896",
   "metadata": {
    "id": "ca1d4896"
   },
   "source": [
    "## More Cleanup to Ensure that we have access to Subjects across langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50e88e4",
   "metadata": {
    "id": "c50e88e4"
   },
   "outputs": [],
   "source": [
    "# mapping between dataset id and the english form of a subject\n",
    "dataset_id_to_eng_subject = {}\n",
    "for row in results_df.iterrows():\n",
    "    if row[1].language == \"English\":\n",
    "        if row[1].dataset_id not in dataset_id_to_eng_subject:\n",
    "            dataset_id_to_eng_subject[row[1].dataset_id] = row[1].subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87fa81f",
   "metadata": {
    "scrolled": true,
    "id": "f87fa81f"
   },
   "outputs": [],
   "source": [
    "entities = {}\n",
    "for row in results_df.iterrows():\n",
    "    # gather helpful row level data\n",
    "    # the subject\n",
    "    subject = row[1].subject\n",
    "    # whether the model got it right\n",
    "    val = row[1].correct\n",
    "    # the dataset id\n",
    "    dataset_id = row[1].dataset_id\n",
    "    # the english version of the subject\n",
    "    english_subject = dataset_id_to_eng_subject[dataset_id]\n",
    "\n",
    "    # commit it to our tracking dict\n",
    "    if english_subject not in entities:\n",
    "        entities[english_subject] = {\n",
    "            \"correct\": 0,\n",
    "            \"incorrect\": 0,\n",
    "            \"langs\": {},\n",
    "            \"alternate_forms\": {},\n",
    "            \"dataset_ids\": set(),\n",
    "        }\n",
    "\n",
    "    # counter of correct/incorrect for that subject\n",
    "    if val:\n",
    "        entities[english_subject][\"correct\"] += 1\n",
    "    else:\n",
    "        entities[english_subject][\"incorrect\"] += 1\n",
    "\n",
    "    # track language\n",
    "    lang = row[1].lang_code\n",
    "\n",
    "    if lang not in entities[english_subject][\"langs\"]:\n",
    "        entities[english_subject][\"langs\"][lang] = 1\n",
    "\n",
    "    else:\n",
    "        entities[english_subject][\"langs\"][lang] += 1\n",
    "\n",
    "    # track any alternate forms\n",
    "    entities[english_subject][\"alternate_forms\"][lang] = subject\n",
    "\n",
    "    entities[english_subject][\"dataset_ids\"].add(dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a28da3",
   "metadata": {
    "id": "a9a28da3"
   },
   "outputs": [],
   "source": [
    "entity_names = []\n",
    "correct = []\n",
    "incorrect = []\n",
    "total = []\n",
    "pct = []\n",
    "langs = []\n",
    "num_langs = []\n",
    "alternate_forms = []\n",
    "dataset_ids = []\n",
    "for k, v in entities.items():\n",
    "    entity_names.append(k)\n",
    "    # track # of times entity is used in a correct statement, incorrect, and pct accuracy\n",
    "    correct.append(v[\"correct\"])\n",
    "    incorrect.append(v[\"incorrect\"])\n",
    "    total.append(int(v[\"correct\"]) + int(v[\"incorrect\"]))\n",
    "    pct.append(int(v[\"correct\"]) / (int(v[\"correct\"]) + int(v[\"incorrect\"])))\n",
    "    # track # of languages the entity is used in\n",
    "    langs.append(v[\"langs\"])\n",
    "    num_langs.append(len(v[\"langs\"]))\n",
    "    alternate_forms.append(v[\"alternate_forms\"])\n",
    "    # track dataset ids its used in\n",
    "    dataset_ids.append(list(v[\"dataset_ids\"]))\n",
    "    # sanity check\n",
    "    assert int(v[\"correct\"]) + int(v[\"incorrect\"]) == sum(v[\"langs\"].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66e674e",
   "metadata": {
    "id": "c66e674e"
   },
   "outputs": [],
   "source": [
    "# the average entity appears in ~12 langs\n",
    "# (remember that this will max out at 20.)\n",
    "np.mean(num_langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ef444e",
   "metadata": {
    "id": "a9ef444e"
   },
   "outputs": [],
   "source": [
    "entity_analysis_df = pd.DataFrame(\n",
    "    {\n",
    "        \"entity\": entity_names,\n",
    "        \"num_correct\": correct,\n",
    "        \"num_incorrect\": incorrect,\n",
    "        \"total_usages\": total,\n",
    "        \"percent_accuracy\": pct,\n",
    "        \"languages\": langs,\n",
    "        \"num_languages\": num_langs,\n",
    "        \"alternate_forms\": alternate_forms,\n",
    "        \"dataset_ids\": dataset_ids,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d147cf25",
   "metadata": {
    "id": "d147cf25"
   },
   "source": [
    "## Usage Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38df8eb1",
   "metadata": {
    "id": "38df8eb1"
   },
   "outputs": [],
   "source": [
    "def get_lang_usage_report_for_entity(entity_val):\n",
    "    usage_dict = entity_analysis_df[entity_analysis_df[\"entity\"] == entity_val][\n",
    "        \"languages\"\n",
    "    ].values[0]\n",
    "\n",
    "    usage_dict = {\n",
    "        code_to_lang_dict[k]: {\"correct\": 0, \"incorrect\": 0}\n",
    "        for k, v in usage_dict.items()\n",
    "    }\n",
    "    # ok, how many of those usages are correct vs not?\n",
    "    dataset_ids = list(\n",
    "        entity_analysis_df[entity_analysis_df[\"entity\"] == entity_val][\"dataset_ids\"]\n",
    "    )[0]\n",
    "\n",
    "    for dataset_id in dataset_ids:\n",
    "        subset = results_df[results_df[\"dataset_id\"] == dataset_id]\n",
    "        for row in subset.iterrows():\n",
    "            lang_used = row[1].language\n",
    "            correct = row[1].correct\n",
    "\n",
    "            if correct:\n",
    "                usage_dict[lang_used][\"correct\"] += 1\n",
    "            else:\n",
    "                usage_dict[lang_used][\"incorrect\"] += 1\n",
    "\n",
    "    return usage_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5bc1cc",
   "metadata": {
    "id": "3b5bc1cc"
   },
   "outputs": [],
   "source": [
    "def get_percent_correct_from_usage_report(usage_report):\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    for l in usage_report.keys():\n",
    "        correct += usage_report[l][\"correct\"]\n",
    "        incorrect += usage_report[l][\"incorrect\"]\n",
    "    return np.round(correct / (correct + incorrect) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf66e1c7",
   "metadata": {
    "scrolled": true,
    "id": "cf66e1c7"
   },
   "outputs": [],
   "source": [
    "kerala_usage = get_lang_usage_report_for_entity(\"Kerala\")\n",
    "kerala_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c6c75b",
   "metadata": {
    "id": "87c6c75b"
   },
   "outputs": [],
   "source": [
    "get_percent_correct_from_usage_report(kerala_usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2161154a",
   "metadata": {
    "id": "2161154a"
   },
   "outputs": [],
   "source": [
    "def get_rows_by_entity(entity_val, outcome=False):\n",
    "    ids = list(\n",
    "        entity_analysis_df[entity_analysis_df[\"entity\"] == entity_val][\"dataset_ids\"]\n",
    "    )[0]\n",
    "    return results_df[\n",
    "        (results_df[\"dataset_id\"].isin(ids)) & (results_df[\"correct\"] == outcome)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c20b1b",
   "metadata": {
    "id": "e5c20b1b"
   },
   "outputs": [],
   "source": [
    "get_rows_by_entity(\"Kerala\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e059021c",
   "metadata": {
    "id": "e059021c"
   },
   "source": [
    "## Significance Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5284f46c",
   "metadata": {
    "id": "5284f46c"
   },
   "source": [
    "* use chi squared to see: \n",
    " \n",
    "    * if the number of correctly and incorrectly classified statements for each language scrip is statistically significant\n",
    "       * yes\n",
    "    * if the number of correctly and incorrectly classified statements for each language group is statistically significant\n",
    "        * yes\n",
    "        \n",
    "    * the number of correctly and incorrectly classified locations for western/eastern locales is statistically significant\n",
    "    * the number of correctly and incorrectly classified entities for women/men is statistically significant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338e2415",
   "metadata": {
    "id": "338e2415"
   },
   "source": [
    "### language groups and script\n",
    "\n",
    "Romance languages: Catalan, French, Italian, Portuguese, Romanian, Spanish\n",
    "Germanic languages: Danish, Dutch, German, Swedish\n",
    "Slavic languages: Bulgarian, Czech, Croatian, Polish, Russian, Serbian, Slovenian, Ukrainian\n",
    "Hungarian: a Uralic language, not related to any of the other languages in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe897b5",
   "metadata": {
    "id": "abe897b5"
   },
   "outputs": [],
   "source": [
    "# 2 x 2\n",
    "lang_to_script_dict = {\n",
    "    \"bg\": \"Cyrillic\",\n",
    "    \"ca\": \"Latin\",\n",
    "    \"cs\": \"Latin\",\n",
    "    \"da\": \"Latin\",\n",
    "    \"de\": \"Latin\",\n",
    "    \"en\": \"Latin\",\n",
    "    \"es\": \"Latin\",\n",
    "    \"fr\": \"Latin\",\n",
    "    \"hr\": \"Latin\",\n",
    "    \"hu\": \"Latin\",\n",
    "    \"it\": \"Latin\",\n",
    "    \"nl\": \"Latin\",\n",
    "    \"pl\": \"Latin\",\n",
    "    \"pt\": \"Latin\",\n",
    "    \"ro\": \"Latin\",\n",
    "    \"ru\": \"Cyrillic\",\n",
    "    \"sl\": \"Latin\",\n",
    "    \"sr\": \"Cyrillic\",\n",
    "    \"sv\": \"Latin\",\n",
    "    \"uk\": \"Cyrillic\",\n",
    "}\n",
    "\n",
    "# 2 x 4\n",
    "lang_to_group_dict = {\n",
    "    \"bg\": \"Slavic\",\n",
    "    \"ca\": \"Romance\",\n",
    "    \"cs\": \"Slavic\",\n",
    "    \"da\": \"Germanic\",\n",
    "    \"de\": \"Germanic\",\n",
    "    \"en\": \"Germanic\",\n",
    "    \"es\": \"Romance\",\n",
    "    \"fr\": \"Romance\",\n",
    "    \"hr\": \"Slavic\",\n",
    "    \"hu\": \"Uralic\",\n",
    "    \"it\": \"Romance\",\n",
    "    \"nl\": \"Germanic\",\n",
    "    \"pl\": \"Slavic\",\n",
    "    \"pt\": \"Romance\",\n",
    "    \"ro\": \"Romance\",\n",
    "    \"ru\": \"Slavic\",\n",
    "    \"sl\": \"Slavic\",\n",
    "    \"sr\": \"Slavic\",\n",
    "    \"sv\": \"Germanic\",\n",
    "    \"uk\": \"Slavic\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0f82c1",
   "metadata": {
    "id": "4f0f82c1"
   },
   "outputs": [],
   "source": [
    "# now, for each of these levels, we need:\n",
    "# number correct\n",
    "# number incorrect\n",
    "# total..\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e649516b",
   "metadata": {
    "id": "e649516b"
   },
   "outputs": [],
   "source": [
    "# scripts\n",
    "cyrillic = {\"correct\": 0, \"incorrect\": 0}\n",
    "latin = {\"correct\": 0, \"incorrect\": 0}\n",
    "\n",
    "# language groups\n",
    "germanic = {\"correct\": 0, \"incorrect\": 0}\n",
    "romance = {\"correct\": 0, \"incorrect\": 0}\n",
    "slavic = {\"correct\": 0, \"incorrect\": 0}\n",
    "uralic = {\"correct\": 0, \"incorrect\": 0}\n",
    "\n",
    "for row in results_df.iterrows():\n",
    "    lang_code = row[1].lang_code\n",
    "    result = row[1].correct\n",
    "    mapping = \"\"\n",
    "\n",
    "    script = lang_to_script_dict[lang_code]\n",
    "    group = lang_to_group_dict[lang_code]\n",
    "\n",
    "    if result:\n",
    "        mapping = \"correct\"\n",
    "    else:\n",
    "        mapping = \"incorrect\"\n",
    "\n",
    "    # language scripts\n",
    "    if script == \"Cyrillic\":\n",
    "        cyrillic[mapping] += 1\n",
    "    elif script == \"Latin\":\n",
    "        latin[mapping] += 1\n",
    "\n",
    "    # language groups\n",
    "    if group == \"Germanic\":\n",
    "        germanic[mapping] += 1\n",
    "    elif group == \"Romance\":\n",
    "        romance[mapping] += 1\n",
    "    elif group == \"Slavic\":\n",
    "        slavic[mapping] += 1\n",
    "    elif group == \"Uralic\":\n",
    "        uralic[mapping] += 1\n",
    "\n",
    "print(f\"cyrllic: {cyrillic}\")\n",
    "print(f\"latin: {latin}\")\n",
    "\n",
    "print(f\"germanic: {germanic}\")\n",
    "print(f\"romance: {romance}\")\n",
    "print(f\"slavic: {slavic}\")\n",
    "print(\n",
    "    f\"uralic: {uralic}\"\n",
    ")  # sanity check -> this is 75.7% correct which is the same as the llama graph result for HU.\n",
    "\n",
    "# sanity check identical output sizes\n",
    "assert sum(cyrillic.values()) + sum(latin.values()) == results_df.shape[0]\n",
    "assert (\n",
    "    sum(germanic.values())\n",
    "    + sum(romance.values())\n",
    "    + sum(slavic.values())\n",
    "    + sum(uralic.values())\n",
    "    == results_df.shape[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4114f0",
   "metadata": {
    "id": "3c4114f0"
   },
   "outputs": [],
   "source": [
    "def chi_squared(category_dicts, flag_one, flag_two, category_explainer):\n",
    "    table = []\n",
    "    top_vals = []\n",
    "    bottom_vals = []\n",
    "    for i in range(len(category_dicts)):\n",
    "        val = category_dicts[i][flag_one]\n",
    "        top_vals.append(category_dicts[i][flag_one])\n",
    "        bottom_vals.append(category_dicts[i][flag_two])\n",
    "\n",
    "    table = np.array([top_vals, bottom_vals])\n",
    "    # print(f\"contingency_table for {category_explainer}\\n(top row is # correct, bottom row is # incorrect)\\n{table}\")\n",
    "\n",
    "    stat, p, dof, expected = chi2_contingency(table)\n",
    "    reject = \"REJECT\" if p <= 0.05 else \"ACCEPT\"\n",
    "\n",
    "    if p < 0.001:\n",
    "        p = \"< .001\"\n",
    "\n",
    "    print(\n",
    "        f\"For {category_explainer}, we see a chi-squared value of {stat} and a p-value of {p}.\"\n",
    "    )\n",
    "    print(\n",
    "        f\"We can {reject} the null hypothesis that {category_explainer} is independent from performance on the CKA assessment.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fb4a1e",
   "metadata": {
    "id": "81fb4a1e"
   },
   "outputs": [],
   "source": [
    "chi_squared([cyrillic, latin], \"correct\", \"incorrect\", \"language script\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272561f9",
   "metadata": {
    "id": "272561f9"
   },
   "outputs": [],
   "source": [
    "chi_squared(\n",
    "    [germanic, romance, slavic, uralic], \"correct\", \"incorrect\", \"language family\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3559b4da",
   "metadata": {
    "id": "3559b4da"
   },
   "source": [
    "### Western vs Eastern locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cd2ef8",
   "metadata": {
    "id": "92cd2ef8"
   },
   "outputs": [],
   "source": [
    "# results_df[(results_df['relation'] == 'P127') & (results_df['lang_code'] == 'en')].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3e55b9",
   "metadata": {
    "id": "2e3e55b9"
   },
   "outputs": [],
   "source": [
    "geo_relations = {\n",
    "    \"capital\": \"P36\",\n",
    "    \"country\": \"P17\",\n",
    "    \"continent\": \"P30\",\n",
    "    \"capital of\": \"P1376\",\n",
    "    \"is in the administrative territorial entity\": \"P131\",\n",
    "    \"shares border with\": \"P47\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b92d14",
   "metadata": {
    "id": "d2b92d14"
   },
   "outputs": [],
   "source": [
    "geo_df = results_df[results_df[\"relation\"].isin(list(geo_relations.values()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa25c78",
   "metadata": {
    "id": "faa25c78"
   },
   "outputs": [],
   "source": [
    "geo_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c69041",
   "metadata": {
    "id": "83c69041"
   },
   "outputs": [],
   "source": [
    "c = 0\n",
    "geo_entities = {}\n",
    "for row in entity_analysis_df.iterrows():\n",
    "    dataset_ids = list(row[1].dataset_ids)\n",
    "    for d in dataset_ids:\n",
    "        if d in list(geo_df[\"dataset_id\"]):\n",
    "            entity = row[1].entity\n",
    "            if entity not in geo_entities:\n",
    "                geo_entities[row[1].entity] = [\n",
    "                    row[1].num_correct,\n",
    "                    row[1].num_incorrect,\n",
    "                    [d],\n",
    "                ]\n",
    "            else:\n",
    "                geo_entities[row[1].entity][2].append(d)\n",
    "\n",
    "    c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bd7a0d",
   "metadata": {
    "id": "d7bd7a0d"
   },
   "outputs": [],
   "source": [
    "len(geo_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb83828",
   "metadata": {
    "id": "1bb83828"
   },
   "outputs": [],
   "source": [
    "for k, v in geo_entities.items():\n",
    "    print(k, v)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def get_continent(place_name, user_agent=\"polyglot_sig_testing\"):\n",
    "    geolocator = Nominatim(user_agent=user_agent)\n",
    "    # first resolve a place name\n",
    "    location = geolocator.geocode(place_name, exactly_one=True)\n",
    "    if location is not None:\n",
    "        # and then get a more specific location in that place\n",
    "        latitude = location.latitude\n",
    "        longitude = location.longitude\n",
    "        # so we can then find a specific pin point address\n",
    "        location = geolocator.reverse((latitude, longitude))\n",
    "\n",
    "        if location is None:\n",
    "            print(f\"Could not find location via lat/long for {place_name}\")\n",
    "            return \"none\"\n",
    "        # pause bt api hits\n",
    "        time.sleep(1)\n",
    "        # that possesses a country code\n",
    "        country_alpha2 = location.raw[\"address\"][\"country_code\"]\n",
    "        if country_alpha2 is None or country_alpha2 == \"\":\n",
    "            print(f\"Could not find country code from location.raw for {place_name}.\")\n",
    "            return \"none\"\n",
    "\n",
    "        country_alpha2 = country_alpha2.upper()\n",
    "        if country_alpha2 == \"TL\":\n",
    "            return \"AF\"\n",
    "\n",
    "        continent_code = country_alpha2_to_continent_code(country_alpha2)\n",
    "        if continent_code is not None and continent_code != \"\":\n",
    "            return continent_code\n",
    "        else:\n",
    "            print(f\"Could not find continent using country_alpha2 for {place_name}.\")\n",
    "            return \"none\"\n",
    "    else:\n",
    "        print(f\"Could not find continent using geocode for {place_name}.\")\n",
    "        return \"none\""
   ],
   "metadata": {
    "id": "aV8O6-MNYWDS"
   },
   "id": "aV8O6-MNYWDS",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "geo_entity_container = {}\n",
    "c = 0\n",
    "\n",
    "for place_name in geo_entities.keys():\n",
    "    if (\n",
    "        \"Welford\" in place_name\n",
    "        or \"VTB\" in place_name\n",
    "        or \"Second French Empire\" in place_name\n",
    "        or place_name == \"Polish\"\n",
    "    ):\n",
    "        geo_entity_container[place_name] = \"none\"\n",
    "        continue\n",
    "    continent = get_continent(place_name)\n",
    "    geo_entity_container[place_name] = continent\n",
    "    if c % 100 == 0:\n",
    "        print(f\"done with iter {c}; just stored {place_name}:{continent}\")\n",
    "\n",
    "    c += 1"
   ],
   "metadata": {
    "id": "16dSAo9RaxZc"
   },
   "id": "16dSAo9RaxZc",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "geo_entity_container_two = {}\n",
    "c = 721\n",
    "black_list = [\n",
    "    \"Welford\",\n",
    "    \"VTB\",\n",
    "    \"Second French Empire\",\n",
    "    \"Polish\",\n",
    "    \"Leyden\",\n",
    "    \"Autonomous University\",\n",
    "    \"Iraklis\",\n",
    "]\n",
    "for i, place_name in enumerate(list(geo_entities.keys())):\n",
    "    if i < 721:\n",
    "        continue\n",
    "    for b in black_list:\n",
    "        if b in place_name:\n",
    "            geo_entity_container_two[place_name] = \"none\"\n",
    "            continue\n",
    "\n",
    "    continent = get_continent(place_name)\n",
    "    geo_entity_container_two[place_name] = continent\n",
    "    if c % 100 == 0:\n",
    "        print(f\"done with iter {c}; just stored {place_name}:{continent}\")\n",
    "\n",
    "    c += 1"
   ],
   "metadata": {
    "id": "sm8nSMknzE7b"
   },
   "id": "sm8nSMknzE7b",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# wrote out first 721.\n",
    "with open(\"geo_codes.json\", \"w\") as outfile:\n",
    "    json.dump(geo_entity_container, outfile)"
   ],
   "metadata": {
    "id": "Aj2v-eyVre2Z"
   },
   "id": "Aj2v-eyVre2Z",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(len(geo_entity_container))"
   ],
   "metadata": {
    "id": "NVwpHDR8y8R2"
   },
   "id": "NVwpHDR8y8R2",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "with open(\"geo_codes_two.json\", \"w\") as outfile:\n",
    "    json.dump(geo_entity_container_two, outfile)"
   ],
   "metadata": {
    "id": "IckaS4tFch5Q"
   },
   "id": "IckaS4tFch5Q",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}