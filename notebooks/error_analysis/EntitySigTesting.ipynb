{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94f71ad4",
   "metadata": {
    "id": "94f71ad4"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcc63c4d",
   "metadata": {
    "id": "fcc63c4d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa36919e",
   "metadata": {
    "id": "fa36919e"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ede8e4f",
   "metadata": {
    "id": "9ede8e4f"
   },
   "outputs": [],
   "source": [
    "wiki_data = pd.read_csv(\"../../data/wikidata/wikidata-property-list.csv\")\n",
    "wiki_data = wiki_data[[\"Title\", \"ID\", \"Datatype\", \"Description\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e1d4cb5",
   "metadata": {
    "id": "1e1d4cb5"
   },
   "outputs": [],
   "source": [
    "code_to_lang_dict = {\n",
    "    \"bg\": \"Bulgarian\",\n",
    "    \"ca\": \"Catalan\",\n",
    "    \"cs\": \"Czech\",\n",
    "    \"da\": \"Danish\",\n",
    "    \"de\": \"German\",\n",
    "    \"en\": \"English\",\n",
    "    \"es\": \"Spanish\",\n",
    "    \"fr\": \"French\",\n",
    "    \"hr\": \"Croatian\",\n",
    "    \"hu\": \"Hungarian\",\n",
    "    \"it\": \"Italian\",\n",
    "    \"nl\": \"Dutch\",\n",
    "    \"pl\": \"Polish\",\n",
    "    \"pt\": \"Portuguese\",\n",
    "    \"ro\": \"Romanian\",\n",
    "    \"ru\": \"Russian\",\n",
    "    \"sl\": \"Slovenian\",\n",
    "    \"sr\": \"Serbian\",\n",
    "    \"sv\": \"Swedish\",\n",
    "    \"uk\": \"Ukrainian\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89d61967",
   "metadata": {
    "id": "89d61967"
   },
   "outputs": [],
   "source": [
    "lang_to_code_dict = {v: k for k, v in code_to_lang_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4216b098",
   "metadata": {
    "id": "4216b098"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/Users/tim/.cache/huggingface/datasets/CalibraGPT___parquet/CalibraGPT--Fact-Completion-24a24a1e4bf6e4a8/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1161990b3e824e7fba7ec3c88b9b7fb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_dict = {}\n",
    "results_dict[\"language\"] = []\n",
    "results_dict[\"relation\"] = []\n",
    "results_dict[\"percentage change\"] = []\n",
    "results_dict[\"new ratio of rows\"] = []\n",
    "results_dict[\"old ratio of rows\"] = []\n",
    "\n",
    "hf_df = datasets.load_dataset(\"CalibraGPT/Fact-Completion\")\n",
    "file_names = glob.glob(\"../../data/result_logs/llama-30b/error-analysis/*.csv\")\n",
    "\n",
    "# confirm grabbing data correctly against LLaMa figure\n",
    "# uncomment print statement at end of for loop to see\n",
    "results_dfs = []\n",
    "count = 0\n",
    "for file in file_names:\n",
    "    language = file.split(\".csv\")[0].split(\"-\")[-1].capitalize()\n",
    "    error_df = pd.read_csv(file)\n",
    "    full_hf_df = hf_df[file.split(\".csv\")[0].split(\"-\")[-1].capitalize()]\n",
    "    full_hf_df = full_hf_df.to_pandas()\n",
    "\n",
    "    # stem is in both\n",
    "    # dataset id is in both\n",
    "    # to see if the model got something wrong, see if the dataset id in the full df is in the error\n",
    "    error_ids = list(error_df[\"dataset_id\"])\n",
    "    correct = []\n",
    "    counts = []\n",
    "    relation_names = []\n",
    "    for row in full_hf_df.iterrows():\n",
    "        # track counts\n",
    "        count += 1\n",
    "        counts.append(count)\n",
    "        # track errors\n",
    "        correct.append(False) if row[1][\"dataset_id\"] in error_ids else correct.append(\n",
    "            True\n",
    "        )\n",
    "        # track relation titles\n",
    "        relation_id = int(row[1].relation[1:])\n",
    "        relation_title = list(wiki_data[wiki_data[\"ID\"] == relation_id][\"Title\"])[0]\n",
    "        relation_names.append(relation_title)\n",
    "\n",
    "    # append result to full df\n",
    "    full_hf_df[\"correct\"] = correct\n",
    "    # append language to full df\n",
    "    full_hf_df[\"language\"] = [language] * full_hf_df.shape[0]\n",
    "    # append language code to full df\n",
    "    lang_code = lang_to_code_dict[language]\n",
    "    full_hf_df[\"lang_code\"] = [lang_code] * full_hf_df.shape[0]\n",
    "    # append relation title to full df\n",
    "    full_hf_df[\"relation_title\"] = relation_names\n",
    "    # also append an arbitrary id to have unique val for each row\n",
    "    full_hf_df[\"analysis_id\"] = counts\n",
    "\n",
    "    results_dfs.append(full_hf_df)\n",
    "\n",
    "results_df = pd.concat(results_dfs)\n",
    "assert results_df.shape[0] == count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1d4896",
   "metadata": {
    "id": "ca1d4896"
   },
   "source": [
    "## More Cleanup to Ensure that we have access to Subjects across langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c50e88e4",
   "metadata": {
    "id": "c50e88e4"
   },
   "outputs": [],
   "source": [
    "# mapping between dataset id and the english form of a subject\n",
    "dataset_id_to_eng_subject = {}\n",
    "for row in results_df.iterrows():\n",
    "    if row[1].language == \"English\":\n",
    "        if row[1].dataset_id not in dataset_id_to_eng_subject:\n",
    "            dataset_id_to_eng_subject[row[1].dataset_id] = row[1].subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f87fa81f",
   "metadata": {
    "id": "f87fa81f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "entities = {}\n",
    "for row in results_df.iterrows():\n",
    "    # gather helpful row level data\n",
    "    # the subject\n",
    "    subject = row[1].subject\n",
    "    # whether the model got it right\n",
    "    val = row[1].correct\n",
    "    # the dataset id\n",
    "    dataset_id = row[1].dataset_id\n",
    "    # the english version of the subject\n",
    "    english_subject = dataset_id_to_eng_subject[dataset_id]\n",
    "\n",
    "    # commit it to our tracking dict\n",
    "    if english_subject not in entities:\n",
    "        entities[english_subject] = {\n",
    "            \"correct\": 0,\n",
    "            \"incorrect\": 0,\n",
    "            \"langs\": {},\n",
    "            \"alternate_forms\": {},\n",
    "            \"dataset_ids\": set(),\n",
    "        }\n",
    "\n",
    "    # counter of correct/incorrect for that subject\n",
    "    if val:\n",
    "        entities[english_subject][\"correct\"] += 1\n",
    "    else:\n",
    "        entities[english_subject][\"incorrect\"] += 1\n",
    "\n",
    "    # track language\n",
    "    lang = row[1].lang_code\n",
    "\n",
    "    if lang not in entities[english_subject][\"langs\"]:\n",
    "        entities[english_subject][\"langs\"][lang] = 1\n",
    "\n",
    "    else:\n",
    "        entities[english_subject][\"langs\"][lang] += 1\n",
    "\n",
    "    # track any alternate forms\n",
    "    entities[english_subject][\"alternate_forms\"][lang] = subject\n",
    "\n",
    "    entities[english_subject][\"dataset_ids\"].add(dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9a28da3",
   "metadata": {
    "id": "a9a28da3"
   },
   "outputs": [],
   "source": [
    "entity_names = []\n",
    "correct = []\n",
    "incorrect = []\n",
    "total = []\n",
    "pct = []\n",
    "langs = []\n",
    "num_langs = []\n",
    "alternate_forms = []\n",
    "dataset_ids = []\n",
    "for k, v in entities.items():\n",
    "    entity_names.append(k)\n",
    "    # track # of times entity is used in a correct statement, incorrect, and pct accuracy\n",
    "    correct.append(v[\"correct\"])\n",
    "    incorrect.append(v[\"incorrect\"])\n",
    "    total.append(int(v[\"correct\"]) + int(v[\"incorrect\"]))\n",
    "    pct.append(int(v[\"correct\"]) / (int(v[\"correct\"]) + int(v[\"incorrect\"])))\n",
    "    # track # of languages the entity is used in\n",
    "    langs.append(v[\"langs\"])\n",
    "    num_langs.append(len(v[\"langs\"]))\n",
    "    alternate_forms.append(v[\"alternate_forms\"])\n",
    "    # track dataset ids its used in\n",
    "    dataset_ids.append(list(v[\"dataset_ids\"]))\n",
    "    # sanity check\n",
    "    assert int(v[\"correct\"]) + int(v[\"incorrect\"]) == sum(v[\"langs\"].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c66e674e",
   "metadata": {
    "id": "c66e674e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.867738745323988"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the average entity appears in ~12 langs\n",
    "# (remember that this will max out at 20.)\n",
    "np.mean(num_langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9ef444e",
   "metadata": {
    "id": "a9ef444e"
   },
   "outputs": [],
   "source": [
    "entity_analysis_df = pd.DataFrame(\n",
    "    {\n",
    "        \"entity\": entity_names,\n",
    "        \"num_correct\": correct,\n",
    "        \"num_incorrect\": incorrect,\n",
    "        \"total_usages\": total,\n",
    "        \"percent_accuracy\": pct,\n",
    "        \"languages\": langs,\n",
    "        \"num_languages\": num_langs,\n",
    "        \"alternate_forms\": alternate_forms,\n",
    "        \"dataset_ids\": dataset_ids,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f32d4291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.011757719194057775"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we don't see a strong trend of the model doing worse with entities as a function of how\n",
    "# many questions it receives about it\n",
    "# which is good because it implies its picks aren't haphazard\n",
    "entity_analysis_df['total_usages'].corr(entity_analysis_df['percent_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e059021c",
   "metadata": {
    "id": "e059021c"
   },
   "source": [
    "## Significance Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5284f46c",
   "metadata": {
    "id": "5284f46c"
   },
   "source": [
    "* use chi squared to see: \n",
    " \n",
    "    * if the number of correctly and incorrectly classified statements for each language scrip is statistically significant\n",
    "       * yes\n",
    "    * if the number of correctly and incorrectly classified statements for each language group is statistically significant\n",
    "        * yes\n",
    "        \n",
    "    * the number of correctly and incorrectly classified locations for western/eastern locales is statistically significant\n",
    "        * diff bt Europe vs Asia, yes (Asia performs better)\n",
    "        * diff bt Oceania vs Asia, yes (Asia performs better)\n",
    "        * diff bt Antarctic vs rest of world, yes (Ant. performs worse)\n",
    "        * diff bt South vs North America, yes (South America performs better)\n",
    "        * diff bt Europe + North America vs Asia, yes (Asia performs better\n",
    "    * the number of correctly and incorrectly classified entities for women/men is statistically significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3c4114f0",
   "metadata": {
    "id": "3c4114f0"
   },
   "outputs": [],
   "source": [
    "def chi_squared(category_dicts, flag_one, flag_two, category_explainer):\n",
    "    table = []\n",
    "    top_vals = []\n",
    "    bottom_vals = []\n",
    "    for i in range(len(category_dicts)):\n",
    "        val = category_dicts[i][flag_one]\n",
    "        top_vals.append(category_dicts[i][flag_one])\n",
    "        bottom_vals.append(category_dicts[i][flag_two])\n",
    "\n",
    "    table = np.array([top_vals, bottom_vals])\n",
    "    # print(f\"contingency_table for {category_explainer}\\n(top row is # correct, bottom row is # incorrect)\\n{table}\")\n",
    "\n",
    "    stat, p, dof, expected = chi2_contingency(table)\n",
    "    reject = \"REJECT\" if p <= 0.05 else \"ACCEPT\"\n",
    "\n",
    "    if p < 0.001:\n",
    "        p = \"< .001\"\n",
    "\n",
    "    print(\n",
    "        f\"For {category_explainer}, we see a chi-squared value of {stat} and a p-value of {p}.\"\n",
    "    )\n",
    "    print(\n",
    "        f\"We can {reject} the null hypothesis that {category_explainer} is independent from performance on the CKA assessment.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338e2415",
   "metadata": {
    "id": "338e2415"
   },
   "source": [
    "### language groups and script\n",
    "\n",
    "* Romance languages: Catalan, French, Italian, Portuguese, Romanian, Spanish\n",
    "* Germanic languages: Danish, Dutch, German, Swedish\n",
    "* Slavic languages: Bulgarian, Czech, Croatian, Polish, Russian, Serbian, Slovenian, Ukrainian\n",
    "* Hungarian: a Uralic language, not related to any of the other languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe897b5",
   "metadata": {
    "id": "abe897b5"
   },
   "outputs": [],
   "source": [
    "# 2 x 2\n",
    "lang_to_script_dict = {\n",
    "    \"bg\": \"Cyrillic\",\n",
    "    \"ca\": \"Latin\",\n",
    "    \"cs\": \"Latin\",\n",
    "    \"da\": \"Latin\",\n",
    "    \"de\": \"Latin\",\n",
    "    \"en\": \"Latin\",\n",
    "    \"es\": \"Latin\",\n",
    "    \"fr\": \"Latin\",\n",
    "    \"hr\": \"Latin\",\n",
    "    \"hu\": \"Latin\",\n",
    "    \"it\": \"Latin\",\n",
    "    \"nl\": \"Latin\",\n",
    "    \"pl\": \"Latin\",\n",
    "    \"pt\": \"Latin\",\n",
    "    \"ro\": \"Latin\",\n",
    "    \"ru\": \"Cyrillic\",\n",
    "    \"sl\": \"Latin\",\n",
    "    \"sr\": \"Cyrillic\",\n",
    "    \"sv\": \"Latin\",\n",
    "    \"uk\": \"Cyrillic\",\n",
    "}\n",
    "\n",
    "# 2 x 4\n",
    "lang_to_group_dict = {\n",
    "    \"bg\": \"Slavic\",\n",
    "    \"ca\": \"Romance\",\n",
    "    \"cs\": \"Slavic\",\n",
    "    \"da\": \"Germanic\",\n",
    "    \"de\": \"Germanic\",\n",
    "    \"en\": \"Germanic\",\n",
    "    \"es\": \"Romance\",\n",
    "    \"fr\": \"Romance\",\n",
    "    \"hr\": \"Slavic\",\n",
    "    \"hu\": \"Uralic\",\n",
    "    \"it\": \"Romance\",\n",
    "    \"nl\": \"Germanic\",\n",
    "    \"pl\": \"Slavic\",\n",
    "    \"pt\": \"Romance\",\n",
    "    \"ro\": \"Romance\",\n",
    "    \"ru\": \"Slavic\",\n",
    "    \"sl\": \"Slavic\",\n",
    "    \"sr\": \"Slavic\",\n",
    "    \"sv\": \"Germanic\",\n",
    "    \"uk\": \"Slavic\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0f82c1",
   "metadata": {
    "id": "4f0f82c1"
   },
   "outputs": [],
   "source": [
    "# now, for each of these levels, we need:\n",
    "# number correct\n",
    "# number incorrect\n",
    "# total..\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e649516b",
   "metadata": {
    "id": "e649516b"
   },
   "outputs": [],
   "source": [
    "# scripts\n",
    "cyrillic = {\"correct\": 0, \"incorrect\": 0}\n",
    "latin = {\"correct\": 0, \"incorrect\": 0}\n",
    "\n",
    "# language groups\n",
    "germanic = {\"correct\": 0, \"incorrect\": 0}\n",
    "romance = {\"correct\": 0, \"incorrect\": 0}\n",
    "slavic = {\"correct\": 0, \"incorrect\": 0}\n",
    "uralic = {\"correct\": 0, \"incorrect\": 0}\n",
    "\n",
    "for row in results_df.iterrows():\n",
    "    lang_code = row[1].lang_code\n",
    "    result = row[1].correct\n",
    "    mapping = \"\"\n",
    "\n",
    "    script = lang_to_script_dict[lang_code]\n",
    "    group = lang_to_group_dict[lang_code]\n",
    "\n",
    "    if result:\n",
    "        mapping = \"correct\"\n",
    "    else:\n",
    "        mapping = \"incorrect\"\n",
    "\n",
    "    # language scripts\n",
    "    if script == \"Cyrillic\":\n",
    "        cyrillic[mapping] += 1\n",
    "    elif script == \"Latin\":\n",
    "        latin[mapping] += 1\n",
    "\n",
    "    # language groups\n",
    "    if group == \"Germanic\":\n",
    "        germanic[mapping] += 1\n",
    "    elif group == \"Romance\":\n",
    "        romance[mapping] += 1\n",
    "    elif group == \"Slavic\":\n",
    "        slavic[mapping] += 1\n",
    "    elif group == \"Uralic\":\n",
    "        uralic[mapping] += 1\n",
    "\n",
    "print(f\"cyrllic: {cyrillic}\")\n",
    "print(f\"latin: {latin}\")\n",
    "\n",
    "print(f\"germanic: {germanic}\")\n",
    "print(f\"romance: {romance}\")\n",
    "print(f\"slavic: {slavic}\")\n",
    "print(\n",
    "    f\"uralic: {uralic}\"\n",
    ")  # sanity check -> this is 75.7% correct which is the same as the llama graph result for HU.\n",
    "\n",
    "# sanity check identical output sizes\n",
    "assert sum(cyrillic.values()) + sum(latin.values()) == results_df.shape[0]\n",
    "assert (\n",
    "    sum(germanic.values())\n",
    "    + sum(romance.values())\n",
    "    + sum(slavic.values())\n",
    "    + sum(uralic.values())\n",
    "    == results_df.shape[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fb4a1e",
   "metadata": {
    "id": "81fb4a1e"
   },
   "outputs": [],
   "source": [
    "chi_squared([cyrillic, latin], \"correct\", \"incorrect\", \"language script\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272561f9",
   "metadata": {
    "id": "272561f9"
   },
   "outputs": [],
   "source": [
    "chi_squared(\n",
    "    [germanic, romance, slavic, uralic], \"correct\", \"incorrect\", \"language family\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3559b4da",
   "metadata": {
    "id": "3559b4da"
   },
   "source": [
    "### Western vs Eastern locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09328a34",
   "metadata": {},
   "source": [
    "#### get geo entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e65a5c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_relations = {\n",
    "'capital': 'P36',\n",
    "'country': 'P17',\n",
    "'continent': 'P30',\n",
    "'capital of': 'P1376',\n",
    "'is in the administrative territorial entity': 'P131',\n",
    "'shares border with': 'P47'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4cdeb968",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df = results_df[results_df['relation'].isin(list(geo_relations.values()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7dbc1806",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_entities = {}\n",
    "for row in entity_analysis_df.iterrows():\n",
    "    dataset_ids = list(row[1].dataset_ids)\n",
    "    for d in dataset_ids:\n",
    "        if d in list(geo_df['dataset_id']):\n",
    "            entity = row[1].entity\n",
    "            if entity not in geo_entities:\n",
    "                geo_entities[row[1].entity] = [row[1].num_correct, row[1].num_incorrect, [d]]\n",
    "            else:\n",
    "                geo_entities[row[1].entity][2].append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e1b25c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3247"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(geo_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c069b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/wikidata/full_geo_entities.json\", \"w\") as outfile:\n",
    "    json.dump(geo_entities, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9440ab",
   "metadata": {},
   "source": [
    "#### read in 'tagged' geo entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eca9ded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_entities_tagged = pd.read_csv(\"../../data/wikidata/geo_entities_tagged.txt\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a8a39bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EU               995\n",
       "AS               629\n",
       "AN               586\n",
       "North America    583\n",
       "AF               213\n",
       "OC               129\n",
       "SA                78\n",
       "unsure            34\n",
       "Name: location, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_entities_tagged['location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c4fd21a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 1, ['rome_18230']]\n",
      "North America\n"
     ]
    }
   ],
   "source": [
    "# count accuracies, first, for EU vs. AS\n",
    "for k, v in geo_entities.items():\n",
    "    entity = k\n",
    "    entity_info = v\n",
    "    entity_location = geo_entities_tagged[geo_entities_tagged['entity'] == entity]['location']\n",
    "    \n",
    "    if entity_location.empty:\n",
    "        print(entity_info)\n",
    "        print(f\"Couldn't retrieve entity location for entity -- {entity}\")\n",
    "    entity_location = list(entity_location)[0]\n",
    "\n",
    "    entity_info.append(entity_location)\n",
    "    # print(f\"{entity} is located in {entity_location}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ad5e7f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# europe\n",
    "europe = {\"correct\": 0, \"incorrect\": 0}\n",
    "# asia\n",
    "asia = {\"correct\": 0, \"incorrect\": 0}\n",
    "# oceania\n",
    "oceania = {\"correct\": 0, \"incorrect\": 0}\n",
    "# north america\n",
    "north_america =  {\"correct\": 0, \"incorrect\": 0}\n",
    "# south america\n",
    "south_america = {\"correct\": 0, \"incorrect\": 0}\n",
    "# africa\n",
    "africa = {\"correct\": 0, \"incorrect\": 0}\n",
    "# antarctica\n",
    "antarctica = {\"correct\": 0, \"incorrect\": 0}\n",
    "for k, v in geo_entities.items():\n",
    "    entity = k\n",
    "    entity_info = v\n",
    "    \n",
    "    num_correct = entity_info[0]\n",
    "    num_incorrect = entity_info[1]\n",
    "    location = entity_info[3]\n",
    "    \n",
    "    if location == 'EU':\n",
    "        europe[\"correct\"] += num_correct\n",
    "        europe[\"incorrect\"] += num_incorrect\n",
    "    elif location == 'AS':\n",
    "        asia[\"correct\"] += num_correct\n",
    "        asia[\"incorrect\"] += num_incorrect\n",
    "    elif location == 'OC':\n",
    "        oceania[\"correct\"] += num_correct\n",
    "        oceania[\"incorrect\"] += num_incorrect\n",
    "    elif location == 'North America':\n",
    "        north_america[\"correct\"] += num_correct\n",
    "        north_america[\"incorrect\"] += num_incorrect\n",
    "    elif location == 'SA':\n",
    "        south_america[\"correct\"] += num_correct\n",
    "        south_america[\"incorrect\"] += num_incorrect\n",
    "    elif location == 'AF':\n",
    "        africa[\"correct\"] += num_correct\n",
    "        africa[\"incorrect\"] += num_incorrect\n",
    "    elif location == 'AN':\n",
    "        antarctica[\"correct\"] += num_correct\n",
    "        antarctica[\"incorrect\"] += num_incorrect\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fb978e",
   "metadata": {},
   "source": [
    "#### assess performance on CKA per continent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0412d61b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16201"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(europe.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "720fb929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9048824146657614"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "europe['correct']/sum(europe.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "228419f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10729"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(asia.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bd158cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9330785720943238"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asia['correct']/sum(asia.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b6ab6fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1761"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(oceania.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "67b830d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.889267461669506"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oceania['correct']/sum(oceania.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b9f0fed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8656"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(north_america.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fd0b1601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8925600739371534"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "north_america['correct']/sum(north_america.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c91d8637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1726"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(south_america.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "30206815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9159907300115875"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "south_america['correct']/sum(south_america.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "cb6ee87d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4366"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(africa.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dcac7276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9177737059092991"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "africa['correct']/sum(africa.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "24d17b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5167"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(antarctica.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f1f1ba47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8064640990903813"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "antarctica['correct']/sum(antarctica.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "16f0e9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rest of world vs. antarctica\n",
    "ds = [europe, asia, oceania, north_america, south_america, africa]\n",
    "rest_of_world = {}\n",
    "for k in [\"correct\", \"incorrect\"]:\n",
    "    rest_of_world[k] = sum(tuple(d[k] for d in ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d4f90f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'correct': 39551, 'incorrect': 3888}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest_of_world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d21321db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9104951771449619"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest_of_world['correct']/sum(rest_of_world.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b21150ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rest of north america + europe vs. asia\n",
    "ds = [europe, north_america]\n",
    "europe_and_na = {}\n",
    "for k in [\"correct\", \"incorrect\"]:\n",
    "    europe_and_na[k] = sum(tuple(d[k] for d in ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "77fc3595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'correct': 22386, 'incorrect': 2471}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "europe_and_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f3a6c20e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.900591382709096"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "europe_and_na['correct']/sum(europe_and_na.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c21a81d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall\n",
    "# rest of world vs. antarctica\n",
    "ds = [europe, asia, oceania, north_america, south_america, africa, antarctica]\n",
    "overall = {}\n",
    "for k in [\"correct\", \"incorrect\"]:\n",
    "    overall[k] = sum(tuple(d[k] for d in ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a2b4d514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48606"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many geo CKA questions were asked for our 3213 location-tagged entities\n",
    "sum(overall.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e58e6d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8994362835863885"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# overall CKA geo perf\n",
    "overall['correct']/sum(overall.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e97e8a4",
   "metadata": {},
   "source": [
    "#### run chi squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bcfb74db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For europe vs. asia geo entities, we see a chi-squared value of 66.40865439517813 and a p-value of < .001.\n",
      "We can REJECT the null hypothesis that europe vs. asia geo entities is independent from performance on the CKA assessment.\n"
     ]
    }
   ],
   "source": [
    "chi_squared(\n",
    "    [europe, asia], \"correct\", \"incorrect\", \"europe vs. asia geo entities\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bd1d2ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For antarctica vs. rest of world geo entities, we see a chi-squared value of 551.3639365665833 and a p-value of < .001.\n",
      "We can REJECT the null hypothesis that antarctica vs. rest of world geo entities is independent from performance on the CKA assessment.\n"
     ]
    }
   ],
   "source": [
    "chi_squared(\n",
    "    [antarctica, rest_of_world], \"correct\", \"incorrect\", \"antarctica vs. rest of world geo entities\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "35c5c06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For oceania vs. asia geo entities, we see a chi-squared value of 42.20897924571737 and a p-value of < .001.\n",
      "We can REJECT the null hypothesis that oceania vs. asia geo entities is independent from performance on the CKA assessment.\n"
     ]
    }
   ],
   "source": [
    "chi_squared(\n",
    "    [asia, oceania], \"correct\", \"incorrect\", \"oceania vs. asia geo entities\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "71f320e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For north vs. south america geo entities, we see a chi-squared value of 8.260629096452938 and a p-value of 0.004051408610312914.\n",
      "We can REJECT the null hypothesis that north vs. south america geo entities is independent from performance on the CKA assessment.\n"
     ]
    }
   ],
   "source": [
    "chi_squared(\n",
    "    [north_america, south_america], \"correct\", \"incorrect\", \"north vs. south america geo entities\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "af4abb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For europe and na vs. asia, we see a chi-squared value of 96.55315610667571 and a p-value of < .001.\n",
      "We can REJECT the null hypothesis that europe and na vs. asia is independent from performance on the CKA assessment.\n"
     ]
    }
   ],
   "source": [
    "chi_squared(\n",
    "    [europe_and_na, asia], \"correct\", \"incorrect\", \"europe and na vs. asia\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f9ac14",
   "metadata": {},
   "source": [
    "### Male vs Female names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b8d01a",
   "metadata": {},
   "source": [
    "#### get people entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdfef11",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_relations = {'P20': 'place of death',\n",
    "'P1303': 'instrument',\n",
    "'P108': 'employer',\n",
    "'P103': 'native language',\n",
    "'P39': 'position held',\n",
    "'P413': 'position played on team',\n",
    "'P937': 'work location',\n",
    "'P641': 'sport',\n",
    "'P106': 'occupation',\n",
    "'P101': 'field of work'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04e9fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_df = results_df[results_df['relation'].isin(list(people_relations.keys()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dffa8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_entities = {}\n",
    "for row in entity_analysis_df.iterrows():\n",
    "    dataset_ids = list(row[1].dataset_ids)\n",
    "    for d in dataset_ids:\n",
    "        if d in list(people_df['dataset_id']):\n",
    "            entity = row[1].entity\n",
    "            if entity not in people_entities:\n",
    "                people_entities[row[1].entity] = [row[1].num_correct, row[1].num_incorrect, [d]]\n",
    "            else:\n",
    "                people_entities[row[1].entity][2].append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f346b41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(people_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9e46b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/wikidata/full_people_entities.json\", \"w\") as outfile:\n",
    "    json.dump(people_entities, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea44f2f",
   "metadata": {},
   "source": [
    "#### read in 'tagged' people entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6057d1e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
