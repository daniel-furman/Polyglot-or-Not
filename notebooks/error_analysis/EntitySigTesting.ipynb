{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94f71ad4",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcc63c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa36919e",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ede8e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_data = pd.read_csv(\"../../data/wikidata/wikidata-property-list.csv\")\n",
    "wiki_data = wiki_data[[\"Title\", \"ID\", \"Datatype\", \"Description\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e1d4cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_to_lang_dict = {\n",
    "    \"bg\": \"Bulgarian\",\n",
    "    \"ca\": \"Catalan\",\n",
    "    \"cs\": \"Czech\",\n",
    "    \"da\": \"Danish\",\n",
    "    \"de\": \"German\",\n",
    "    \"en\": \"English\",\n",
    "    \"es\": \"Spanish\",\n",
    "    \"fr\": \"French\",\n",
    "    \"hr\": \"Croatian\",\n",
    "    \"hu\": \"Hungarian\",\n",
    "    \"it\": \"Italian\",\n",
    "    \"nl\": \"Dutch\",\n",
    "    \"pl\": \"Polish\",\n",
    "    \"pt\": \"Portuguese\",\n",
    "    \"ro\": \"Romanian\",\n",
    "    \"ru\": \"Russian\",\n",
    "    \"sl\": \"Slovenian\",\n",
    "    \"sr\": \"Serbian\",\n",
    "    \"sv\": \"Swedish\",\n",
    "    \"uk\": \"Ukrainian\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89d61967",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_to_code_dict = {v: k for k, v in code_to_lang_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4216b098",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/Users/tim/.cache/huggingface/datasets/CalibraGPT___parquet/CalibraGPT--Fact-Completion-24a24a1e4bf6e4a8/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf4b5378322a4393a14d37e9179c76d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_dict = {}\n",
    "results_dict[\"language\"] = []\n",
    "results_dict[\"relation\"] = []\n",
    "results_dict[\"percentage change\"] = []\n",
    "results_dict[\"new ratio of rows\"] = []\n",
    "results_dict[\"old ratio of rows\"] = []\n",
    "\n",
    "hf_df = datasets.load_dataset(\"CalibraGPT/Fact-Completion\")\n",
    "file_names = glob.glob(\"../../data/result_logs/llama-30b/error-analysis/*.csv\")\n",
    "\n",
    "# confirm grabbing data correctly against LLaMa figure\n",
    "# uncomment print statement at end of for loop to see\n",
    "results_dfs = []\n",
    "count = 0\n",
    "for file in file_names:\n",
    "    language = file.split(\".csv\")[0].split(\"-\")[-1].capitalize()\n",
    "    error_df = pd.read_csv(file)\n",
    "    full_hf_df = hf_df[file.split(\".csv\")[0].split(\"-\")[-1].capitalize()]\n",
    "    full_hf_df = full_hf_df.to_pandas()\n",
    "\n",
    "    # stem is in both\n",
    "    # dataset id is in both\n",
    "    # to see if the model got something wrong, see if the dataset id in the full df is in the error\n",
    "    error_ids = list(error_df[\"dataset_id\"])\n",
    "    correct = []\n",
    "    counts = []\n",
    "    relation_names = []\n",
    "    for row in full_hf_df.iterrows():\n",
    "        # track counts\n",
    "        count += 1\n",
    "        counts.append(count)\n",
    "        # track errors\n",
    "        correct.append(False) if row[1][\"dataset_id\"] in error_ids else correct.append(\n",
    "            True\n",
    "        )\n",
    "        # track relation titles\n",
    "        relation_id = int(row[1].relation[1:])\n",
    "        relation_title = list(wiki_data[wiki_data[\"ID\"] == relation_id][\"Title\"])[0]\n",
    "        relation_names.append(relation_title)\n",
    "\n",
    "    # append result to full df\n",
    "    full_hf_df[\"correct\"] = correct\n",
    "    # append language to full df\n",
    "    full_hf_df[\"language\"] = [language] * full_hf_df.shape[0]\n",
    "    # append language code to full df\n",
    "    lang_code = lang_to_code_dict[language]\n",
    "    full_hf_df[\"lang_code\"] = [lang_code] * full_hf_df.shape[0]\n",
    "    # append relation title to full df\n",
    "    full_hf_df[\"relation_title\"] = relation_names\n",
    "    # also append an arbitrary id to have unique val for each row\n",
    "    full_hf_df[\"analysis_id\"] = counts\n",
    "\n",
    "    results_dfs.append(full_hf_df)\n",
    "\n",
    "results_df = pd.concat(results_dfs)\n",
    "assert results_df.shape[0] == count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1d4896",
   "metadata": {},
   "source": [
    "## More Cleanup to Ensure that we have access to Subjects across langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c50e88e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping between dataset id and the english form of a subject\n",
    "dataset_id_to_eng_subject = {}\n",
    "for row in results_df.iterrows():\n",
    "    if row[1].language == \"English\":\n",
    "        if row[1].dataset_id not in dataset_id_to_eng_subject:\n",
    "            dataset_id_to_eng_subject[row[1].dataset_id] = row[1].subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfa0b6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Megan Rapinoe'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put in an id and get the english subject back\n",
    "dataset_id_to_eng_subject[\"rome_21844\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f87fa81f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "entities = {}\n",
    "for row in results_df.iterrows():\n",
    "    # gather helpful row level data\n",
    "    # the subject\n",
    "    subject = row[1].subject\n",
    "    # whether the model got it right\n",
    "    val = row[1].correct\n",
    "    # the dataset id\n",
    "    dataset_id = row[1].dataset_id\n",
    "    # the english version of the subject\n",
    "    english_subject = dataset_id_to_eng_subject[dataset_id]\n",
    "\n",
    "    # commit it to our tracking dict\n",
    "    if english_subject not in entities:\n",
    "        entities[english_subject] = {\n",
    "            \"correct\": 0,\n",
    "            \"incorrect\": 0,\n",
    "            \"langs\": {},\n",
    "            \"alternate_forms\": {},\n",
    "            \"dataset_ids\": set(),\n",
    "        }\n",
    "\n",
    "    # counter of correct/incorrect for that subject\n",
    "    if val:\n",
    "        entities[english_subject][\"correct\"] += 1\n",
    "    else:\n",
    "        entities[english_subject][\"incorrect\"] += 1\n",
    "\n",
    "    # track language\n",
    "    lang = row[1].lang_code\n",
    "\n",
    "    if lang not in entities[english_subject][\"langs\"]:\n",
    "        entities[english_subject][\"langs\"][lang] = 1\n",
    "\n",
    "    else:\n",
    "        entities[english_subject][\"langs\"][lang] += 1\n",
    "\n",
    "    # track any alternate forms\n",
    "    entities[english_subject][\"alternate_forms\"][lang] = subject\n",
    "\n",
    "    entities[english_subject][\"dataset_ids\"].add(dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9a28da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_names = []\n",
    "correct = []\n",
    "incorrect = []\n",
    "total = []\n",
    "pct = []\n",
    "langs = []\n",
    "num_langs = []\n",
    "alternate_forms = []\n",
    "dataset_ids = []\n",
    "for k, v in entities.items():\n",
    "    entity_names.append(k)\n",
    "    # track # of times entity is used in a correct statement, incorrect, and pct accuracy\n",
    "    correct.append(v[\"correct\"])\n",
    "    incorrect.append(v[\"incorrect\"])\n",
    "    total.append(int(v[\"correct\"]) + int(v[\"incorrect\"]))\n",
    "    pct.append(int(v[\"correct\"]) / (int(v[\"correct\"]) + int(v[\"incorrect\"])))\n",
    "    # track # of languages the entity is used in\n",
    "    langs.append(v[\"langs\"])\n",
    "    num_langs.append(len(v[\"langs\"]))\n",
    "    alternate_forms.append(v[\"alternate_forms\"])\n",
    "    # track dataset ids its used in\n",
    "    dataset_ids.append(list(v[\"dataset_ids\"]))\n",
    "    # sanity check\n",
    "    assert int(v[\"correct\"]) + int(v[\"incorrect\"]) == sum(v[\"langs\"].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c66e674e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.867738745323988"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the average entity appears in ~12 langs\n",
    "# (remember that this will max out at 20.)\n",
    "np.mean(num_langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9ef444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_analysis_df = pd.DataFrame(\n",
    "    {\n",
    "        \"entity\": entity_names,\n",
    "        \"num_correct\": correct,\n",
    "        \"num_incorrect\": incorrect,\n",
    "        \"total_usages\": total,\n",
    "        \"percent_accuracy\": pct,\n",
    "        \"languages\": langs,\n",
    "        \"num_languages\": num_langs,\n",
    "        \"alternate_forms\": alternate_forms,\n",
    "        \"dataset_ids\": dataset_ids,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a575e20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_analysis_df.to_json(\n",
    "    \"../../data/error_analysis/entity_analysis_language_and_accuracy_by_entity.json\",\n",
    "    orient=\"index\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d147cf25",
   "metadata": {},
   "source": [
    "## Usage Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38df8eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lang_usage_report_for_entity(entity_val):\n",
    "    usage_dict = entity_analysis_df[entity_analysis_df[\"entity\"] == entity_val][\n",
    "        \"languages\"\n",
    "    ].values[0]\n",
    "\n",
    "    usage_dict = {\n",
    "        code_to_lang_dict[k]: {\"correct\": 0, \"incorrect\": 0}\n",
    "        for k, v in usage_dict.items()\n",
    "    }\n",
    "    # ok, how many of those usages are correct vs not?\n",
    "    dataset_ids = list(\n",
    "        entity_analysis_df[entity_analysis_df[\"entity\"] == entity_val][\"dataset_ids\"]\n",
    "    )[0]\n",
    "\n",
    "    for dataset_id in dataset_ids:\n",
    "        subset = results_df[results_df[\"dataset_id\"] == dataset_id]\n",
    "        for row in subset.iterrows():\n",
    "            lang_used = row[1].language\n",
    "            correct = row[1].correct\n",
    "\n",
    "            if correct:\n",
    "                usage_dict[lang_used][\"correct\"] += 1\n",
    "            else:\n",
    "                usage_dict[lang_used][\"incorrect\"] += 1\n",
    "\n",
    "    return usage_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b5bc1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_percent_correct_from_usage_report(usage_report):\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    for l in usage_report.keys():\n",
    "        correct += usage_report[l][\"correct\"]\n",
    "        incorrect += usage_report[l][\"incorrect\"]\n",
    "    return np.round(correct / (correct + incorrect) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf66e1c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Serbian': {'correct': 1, 'incorrect': 0},\n",
       " 'Ukrainian': {'correct': 3, 'incorrect': 0},\n",
       " 'Dutch': {'correct': 5, 'incorrect': 1},\n",
       " 'Swedish': {'correct': 4, 'incorrect': 0},\n",
       " 'Catalan': {'correct': 5, 'incorrect': 1},\n",
       " 'Polish': {'correct': 3, 'incorrect': 0},\n",
       " 'Bulgarian': {'correct': 5, 'incorrect': 0},\n",
       " 'Slovenian': {'correct': 2, 'incorrect': 0},\n",
       " 'English': {'correct': 6, 'incorrect': 0},\n",
       " 'German': {'correct': 6, 'incorrect': 0},\n",
       " 'Portuguese': {'correct': 6, 'incorrect': 0},\n",
       " 'Czech': {'correct': 3, 'incorrect': 0},\n",
       " 'Spanish': {'correct': 3, 'incorrect': 1},\n",
       " 'Croatian': {'correct': 1, 'incorrect': 0},\n",
       " 'Danish': {'correct': 6, 'incorrect': 0},\n",
       " 'French': {'correct': 5, 'incorrect': 0},\n",
       " 'Italian': {'correct': 5, 'incorrect': 0},\n",
       " 'Romanian': {'correct': 5, 'incorrect': 0}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kerala_usage = get_lang_usage_report_for_entity(\"Kerala\")\n",
    "kerala_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87c6c75b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_percent_correct_from_usage_report(kerala_usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2161154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rows_by_entity(entity_val, outcome=False):\n",
    "    ids = list(\n",
    "        entity_analysis_df[entity_analysis_df[\"entity\"] == entity_val][\"dataset_ids\"]\n",
    "    )[0]\n",
    "    return results_df[\n",
    "        (results_df[\"dataset_id\"].isin(ids)) & (results_df[\"correct\"] == outcome)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5c20b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>stem</th>\n",
       "      <th>true</th>\n",
       "      <th>false</th>\n",
       "      <th>relation</th>\n",
       "      <th>subject</th>\n",
       "      <th>object</th>\n",
       "      <th>correct</th>\n",
       "      <th>language</th>\n",
       "      <th>lang_code</th>\n",
       "      <th>relation_title</th>\n",
       "      <th>analysis_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11211</th>\n",
       "      <td>rome_16815</td>\n",
       "      <td>In Kerala verstaan ​​ze &lt;br&gt; In Kerala begrijp...</td>\n",
       "      <td>Engels</td>\n",
       "      <td>Fins</td>\n",
       "      <td>P37</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>Engels</td>\n",
       "      <td>False</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>nl</td>\n",
       "      <td>official language</td>\n",
       "      <td>24556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9395</th>\n",
       "      <td>rome_16815</td>\n",
       "      <td>A Kerala, entenen &lt;br&gt; A Kerala, entenen el</td>\n",
       "      <td>Anglès</td>\n",
       "      <td>finès</td>\n",
       "      <td>P37</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>Anglès</td>\n",
       "      <td>False</td>\n",
       "      <td>Catalan</td>\n",
       "      <td>ca</td>\n",
       "      <td>official language</td>\n",
       "      <td>71556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9320</th>\n",
       "      <td>rome_16815</td>\n",
       "      <td>En Kerala entienden</td>\n",
       "      <td>Inglés</td>\n",
       "      <td>finlandés</td>\n",
       "      <td>P37</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>Inglés</td>\n",
       "      <td>False</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>es</td>\n",
       "      <td>official language</td>\n",
       "      <td>206544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dataset_id                                               stem    true  \\\n",
       "11211  rome_16815  In Kerala verstaan ​​ze <br> In Kerala begrijp...  Engels   \n",
       "9395   rome_16815        A Kerala, entenen <br> A Kerala, entenen el  Anglès   \n",
       "9320   rome_16815                                En Kerala entienden  Inglés   \n",
       "\n",
       "           false relation subject  object  correct language lang_code  \\\n",
       "11211       Fins      P37  Kerala  Engels    False    Dutch        nl   \n",
       "9395       finès      P37  Kerala  Anglès    False  Catalan        ca   \n",
       "9320   finlandés      P37  Kerala  Inglés    False  Spanish        es   \n",
       "\n",
       "          relation_title  analysis_id  \n",
       "11211  official language        24556  \n",
       "9395   official language        71556  \n",
       "9320   official language       206544  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rows_by_entity(\"Kerala\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e059021c",
   "metadata": {},
   "source": [
    "## Significance Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5284f46c",
   "metadata": {},
   "source": [
    "* use chi squared to see: \n",
    " \n",
    "    * if the number of correctly and incorrectly classified statements for each language scrip is statistically significant\n",
    "       * yes\n",
    "    * if the number of correctly and incorrectly classified statements for each language group is statistically significant\n",
    "        * yes\n",
    "        \n",
    "    * the number of correctly and incorrectly classified locations for western/eastern locales is statistically significant\n",
    "    * the number of correctly and incorrectly classified entities for women/men is statistically significant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338e2415",
   "metadata": {},
   "source": [
    "### language groups and script\n",
    "\n",
    "Romance languages: Catalan, French, Italian, Portuguese, Romanian, Spanish\n",
    "Germanic languages: Danish, Dutch, German, Swedish\n",
    "Slavic languages: Bulgarian, Czech, Croatian, Polish, Russian, Serbian, Slovenian, Ukrainian\n",
    "Hungarian: a Uralic language, not related to any of the other languages in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abe897b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 x 2\n",
    "lang_to_script_dict = {\n",
    "    \"bg\": \"Cyrillic\",\n",
    "    \"ca\": \"Latin\",\n",
    "    \"cs\": \"Latin\",\n",
    "    \"da\": \"Latin\",\n",
    "    \"de\": \"Latin\",\n",
    "    \"en\": \"Latin\",\n",
    "    \"es\": \"Latin\",\n",
    "    \"fr\": \"Latin\",\n",
    "    \"hr\": \"Latin\",\n",
    "    \"hu\": \"Latin\",\n",
    "    \"it\": \"Latin\",\n",
    "    \"nl\": \"Latin\",\n",
    "    \"pl\": \"Latin\",\n",
    "    \"pt\": \"Latin\",\n",
    "    \"ro\": \"Latin\",\n",
    "    \"ru\": \"Cyrillic\",\n",
    "    \"sl\": \"Latin\",\n",
    "    \"sr\": \"Cyrillic\",\n",
    "    \"sv\": \"Latin\",\n",
    "    \"uk\": \"Cyrillic\",\n",
    "}\n",
    "\n",
    "# 2 x 4\n",
    "lang_to_group_dict = {\n",
    "    \"bg\": \"Slavic\",\n",
    "    \"ca\": \"Romance\",\n",
    "    \"cs\": \"Slavic\",\n",
    "    \"da\": \"Germanic\",\n",
    "    \"de\": \"Germanic\",\n",
    "    \"en\": \"Germanic\",\n",
    "    \"es\": \"Romance\",\n",
    "    \"fr\": \"Romance\",\n",
    "    \"hr\": \"Slavic\",\n",
    "    \"hu\": \"Uralic\",\n",
    "    \"it\": \"Romance\",\n",
    "    \"nl\": \"Germanic\",\n",
    "    \"pl\": \"Slavic\",\n",
    "    \"pt\": \"Romance\",\n",
    "    \"ro\": \"Romance\",\n",
    "    \"ru\": \"Slavic\",\n",
    "    \"sl\": \"Slavic\",\n",
    "    \"sr\": \"Slavic\",\n",
    "    \"sv\": \"Germanic\",\n",
    "    \"uk\": \"Slavic\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f0f82c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>stem</th>\n",
       "      <th>true</th>\n",
       "      <th>false</th>\n",
       "      <th>relation</th>\n",
       "      <th>subject</th>\n",
       "      <th>object</th>\n",
       "      <th>correct</th>\n",
       "      <th>language</th>\n",
       "      <th>lang_code</th>\n",
       "      <th>relation_title</th>\n",
       "      <th>analysis_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>calinet_8922</td>\n",
       "      <td>Приус производи</td>\n",
       "      <td>Тоиота</td>\n",
       "      <td>Хонда</td>\n",
       "      <td>P176</td>\n",
       "      <td>Приус</td>\n",
       "      <td>Тоиота</td>\n",
       "      <td>True</td>\n",
       "      <td>Serbian</td>\n",
       "      <td>sr</td>\n",
       "      <td>manufacturer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rome_5025</td>\n",
       "      <td>Сундар Пицхаи ради за</td>\n",
       "      <td>Гоогле</td>\n",
       "      <td>Аппле</td>\n",
       "      <td>P108</td>\n",
       "      <td>Сундар Пицхаи</td>\n",
       "      <td>Гоогле</td>\n",
       "      <td>False</td>\n",
       "      <td>Serbian</td>\n",
       "      <td>sr</td>\n",
       "      <td>employer</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rome_21333</td>\n",
       "      <td>Главни град Народне Републике Кине,</td>\n",
       "      <td>Пекинг</td>\n",
       "      <td>Кабул</td>\n",
       "      <td>P36</td>\n",
       "      <td>Народна Република Кина</td>\n",
       "      <td>Пекинг</td>\n",
       "      <td>True</td>\n",
       "      <td>Serbian</td>\n",
       "      <td>sr</td>\n",
       "      <td>capital</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rome_8738</td>\n",
       "      <td>У Синт Мартену разумеју</td>\n",
       "      <td>холандски</td>\n",
       "      <td>дански</td>\n",
       "      <td>P37</td>\n",
       "      <td>Синт Маартен</td>\n",
       "      <td>холандски</td>\n",
       "      <td>True</td>\n",
       "      <td>Serbian</td>\n",
       "      <td>sr</td>\n",
       "      <td>official language</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rome_8783</td>\n",
       "      <td>Хаас Хоусе се налази у месту</td>\n",
       "      <td>Беч</td>\n",
       "      <td>Алберта</td>\n",
       "      <td>P131</td>\n",
       "      <td>Хаас Хоусе</td>\n",
       "      <td>Беч</td>\n",
       "      <td>True</td>\n",
       "      <td>Serbian</td>\n",
       "      <td>sr</td>\n",
       "      <td>is in the administrative territorial entity</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dataset_id                                 stem       true    false  \\\n",
       "0  calinet_8922                      Приус производи     Тоиота    Хонда   \n",
       "1     rome_5025                Сундар Пицхаи ради за     Гоогле    Аппле   \n",
       "2    rome_21333  Главни град Народне Републике Кине,     Пекинг    Кабул   \n",
       "3     rome_8738              У Синт Мартену разумеју  холандски   дански   \n",
       "4     rome_8783         Хаас Хоусе се налази у месту        Беч  Алберта   \n",
       "\n",
       "  relation                 subject     object  correct language lang_code  \\\n",
       "0     P176                   Приус     Тоиота     True  Serbian        sr   \n",
       "1     P108           Сундар Пицхаи     Гоогле    False  Serbian        sr   \n",
       "2      P36  Народна Република Кина     Пекинг     True  Serbian        sr   \n",
       "3      P37            Синт Маартен  холандски     True  Serbian        sr   \n",
       "4     P131              Хаас Хоусе        Беч     True  Serbian        sr   \n",
       "\n",
       "                                relation_title  analysis_id  \n",
       "0                                 manufacturer            1  \n",
       "1                                     employer            2  \n",
       "2                                      capital            3  \n",
       "3                            official language            4  \n",
       "4  is in the administrative territorial entity            5  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now, for each of these levels, we need:\n",
    "# number correct\n",
    "# number incorrect\n",
    "# total..\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e649516b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cyrllic: {'correct': 26248, 'incorrect': 10962}\n",
      "latin: {'correct': 221567, 'incorrect': 44366}\n",
      "germanic: {'correct': 93963, 'incorrect': 16109}\n",
      "romance: {'correct': 97762, 'incorrect': 19307}\n",
      "slavic: {'correct': 52568, 'incorrect': 18784}\n",
      "uralic: {'correct': 3522, 'incorrect': 1128}\n"
     ]
    }
   ],
   "source": [
    "# scripts\n",
    "cyrillic = {'correct': 0, 'incorrect': 0}\n",
    "latin = {'correct': 0, 'incorrect': 0}\n",
    "\n",
    "# language groups\n",
    "germanic = {'correct': 0, 'incorrect': 0}\n",
    "romance = {'correct': 0, 'incorrect': 0}\n",
    "slavic = {'correct': 0, 'incorrect': 0}\n",
    "uralic = {'correct': 0, 'incorrect': 0}\n",
    "\n",
    "for row in results_df.iterrows():\n",
    "        \n",
    "    lang_code = row[1].lang_code\n",
    "    result = row[1].correct\n",
    "    mapping = ''\n",
    "    \n",
    "    script = lang_to_script_dict[lang_code]\n",
    "    group = lang_to_group_dict[lang_code]\n",
    "    \n",
    "    if result:\n",
    "        mapping = 'correct'\n",
    "    else:\n",
    "        mapping = 'incorrect'\n",
    "    \n",
    "    # language scripts\n",
    "    if script == 'Cyrillic':\n",
    "        cyrillic[mapping] +=1\n",
    "    elif script == 'Latin':\n",
    "        latin[mapping] +=1\n",
    "        \n",
    "    # language groups\n",
    "    if group == 'Germanic':\n",
    "        germanic[mapping] +=1\n",
    "    elif group == 'Romance':\n",
    "        romance[mapping] +=1\n",
    "    elif group == 'Slavic':\n",
    "        slavic[mapping] +=1\n",
    "    elif group == 'Uralic':\n",
    "        uralic[mapping] +=1\n",
    "    \n",
    "print(f\"cyrllic: {cyrillic}\")\n",
    "print(f\"latin: {latin}\")\n",
    "\n",
    "print(f\"germanic: {germanic}\")\n",
    "print(f\"romance: {romance}\")\n",
    "print(f\"slavic: {slavic}\")\n",
    "print(f\"uralic: {uralic}\") # sanity check -> this is 75.7% correct which is the same as the llama graph result for HU.\n",
    "\n",
    "# sanity check identical output sizes\n",
    "assert(sum(cyrillic.values()) + sum(latin.values()) == results_df.shape[0])\n",
    "assert(sum(germanic.values()) + sum(romance.values()) + sum(slavic.values()) + sum(uralic.values()) == results_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3c4114f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_squared(category_dicts, flag_one, flag_two, category_explainer):\n",
    "    \n",
    "    table = []\n",
    "    top_vals = []\n",
    "    bottom_vals = []\n",
    "    for i in range(len(category_dicts)):\n",
    "        val = category_dicts[i][flag_one]\n",
    "        top_vals.append(category_dicts[i][flag_one])\n",
    "        bottom_vals.append(category_dicts[i][flag_two])\n",
    "    \n",
    "    table = np.array([top_vals, bottom_vals])\n",
    "    # print(f\"contingency_table for {category_explainer}\\n(top row is # correct, bottom row is # incorrect)\\n{table}\")\n",
    "        \n",
    "    stat, p, dof, expected = chi2_contingency(table)\n",
    "    reject = 'REJECT' if p <= .05 else 'ACCEPT'\n",
    "    \n",
    "    if p < .001:\n",
    "        p = \"< .001\"\n",
    "    \n",
    "    print(f\"For {category_explainer}, we see a chi-squared value of {stat} and a p-value of {p}.\")\n",
    "    print(f\"We can {reject} the null hypothesis that {category_explainer} is independent from performance on the CKA assessment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "81fb4a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For language script, we see a chi-squared value of 3570.576274105528 and a p-value of < .001.\n",
      "We can REJECT the null hypothesis that language script is independent from performance on the CKA assessment.\n"
     ]
    }
   ],
   "source": [
    "chi_squared([cyrillic, latin], 'correct', 'incorrect', 'language script')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "272561f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For language family, we see a chi-squared value of 4438.005771880503 and a p-value of < .001.\n",
      "We can REJECT the null hypothesis that language family is independent from performance on the CKA assessment.\n"
     ]
    }
   ],
   "source": [
    "chi_squared([germanic, romance, slavic, uralic], 'correct', 'incorrect', 'language family')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3559b4da",
   "metadata": {},
   "source": [
    "### Western vs Eastern locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "92cd2ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df[(results_df['relation'] == 'P127') & (results_df['lang_code'] == 'en')].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "2e3e55b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_relations = {\n",
    "'capital': 'P36',\n",
    "'country': 'P17',\n",
    "'continent': 'P30',\n",
    "'capital of': 'P1376',\n",
    "'is in the administrative territorial entity': 'P131',\n",
    "'shares border with': 'P47'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "d2b92d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df = results_df[results_df['relation'].isin(list(geo_relations.values()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "faa25c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44297, 12)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "83c69041",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "geo_entities = {}\n",
    "for row in entity_analysis_df.iterrows():\n",
    "    dataset_ids = list(row[1].dataset_ids)\n",
    "    for d in dataset_ids:\n",
    "        if d in list(geo_df['dataset_id']):\n",
    "            entity = row[1].entity\n",
    "            if entity not in geo_entities:\n",
    "                geo_entities[row[1].entity] = [row[1].num_correct, row[1].num_incorrect, [d]]\n",
    "            else:\n",
    "                geo_entities[row[1].entity][2].append(d)\n",
    "                \n",
    "    c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "d7bd7a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3247"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(geo_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "1bb83828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "People's Republic of China [17, 0, ['rome_21333']]\n"
     ]
    }
   ],
   "source": [
    "for k, v in geo_entities.items():\n",
    "    print(k, v)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "bb4c49ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# work with gazetteer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67b36db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anlp] *",
   "language": "python",
   "name": "conda-env-anlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
