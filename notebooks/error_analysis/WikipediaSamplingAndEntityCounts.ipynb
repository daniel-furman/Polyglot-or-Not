{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "93fb5fbc",
      "metadata": {
        "id": "93fb5fbc"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/daniel-furman/Capstone.git\n",
        "!pip install -r /content/Capstone/requirements.txt\n",
        "#!pip install -r /content/Capstone/requirements_llama.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFVvVvCIoNpj",
        "outputId": "2a977ddd-b444-439f-e8aa-a23b6f68584e"
      },
      "id": "kFVvVvCIoNpj",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Capstone'...\n",
            "remote: Enumerating objects: 3615, done.\u001b[K\n",
            "remote: Counting objects: 100% (3615/3615), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1251/1251), done.\u001b[K\n",
            "remote: Total 3615 (delta 2295), reused 3579 (delta 2262), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (3615/3615), 331.55 MiB | 16.02 MiB/s, done.\n",
            "Resolving deltas: 100% (2295/2295), done.\n",
            "Updating files: 100% (313/313), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu116\n",
            "Requirement already satisfied: numpy==1.22.4 in /usr/local/lib/python3.10/dist-packages (from -r /content/Capstone/requirements.txt (line 1)) (1.22.4)\n",
            "Collecting sentencepiece==0.1.97\n",
            "  Downloading sentencepiece-0.1.97-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch==1.13.1\n",
            "  Downloading https://download.pytorch.org/whl/cu116/torch-1.13.1%2Bcu116-cp310-cp310-linux_x86_64.whl (1977.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m735.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.26.1\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets==2.10.1\n",
            "  Downloading datasets-2.10.1-py3-none-any.whl (469 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate==0.16.0\n",
            "  Downloading accelerate-0.16.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes==0.37.0\n",
            "  Downloading bitsandbytes-0.37.0-py3-none-any.whl (76.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.3/76.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm==4.65.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/Capstone/requirements.txt (line 9)) (4.65.0)\n",
            "Collecting black==23.1.0\n",
            "  Downloading black-23.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flake8==6.0.0\n",
            "  Downloading flake8-6.0.0-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deep-translator==1.10.1\n",
            "  Downloading deep_translator-1.10.1-py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: nltk==3.8.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/Capstone/requirements.txt (line 13)) (3.8.1)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1->-r /content/Capstone/requirements.txt (line 4)) (4.5.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.1->-r /content/Capstone/requirements.txt (line 5)) (3.12.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.1->-r /content/Capstone/requirements.txt (line 5)) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.1->-r /content/Capstone/requirements.txt (line 5)) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m89.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.1->-r /content/Capstone/requirements.txt (line 5)) (2022.10.31)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.1->-r /content/Capstone/requirements.txt (line 5)) (23.1)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.1->-r /content/Capstone/requirements.txt (line 6)) (1.5.3)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.1->-r /content/Capstone/requirements.txt (line 6)) (9.0.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.1->-r /content/Capstone/requirements.txt (line 6)) (2023.4.0)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting dill<0.3.7,>=0.3.0\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.16.0->-r /content/Capstone/requirements.txt (line 7)) (5.9.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black==23.1.0->-r /content/Capstone/requirements.txt (line 10)) (8.1.3)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black==23.1.0->-r /content/Capstone/requirements.txt (line 10)) (2.0.1)\n",
            "Collecting pathspec>=0.9.0\n",
            "  Downloading pathspec-0.11.1-py3-none-any.whl (29 kB)\n",
            "Collecting mypy-extensions>=0.4.3\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black==23.1.0->-r /content/Capstone/requirements.txt (line 10)) (3.3.0)\n",
            "Collecting mccabe<0.8.0,>=0.7.0\n",
            "  Downloading mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting pyflakes<3.1.0,>=3.0.0\n",
            "  Downloading pyflakes-3.0.1-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycodestyle<2.11.0,>=2.10.0\n",
            "  Downloading pycodestyle-2.10.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from deep-translator==1.10.1->-r /content/Capstone/requirements.txt (line 12)) (4.11.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1->-r /content/Capstone/requirements.txt (line 13)) (1.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator==1.10.1->-r /content/Capstone/requirements.txt (line 12)) (2.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.10.1->-r /content/Capstone/requirements.txt (line 6)) (2.0.12)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.10.1->-r /content/Capstone/requirements.txt (line 6)) (23.1.0)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.26.1->-r /content/Capstone/requirements.txt (line 5)) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.26.1->-r /content/Capstone/requirements.txt (line 5)) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.26.1->-r /content/Capstone/requirements.txt (line 5)) (1.26.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.10.1->-r /content/Capstone/requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.10.1->-r /content/Capstone/requirements.txt (line 6)) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets==2.10.1->-r /content/Capstone/requirements.txt (line 6)) (1.16.0)\n",
            "Installing collected packages: tokenizers, sentencepiece, bitsandbytes, xxhash, torch, python-dotenv, pyflakes, pycodestyle, pathspec, mypy-extensions, multidict, mccabe, frozenlist, dill, async-timeout, yarl, responses, multiprocess, huggingface-hub, flake8, deep-translator, black, aiosignal, accelerate, transformers, aiohttp, datasets\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.0+cu118\n",
            "    Uninstalling torch-2.0.0+cu118:\n",
            "      Successfully uninstalled torch-2.0.0+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.15.1+cu118 requires torch==2.0.0, but you have torch 1.13.1+cu116 which is incompatible.\n",
            "torchtext 0.15.1 requires torch==2.0.0, but you have torch 1.13.1+cu116 which is incompatible.\n",
            "torchdata 0.6.0 requires torch==2.0.0, but you have torch 1.13.1+cu116 which is incompatible.\n",
            "torchaudio 2.0.1+cu118 requires torch==2.0.0, but you have torch 1.13.1+cu116 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.16.0 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 bitsandbytes-0.37.0 black-23.1.0 datasets-2.10.1 deep-translator-1.10.1 dill-0.3.6 flake8-6.0.0 frozenlist-1.3.3 huggingface-hub-0.14.1 mccabe-0.7.0 multidict-6.0.4 multiprocess-0.70.14 mypy-extensions-1.0.0 pathspec-0.11.1 pycodestyle-2.10.0 pyflakes-3.0.1 python-dotenv-1.0.0 responses-0.18.0 sentencepiece-0.1.97 tokenizers-0.13.3 torch-1.13.1+cu116 transformers-4.26.1 xxhash-3.2.0 yarl-1.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ftfy==5.4.1\n",
        "!pip install spacy==3.5.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrwigIVUobcF",
        "outputId": "46925d85-c2ef-45b7-9b80-67e9df2eafdb"
      },
      "id": "LrwigIVUobcF",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ftfy==5.4.1\n",
            "  Downloading ftfy-5.4.1.tar.gz (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy==5.4.1) (0.2.6)\n",
            "Building wheels for collected packages: ftfy\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-5.4.1-py3-none-any.whl size=42861 sha256=e1235fe42296979d09d52144675eb5e4bf40e897e366553ad0b8d7aa7112f2bb\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/91/4b/87bb696a4f23e5a661792b300cc920b35aa8f3a0f7e3a83a92\n",
            "Successfully built ftfy\n",
            "Installing collected packages: ftfy\n",
            "Successfully installed ftfy-5.4.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy==3.5.2 in /usr/local/lib/python3.10/dist-packages (3.5.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.2) (23.1)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.2) (1.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.2) (2.4.6)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.2) (6.3.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.2) (3.3.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.2) (0.10.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.2) (3.0.12)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.2) (1.0.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.2) (67.7.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.2) (1.10.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.2) (3.0.8)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.2) (1.22.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.2) (3.1.2)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.2) (1.0.4)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.2) (0.7.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.2) (2.27.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.2) (4.65.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.2) (2.0.7)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.2) (8.1.9)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.2) (2.0.8)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy==3.5.2) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.5.2) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.5.2) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.5.2) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.5.2) (2.0.12)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy==3.5.2) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy==3.5.2) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy==3.5.2) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy==3.5.2) (2.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 223,
      "id": "484138e4",
      "metadata": {
        "id": "484138e4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import json\n",
        "from json import JSONDecodeError\n",
        "import urllib.parse\n",
        "import urllib.request\n",
        "\n",
        "import os\n",
        "\n",
        "import re\n",
        "from ftfy import fix_text\n",
        "from string import punctuation\n",
        "\n",
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content/Capstone/notebooks/error_analysis\")"
      ],
      "metadata": {
        "id": "yUskpRVupyes"
      },
      "id": "yUskpRVupyes",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d8ecc316",
      "metadata": {
        "id": "d8ecc316"
      },
      "source": [
        "## Load Entity Data and Spacy models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "20aaef30",
      "metadata": {
        "id": "20aaef30"
      },
      "outputs": [],
      "source": [
        "code_to_lang_dict = {\n",
        "    \"bg\": \"Bulgarian\",\n",
        "    \"ca\": \"Catalan\",\n",
        "    \"cs\": \"Czech\",\n",
        "    \"da\": \"Danish\",\n",
        "    \"de\": \"German\",\n",
        "    \"en\": \"English\",\n",
        "    \"es\": \"Spanish\",\n",
        "    \"fr\": \"French\",\n",
        "    \"hr\": \"Croatian\",\n",
        "    \"hu\": \"Hungarian\",\n",
        "    \"it\": \"Italian\",\n",
        "    \"nl\": \"Dutch\",\n",
        "    \"pl\": \"Polish\",\n",
        "    \"pt\": \"Portuguese\",\n",
        "    \"ro\": \"Romanian\",\n",
        "    \"ru\": \"Russian\",\n",
        "    \"sl\": \"Slovenian\",\n",
        "    \"sr\": \"Serbian\",\n",
        "    \"sv\": \"Swedish\",\n",
        "    \"uk\": \"Ukrainian\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code_to_wiki_cleanup_dict = {\n",
        "    \"ca\": \"Referèncie\",\n",
        "    \"da\": \"Litteratur\",\n",
        "    \"de\": \"Literatur\",\n",
        "    \"en\": \"References\",\n",
        "    \"es\": \"Referencias\",\n",
        "    \"fr\": \"Notes et références\",\n",
        "    \"hr\": \"Izvori\",\n",
        "    \"it\": \"Note\",\n",
        "    \"nl\": \"Literatuur\",\n",
        "    \"pl\": \"Przypisy\",\n",
        "    \"pt\": \"Referências\",\n",
        "    \"ro\": \"Note\",\n",
        "    \"ru\": \"Примечания\",\n",
        "    \"sv\": \"Källor\",\n",
        "    \"uk\": \"Література\",\n",
        "}"
      ],
      "metadata": {
        "id": "j9q3v7wkytZs"
      },
      "id": "j9q3v7wkytZs",
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "29ea8ff8",
      "metadata": {
        "id": "29ea8ff8"
      },
      "outputs": [],
      "source": [
        "# one could change this to a different model like their\n",
        "# transformer based variant\n",
        "# but that is not available for every language we want to work with\n",
        "code_to_spacy_model_dict = {\n",
        "    \"ca\": \"ca_core_news_lg\",\n",
        "    \"da\": \"da_core_news_lg\",\n",
        "    \"de\": \"de_core_news_lg\",\n",
        "    \"en\": \"en_core_web_lg\",\n",
        "    \"es\": \"es_core_news_lg\",\n",
        "    \"fr\": \"fr_core_news_lg\",\n",
        "    \"hr\": \"hr_core_news_lg\",\n",
        "    \"it\": \"it_core_news_lg\",\n",
        "    \"nl\": \"nl_core_news_lg\",\n",
        "    \"pl\": \"pl_core_news_lg\",\n",
        "    \"pt\": \"pt_core_news_lg\",\n",
        "    \"ro\": \"ro_core_news_lg\",\n",
        "    \"ru\": \"ru_core_news_lg\",\n",
        "    \"sv\": \"sv_core_news_lg\",\n",
        "    \"uk\": \"uk_core_news_lg\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download {code_to_spacy_model_dict[\"ca\"]}\n",
        "# !python -m spacy download {code_to_spacy_model_dict[\"da\"]}\n",
        "# !python -m spacy download {code_to_spacy_model_dict[\"de\"]}\n",
        "!python -m spacy download {code_to_spacy_model_dict[\"en\"]}\n",
        "# !python -m spacy download {code_to_spacy_model_dict[\"es\"]}\n",
        "!python -m spacy download {code_to_spacy_model_dict[\"fr\"]}\n",
        "# !python -m spacy download {code_to_spacy_model_dict[\"hr\"]}\n",
        "# !python -m spacy download {code_to_spacy_model_dict[\"it\"]}\n",
        "# !python -m spacy download {code_to_spacy_model_dict[\"nl\"]}\n",
        "# !python -m spacy download {code_to_spacy_model_dict[\"pl\"]}\n",
        "# !python -m spacy download {code_to_spacy_model_dict[\"pt\"]}\n",
        "# !python -m spacy download {code_to_spacy_model_dict[\"ro\"]}\n",
        "# !python -m spacy download {code_to_spacy_model_dict[\"ru\"]}\n",
        "# !python -m spacy download {code_to_spacy_model_dict[\"sv\"]}\n",
        "# !python -m spacy download {code_to_spacy_model_dict[\"uk\"]}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4A9KCKqDqrdo",
        "outputId": "c96ca346-4b79-41b4-ed9b-bfb32f3de263"
      },
      "id": "4A9KCKqDqrdo",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-01 00:24:33.612582: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ca-core-news-lg==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/ca_core_news_lg-3.5.0/ca_core_news_lg-3.5.0-py3-none-any.whl (574.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m574.0/574.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from ca-core-news-lg==3.5.0) (3.5.2)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-lg==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-lg==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-lg==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-lg==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-lg==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-lg==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-lg==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-lg==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-lg==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-lg==3.5.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-lg==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-lg==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-lg==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-lg==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-lg==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-lg==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-lg==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-lg==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-lg==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->ca-core-news-lg==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->ca-core-news-lg==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->ca-core-news-lg==3.5.0) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->ca-core-news-lg==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->ca-core-news-lg==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->ca-core-news-lg==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->ca-core-news-lg==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->ca-core-news-lg==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->ca-core-news-lg==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->ca-core-news-lg==3.5.0) (2.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('ca_core_news_lg')\n",
            "2023-05-01 00:25:07.506509: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-lg==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.5.0/en_core_web_lg-3.5.0-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-lg==3.5.0) (3.5.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (23.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.1.2)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.5.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "2023-05-01 00:25:52.613887: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fr-core-news-lg==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_lg-3.5.0/fr_core_news_lg-3.5.0-py3-none-any.whl (571.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.8/571.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from fr-core-news-lg==3.5.0) (3.5.2)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (23.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->fr-core-news-lg==3.5.0) (2.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_lg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "id": "b513519f",
      "metadata": {
        "id": "b513519f"
      },
      "outputs": [],
      "source": [
        "def load_spacy_models(code_to_spacy_model_dict):\n",
        "    container = {}\n",
        "    for lang, model in code_to_spacy_model_dict.items():\n",
        "        if lang == 'ca' or lang == 'en' or lang == 'fr':\n",
        "            container[lang] = spacy.load(model)\n",
        "\n",
        "    return container"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spacy_models = load_spacy_models(code_to_spacy_model_dict)"
      ],
      "metadata": {
        "id": "GXS9v6DUqJTP"
      },
      "id": "GXS9v6DUqJTP",
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "d350b9af",
      "metadata": {
        "id": "d350b9af"
      },
      "outputs": [],
      "source": [
        "lang_codes = list(code_to_lang_dict.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "0c48dd74",
      "metadata": {
        "id": "0c48dd74"
      },
      "outputs": [],
      "source": [
        "entity_analysis_df = pd.read_csv(\n",
        "    \"../../data/error_analysis/entity_analysis_language_and_accuracy_by_entity.csv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "f76ba1c9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "f76ba1c9",
        "outputId": "663b756f-e4f7-41be-e6ba-4ec002961cad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       entity  num_correct  num_incorrect  total_usages  \\\n",
              "0                       Prius           16              0            16   \n",
              "1               Sundar Pichai           18              1            19   \n",
              "2  People's Republic of China           17              0            17   \n",
              "3                Sint Maarten           11             10            21   \n",
              "4                  Haas House            9              5            14   \n",
              "\n",
              "   percent_accuracy                                          languages  \\\n",
              "0          1.000000  {'sr': 1, 'uk': 1, 'nl': 1, 'sv': 1, 'ca': 1, ...   \n",
              "1          0.947368  {'sr': 1, 'uk': 1, 'nl': 1, 'sv': 1, 'ca': 1, ...   \n",
              "2          1.000000  {'sr': 1, 'uk': 1, 'nl': 1, 'sv': 1, 'hu': 1, ...   \n",
              "3          0.523810  {'sr': 1, 'nl': 2, 'sv': 1, 'ca': 1, 'pl': 1, ...   \n",
              "4          0.642857  {'sr': 1, 'nl': 1, 'sv': 1, 'hu': 1, 'ca': 1, ...   \n",
              "\n",
              "   num_languages                                    alternate_forms  \\\n",
              "0             16  {'sr': 'Приус', 'uk': 'Prius', 'nl': 'Prius', ...   \n",
              "1             19  {'sr': 'Сундар Пицхаи', 'uk': 'Сундар Пічаї', ...   \n",
              "2             17  {'sr': 'Народна Република Кина', 'uk': 'Народн...   \n",
              "3             14  {'sr': 'Синт Маартен', 'nl': 'Sint Maarten', '...   \n",
              "4             14  {'sr': 'Хаас Хоусе', 'nl': 'Haas House', 'sv':...   \n",
              "\n",
              "                   dataset_ids  \n",
              "0             ['calinet_8922']  \n",
              "1                ['rome_5025']  \n",
              "2               ['rome_21333']  \n",
              "3  ['rome_8738', 'rome_20596']  \n",
              "4                ['rome_8783']  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0c1c33c0-c666-4119-837d-5f1762f39a9c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>entity</th>\n",
              "      <th>num_correct</th>\n",
              "      <th>num_incorrect</th>\n",
              "      <th>total_usages</th>\n",
              "      <th>percent_accuracy</th>\n",
              "      <th>languages</th>\n",
              "      <th>num_languages</th>\n",
              "      <th>alternate_forms</th>\n",
              "      <th>dataset_ids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Prius</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{'sr': 1, 'uk': 1, 'nl': 1, 'sv': 1, 'ca': 1, ...</td>\n",
              "      <td>16</td>\n",
              "      <td>{'sr': 'Приус', 'uk': 'Prius', 'nl': 'Prius', ...</td>\n",
              "      <td>['calinet_8922']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sundar Pichai</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>0.947368</td>\n",
              "      <td>{'sr': 1, 'uk': 1, 'nl': 1, 'sv': 1, 'ca': 1, ...</td>\n",
              "      <td>19</td>\n",
              "      <td>{'sr': 'Сундар Пицхаи', 'uk': 'Сундар Пічаї', ...</td>\n",
              "      <td>['rome_5025']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>People's Republic of China</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{'sr': 1, 'uk': 1, 'nl': 1, 'sv': 1, 'hu': 1, ...</td>\n",
              "      <td>17</td>\n",
              "      <td>{'sr': 'Народна Република Кина', 'uk': 'Народн...</td>\n",
              "      <td>['rome_21333']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sint Maarten</td>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "      <td>21</td>\n",
              "      <td>0.523810</td>\n",
              "      <td>{'sr': 1, 'nl': 2, 'sv': 1, 'ca': 1, 'pl': 1, ...</td>\n",
              "      <td>14</td>\n",
              "      <td>{'sr': 'Синт Маартен', 'nl': 'Sint Maarten', '...</td>\n",
              "      <td>['rome_8738', 'rome_20596']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Haas House</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>14</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>{'sr': 1, 'nl': 1, 'sv': 1, 'hu': 1, 'ca': 1, ...</td>\n",
              "      <td>14</td>\n",
              "      <td>{'sr': 'Хаас Хоусе', 'nl': 'Haas House', 'sv':...</td>\n",
              "      <td>['rome_8783']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c1c33c0-c666-4119-837d-5f1762f39a9c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0c1c33c0-c666-4119-837d-5f1762f39a9c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0c1c33c0-c666-4119-837d-5f1762f39a9c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "entity_analysis_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acf7ea8c",
      "metadata": {
        "id": "acf7ea8c"
      },
      "source": [
        "So we have 23k entities to work with. We're interested in how many times they get mentioned on wikipedia."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(entity_analysis_df[\"entity\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6dLYfqo5hTg",
        "outputId": "95e1879d-a050-466c-c5d4-f29a47d30e20"
      },
      "id": "U6dLYfqo5hTg",
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "id": "f7efb860",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7efb860",
        "outputId": "470f0849-ed9d-40dc-e2a4-ad80153c1e39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "couldn't parse {\"sr\": \"Јое \"Фингерс\" Царр\", \"sv\": \"Joe \"Fingers\" Carr\", \"ca\": \"Joe \"Fingers\" Carr\", \"pl\": \"Joe „Palce” Carr\", \"bg\": \"Джо \"Пръстите\" Кар\", \"sl\": \"Joe \"Fingers\" Carr\", \"en\": \"Joe \"Fingers\" Carr\", \"pt\": \"Joe \"Fingers\" Carr\", \"es\": \"Joe \"Fingers\" Carr\", \"hr\": \"Joe \"Fingers\" Carr\", \"da\": \"Joe \"Fingers\" Carr\", \"fr\": \"Joe \"Fingers\" Carr\", \"it\": \"Joe \"Fingers\" Carr\", \"ro\": \"Joe \"Fingers\" Carr\"}\n",
            "couldn't parse {\"sr\": \"Дернст \"Д\\'Миле\" Емил ИИ\", \"nl\": \"Dernst \"D\\'Mile\" Emile II\", \"sv\": \"Dernst \"D\\'Mile\" Emile II\", \"ca\": \"Dernst \"D\\'Mile\" Emile II\", \"pl\": \"Dernsta „D'Mile” Emila II\", \"bg\": \"Dernst \"D\\'Mile\" Emile II\", \"sl\": \"Dernst \"D\\'Mile\" Emile II\", \"en\": \"Dernst \"D\\'Mile\" Emile II\", \"de\": \"Dernst \"D\\'Mile\" Emile II\", \"pt\": \"Dernst \"D\\'Mile\" Emile II\", \"cs\": \"Dernst \"D\\'Mile\" Emile II\", \"hr\": \"Dernst \"D\\'Mile\" Emile II\", \"fr\": \"Dernst \"D\\'Mile\" Emile II\", \"it\": \"Dernst \"D\\'Mile\" Emile II\", \"ro\": \"Dernst \"D\\'Mile\" Emile II\"}\n",
            "couldn't parse {\"sr\": \"Р.А. Дицкеи\", \"uk\": \"Р.А. Дікі\", \"sv\": \"R.A. Löst skjortbröst\", \"ca\": \"R.A. Dickey\", \"bg\": \"Р.А. Дики\", \"sl\": \"R.A. Dickey\", \"en\": \"R.A. Dickey\", \"de\": \"R.A. Dickey\", \"pt\": \"R.A. Dickey\", \"cs\": \"R.A. Dickey\", \"hr\": \"R.A. Dickey\", \"da\": \"R.A. Dickey\", \"fr\": \"R.\\xa0A. Dicky\", \"it\": \"RA. Dickey\", \"ro\": \"R.A. Dickey\"}\n",
            "couldn't parse {\"sr\": \"Разарач класе Спруанце\", \"uk\": \"Есмінець типу \"Ялина\".\", \"nl\": \"Vernietiger van de Spruance-klasse\", \"sv\": \"Jagare av Spruance-klass\", \"pl\": \"Niszczyciel klasy Spruance\", \"bg\": \"Разрушител от клас Spruance\", \"sl\": \"Rušilec razreda Spruance\", \"en\": \"Spruance-class destroyer\", \"de\": \"Zerstörer der Spruance-Klasse\", \"pt\": \"Destruidor classe Spruance\", \"cs\": \"Torpédoborec třídy Spruance\", \"es\": \"Destructor clase Spruance\", \"da\": \"Spruance-klasse destroyer\", \"it\": \"Cacciatorpediniere di classe Spruance\", \"ro\": \"distrugător din clasa Spruance\"}\n",
            "couldn't parse {\"uk\": \"3-2-1 Пінгвіни!\", \"nl\": \"3-2-1 pinguins!\", \"sv\": \"3-2-1 Penguins!\", \"ca\": \"3-2-1 Pingüins!\", \"pl\": \"3-2-1 Pingwiny!\", \"ru\": \"3-2-1 Пингвинз!\", \"bg\": \"3-2-1 Пингвини!\", \"sl\": \"3-2-1 Pingvini!\", \"en\": \"3-2-1 Penguins!\", \"pt\": \"3-2-1 Pinguins!\", \"cs\": \"3-2-1 Penguins!\", \"es\": \"¡3-2-1 pingüinos!\", \"da\": \"3-2-1 Pingviner!\", \"fr\": \"Pingouins 3-2-1\\xa0!\", \"it\": \"3-2-1 Pinguini!\", \"ro\": \"3-2-1 Pinguini!\"}\n",
            "couldn't parse {\"uk\": \"Космічна корпорація \"Енергія\".\", \"nl\": \"Space Corporation Energia\", \"sv\": \"Space Corporation Energia\", \"ca\": \"Space Corporation Energia\", \"bg\": \"Космическа корпорация Енергия\", \"en\": \"Space Corporation Energia\", \"de\": \"Space Corporation Energia\", \"pt\": \"Space Corporation Energia\", \"es\": \"Space Corporation Energia\", \"da\": \"Space Corporation Energia\", \"fr\": \"Space Corporation Energia\", \"it\": \"Space Corporation Energia\", \"ro\": \"Space Corporation Energia\"}\n",
            "couldn't parse {\"uk\": \"Час підписання!\", \"nl\": \"Tekentijd!\", \"sv\": \"Signeringstid!\", \"ca\": \"Hora de signatura!\", \"pl\": \"Czas na podpisanie!\", \"ru\": \"Время подписания!\", \"bg\": \"Време за подписване!\", \"sl\": \"Čas za podpis!\", \"en\": \"Signing Time!\", \"de\": \"Signierzeit!\", \"pt\": \"Hora de assinar!\", \"cs\": \"Čas podpisu!\", \"es\": \"¡Hora de firmar!\", \"da\": \"Signeringstid!\", \"fr\": \"L'heure de la signature\\xa0!\", \"it\": \"Tempo di firma!\", \"ro\": \"Ora semnării!\"}\n",
            "couldn't parse {\"uk\": \"Проект \"Недільний вечір\".\", \"nl\": \"The Sunday Night Project\", \"sv\": \"The Sunday Night Project\", \"ca\": \"El projecte del diumenge a la nit\", \"pl\": \"The Sunday Night Project\", \"bg\": \"Проектът Неделя вечер\", \"sl\": \"Projekt Sunday Night\", \"en\": \"The Sunday Night Project\", \"pt\": \"Projeto Domingo à noite\", \"cs\": \"The Sunday Night Project\", \"es\": \"The Sunday Night Project\", \"hr\": \"Projekt nedjeljom navečer\", \"da\": \"Sunday Night Project\", \"fr\": \"The Sunday Night Project\", \"it\": \"Il progetto della domenica sera\", \"ro\": \"The Sunday Night Project\"}\n",
            "couldn't parse {\"uk\": \"Просто застрели мене!\", \"nl\": \"Schiet me gewoon neer!\", \"sv\": \"Skjut mig bara!\", \"ca\": \"Només dispara'm!\", \"pl\": \"Po prostu mnie zastrzel!\", \"ru\": \"Просто стреляй в меня!\", \"bg\": \"Просто ме застреляй!\", \"sl\": \"Samo ustreli me!\", \"en\": \"Just Shoot Me!\", \"pt\": \"Apenas atire em mim!\", \"cs\": \"Jen mě zastřel!\", \"es\": \"¡Sólo disparame!\", \"da\": \"Bare skyd mig!\", \"fr\": \"Tirez-moi juste dessus\\xa0!\", \"it\": \"Sparami e basta!\", \"ro\": \"Doar împușcă-mă!\"}\n",
            "couldn't parse {\"uk\": \"Гей, Жанні!\", \"nl\": \"Hé, Jeanny!\", \"sv\": \"Hej, Jeannie!\", \"ca\": \"Ei, Jeannie!\", \"pl\": \"Hej, Jeannie!\", \"ru\": \"Эй, Джинни!\", \"bg\": \"Хей, Жани!\", \"sl\": \"Živjo, Jeannie!\", \"en\": \"Hey, Jeannie!\", \"pt\": \"Oi, Jeanne!\", \"cs\": \"Čau, Jeannie!\", \"es\": \"¡Hola, Jeannie!\", \"da\": \"Hej, Jeannie!\", \"fr\": \"Salut Jeannie\\xa0!\", \"it\": \"Ehi, Giovanna!\", \"ro\": \"Hei, Jeannie!\"}\n",
            "couldn't parse {\"nl\": \"All-Oekraïense Unie \"Svoboda\", \"sv\": \"All-Ukrainian Union \"Svoboda\", \"ca\": \"Unió de tot Ucraïna \"Svoboda\", \"bg\": \"Всеукраински съюз \"Свобода\", \"en\": \"All-Ukrainian Union \"Svoboda\", \"de\": \"Allukrainischer Verband \"Svoboda\", \"pt\": \"União Ucraniana \"Svoboda\", \"es\": \"Unión de Ucrania \"Svoboda\", \"da\": \"All-Ukrainian Union \"Svoboda\", \"fr\": \"Union panukrainienne \"Svoboda\", \"it\": \"Unione tutta ucraina \"Svoboda\", \"ro\": \"Uniunea integrală ucraineană „Svoboda”\"}\n",
            "couldn't parse {\"nl\": \"Bomaanslag op Canal Hotel\", \"sv\": \"Canal Hotel bombning\", \"ca\": \"Atemptat a l'hotel Canal\", \"bg\": \"Атентатът в хотел \"Канал\".\", \"en\": \"Canal Hotel bombing\", \"de\": \"Bombenanschlag auf das Canal Hotel\", \"pt\": \"Bombardeio Hotel Canal\", \"da\": \"Canal Hotel bombning\", \"fr\": \"Attentat à l'hôtel Canal\", \"it\": \"Attentato all'Hotel Canal\", \"ro\": \"Atentatul la Hotelul Canal\"}\n",
            "couldn't parse {\"nl\": \"Jordan \"Ratbeard\" Hastings\", \"sv\": \"Jordan \"Ratbeard\" Hastings\", \"ca\": \"Jordan \"Ratbeard\" Hastings\", \"bg\": \"Джордан \"Ratbeard\" Хейстингс\", \"en\": \"Jordan \"Ratbeard\" Hastings\", \"de\": \"Jordan \"Ratbeard\" Hastings\", \"pt\": \"Jordan \"Ratbeard\" Hastings\", \"es\": \"Jordan \"Ratbeard\" Hastings\", \"da\": \"Jordan \"Ratbeard\" Hastings\", \"it\": \"Jordan \"Ratbeard\" Hastings\", \"ro\": \"Jordan „Barbă de șobolan” Hastings\"}\n",
            "couldn't parse {\"nl\": \"Jerome \"Romeo\" Jones\", \"ca\": \"Jerome \"Romeo\" Jones\", \"bg\": \"Джером \"Ромео\" Джоунс\", \"en\": \"Jerome \"Romeo\" Jones\", \"de\": \"Jérôme „Romeo“ Jones\", \"pt\": \"Jerome \"Romeo\" Jones\", \"da\": \"Jerome \"Romeo\" Jones\", \"fr\": \"Jerome \"Romeo\" Jones\", \"it\": \"Jerome \"Romeo\" Jones\", \"ro\": \"Jerome „Romeo” Jones\"}\n",
            "couldn't parse {\"nl\": \"26e Europese Filmprijzen\", \"sv\": \"26:e European Film Awards\", \"ca\": \"26è Premis del Cinema Europeu\", \"bg\": \"26-и Европейски филмови награди\", \"en\": \"26th European Film Awards\", \"pt\": \"26º Prêmio do Cinema Europeu\", \"da\": \"26. European Film Awards\", \"fr\": \"26e\\xa0Prix du cinéma européen\", \"it\": \"26° Premio del cinema europeo\", \"ro\": \"A 26-a ediție a Premiilor Filmului European\"}\n",
            "couldn't parse {\"nl\": \"Lanyon Place treinstation\", \"sv\": \"Lanyon Place järnvägsstation\", \"ca\": \"Estació de tren de Lanyon Place\", \"bg\": \"Жп гара Lanyon Place\", \"en\": \"Lanyon Place railway station\", \"de\": \"Bahnhof Lanyon Place\", \"pt\": \"Estação Ferroviária Lanyon Place\", \"es\": \"Estación de tren de Lanyon Place\", \"da\": \"Lanyon Place banegård\", \"fr\": \"Gare de Lanyon\\xa0Place\", \"it\": \"Stazione ferroviaria di Lanyon Place\", \"ro\": \"Gara Lanyon Place\"}\n",
            "couldn't parse {\"nl\": \"Fulfillingness' First Finale\", \"sv\": \"Fulfillingness' First Finale\", \"ca\": \"Primer final de la satisfacció\", \"bg\": \"Първи финал на \"Изпълнение\".\", \"en\": \"Fulfillingness' First Finale\", \"pt\": \"Fulfillingness' First Finale\", \"es\": \"Primer Final de Cumplimiento\", \"da\": \"Fulfillingness' First Finale\", \"fr\": \"Première finale de Fulfillness\", \"it\": \"Il primo finale di Fulfillingness\"}\n",
            "couldn't parse {\"nl\": \"Operatie Onweer\", \"sv\": \"Operation Storm\", \"ca\": \"Operació Tempesta\", \"bg\": \"Операция \"Буря\".\", \"en\": \"Operation Storm\", \"de\": \"Operation Sturm\", \"pt\": \"Operação Tempestade\", \"es\": \"Operación Tormenta\", \"da\": \"Operation Storm\", \"fr\": \"Opération Tempête\", \"it\": \"Operazione Tempesta\"}\n",
            "couldn't parse {\"nl\": \"Walla!\", \"sv\": \"Walla!\", \"ca\": \"Walla!\", \"bg\": \"Уола!\", \"en\": \"Walla!\", \"pt\": \"Walla!\", \"es\": \"Walla!\", \"da\": \"Walla!\", \"fr\": \"Walla\\xa0!\", \"it\": \"Walla!\", \"ro\": \"Walla!\"}\n",
            "couldn't parse {\"nl\": \"Drie Rivieren Filmfestival\", \"sv\": \"Three Rivers Film Festival\", \"ca\": \"Three Rivers Film Festival\", \"bg\": \"Филмов фестивал \"Три реки\".\", \"en\": \"Three Rivers Film Festival\", \"de\": \"Three Rivers Film Festival\", \"pt\": \"Festival de Cinema de Três Rios\", \"es\": \"Festival de Cine de los Tres Ríos\", \"da\": \"Three Rivers Film Festival\", \"fr\": \"Festival du film des trois rivières\", \"it\": \"Three Rivers Film Festival\", \"ro\": \"Three Rivers Film Festival\"}\n",
            "couldn't parse {\"nl\": \"$ 9,99\", \"sv\": \"9,99 USD\", \"ca\": \"9,99\\xa0$\", \"bg\": \"$9,99\", \"en\": \"$9.99\", \"pt\": \"US$ 9,99\", \"es\": \"$9.99\", \"da\": \"9,99 USD\", \"fr\": \"9,99 $\", \"it\": \"$ 9,99\"}\n",
            "couldn't parse {\"nl\": \"Leroy \"Nicky\" Barnes\", \"sv\": \"Leroy \"Nicky\" Barnes\", \"ca\": \"Leroy \"Nicky\" Barnes\", \"bg\": \"Лирой \"Ники\" Барнс\", \"en\": \"Leroy \"Nicky\" Barnes\", \"de\": \"Leroy \"Nicky\" Barnes\", \"pt\": \"Leroy \"Nicky\" Barnes\", \"es\": \"Leroy \"Nicky\" Barnes\", \"da\": \"Leroy \"Nicky\" Barnes\", \"fr\": \"Leroy \"Nicky\" Barnes\", \"it\": \"Leroy \"Nicky\" Barnes\", \"ro\": \"Leroy „Nicky” Barnes\"}\n",
            "couldn't parse {\"nl\": \"Dick \"Night Train\" Lane\", \"sv\": \"Dick \"Night Train\" Lane\", \"ca\": \"Dick \"Night Train\" Lane\", \"en\": \"Dick \"Night Train\" Lane\", \"pt\": \"Dick \"Night Train\" Lane\", \"es\": \"Dick \"Night Train\" Lane\", \"da\": \"Dick \"Night Train\" Lane\", \"it\": \"Dick \"Night Train\" Lane\", \"ro\": \"Dick \"Night Train\" Lane\"}\n",
            "couldn't parse {\"nl\": \"Beyblade: Metal Fusion\", \"sv\": \"Beyblade: Metal Fusion\", \"ca\": \"Beyblade: Metal Fusion\", \"bg\": \"Beyblade: Metal Fusion\", \"en\": \"Beyblade: Metal Fusion\", \"pt\": \"Beyblade: Metal Fusion\", \"es\": \"Beyblade: Metal Fusion\", \"da\": \"Beyblade: Metal Fusion\", \"fr\": \"Beyblade\\xa0: fusion du métal\", \"it\": \"Beyblade: Metal Fusion\", \"ro\": \"Beyblade: Metal Fusion\"}\n",
            "couldn't parse {\"nl\": \"Franz Liszt Muziekacademie\", \"sv\": \"Franz Liszt Musikakademi\", \"ca\": \"Acadèmia de Música Franz Liszt\", \"bg\": \"Музикална академия \"Франц Лист\".\", \"en\": \"Franz Liszt Academy of Music\", \"de\": \"Franz-Liszt-Musikhochschule\", \"pt\": \"Franz Liszt Academy of Music\", \"es\": \"Academia de Música Franz Liszt\", \"da\": \"Franz Liszt Musikakademi\", \"ro\": \"Academia de Muzică Franz Liszt\"}\n",
            "couldn't parse {\"nl\": \"Biff Bang Pow!\", \"sv\": \"Biff Bang Pow!\", \"ca\": \"Biff Bang Pow!\", \"bg\": \"Biff Bang Pow!\", \"en\": \"Biff Bang Pow!\", \"pt\": \"Biff Bang Pow!\", \"es\": \"Biff Bang Pow!\", \"da\": \"Biff Bang Pow!\", \"fr\": \"Biff Bang Pow\\xa0!\", \"it\": \"Biff Bang Pow!\", \"ro\": \"Biff Bang Pow!\"}\n",
            "couldn't parse {\"nl\": \"Insight Film Festival\", \"sv\": \"Insight Film Festival\", \"ca\": \"Insight Film Festival\", \"bg\": \"Филмов фестивал \"Инсайт\".\", \"en\": \"Insight Film Festival\", \"pt\": \"Insight Film Festival\", \"da\": \"Insight Film Festival\", \"fr\": \"Insight Film Festival\", \"it\": \"Insight Film Festival\", \"ro\": \"Insight Film Festival\"}\n",
            "couldn't parse {\"nl\": \"Andrew \"Whitey\" White\", \"sv\": \"Andrew \"Whitey\" White\", \"ca\": \"Andrew \"Whitey\" White\", \"pl\": \"Andrzeja „Whiteya” White'a\", \"bg\": \"Андрю \"Уайти\" Уайт\", \"en\": \"Andrew \"Whitey\" White\", \"de\": \"Andrew \"Whitey\" White\", \"pt\": \"Andrew \"Whitey\" White\", \"es\": \"Andrew \"Whitey\" White\", \"da\": \"Andrew \"Whitey\" White\", \"fr\": \"Andrew \"Whitey\" White\", \"it\": \"Andrew \"Whitey\" White\", \"ro\": \"Andrew \"Whitey\" White\"}\n",
            "couldn't parse {\"nl\": \"Bomaanslag op King David Hotel\", \"sv\": \"Bombning av King David Hotel\", \"ca\": \"Atemptat a l'hotel King David\", \"bg\": \"Атентатът в хотел \"Крал Дейвид\".\", \"en\": \"King David Hotel bombing\", \"de\": \"Bombenanschlag auf das King David Hotel\", \"pt\": \"Atentado ao Hotel King David\", \"es\": \"Bombardeo en el Hotel Rey David\", \"da\": \"King David Hotel bombning\", \"fr\": \"Attentat à l'hôtel King David\", \"it\": \"Attentato al King David Hotel\", \"ro\": \"Atentatul la hotelul King David\"}\n",
            "couldn't parse {\"nl\": \"Laurdine \"Pat\" Patrick\", \"sv\": \"Laurdine \"Pat\" Patrick\", \"bg\": \"Лордин \"Пат\" Патрик\", \"en\": \"Laurdine \"Pat\" Patrick\", \"de\": \"Laurdine \"Pat\" Patrick\", \"pt\": \"Laurdine \"Pat\" Patrick\", \"es\": \"Laurdine \"Pat\" Patrick\", \"da\": \"Laurdine \"Pat\" Patrick\", \"ro\": \"Laurdine \"Pat\" Patrick\"}\n",
            "couldn't parse {\"sv\": \"James Stephen \"Big Jim\" Hogg\", \"hu\": \"James Stephen \"Big Jim\" Hogg\", \"ca\": \"James Stephen \"Big Jim\" Hogg\", \"en\": \"James Stephen \"Big Jim\" Hogg\", \"pt\": \"James Stephen \"Big Jim\" Hogg\", \"es\": \"James Stephen \"Big Jim\" Hogg\", \"da\": \"James Stephen \"Big Jim\" Hogg\", \"fr\": \"James Stephen \"Big Jim\" Hogg\", \"it\": \"James Stephen \"Big Jim\" Hogg\"}\n",
            "couldn't parse {\"en\": \"James \"Jimmy Henchman\" Rosemond\"}\n",
            "couldn't parse {\"en\": \"Thomas \"Hollywood\" Henderson\", \"cs\": \"Thomas \"Hollywood\" Henderson\", \"fr\": \"Thomas \"Hollywood\" Henderson\", \"ro\": \"Thomas \"Hollywood\" Henderson\"}\n"
          ]
        }
      ],
      "source": [
        "# get lookup that connects the english form of an entity to its multilingual version\n",
        "# annoying that with the way the DF is set up right now, have to do manual cleanup to extract the translated forms\n",
        "# should update the other NB so that it ouptuts a well formatted json into the column\n",
        "target_entities_multiling = {}\n",
        "for row in entity_analysis_df.iterrows():\n",
        "    d = row[1].alternate_forms\n",
        "    for code in code_to_lang_dict.keys():\n",
        "        d = d.replace(\"'\" + code + \"'\", '\"' + code + '\"')\n",
        "    \n",
        "    d = d.replace(\": '\", ': \"')\n",
        "    d = d.replace(\"',\", '\",')\n",
        "    d = d.replace(\"'}\", '\"}')\n",
        "    d = d.replace('\"\"', '\"')\n",
        "    try:\n",
        "        d = json.loads(d)\n",
        "        target_entities_multiling[row[1].entity] = d\n",
        "\n",
        "    except JSONDecodeError:\n",
        "        print(f\"couldn't parse {d}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(target_entities_multiling)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LR-Uz8hA4uIb",
        "outputId": "5995c650-dd89-4700-9100-572021e12999"
      },
      "id": "LR-Uz8hA4uIb",
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23224"
            ]
          },
          "metadata": {},
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "7a85fa95",
      "metadata": {
        "id": "7a85fa95"
      },
      "outputs": [],
      "source": [
        "# for a given language, randomly sample <n> articles (max of 500).\n",
        "# return a dict of their id and title.\n",
        "def get_wikipedia_pages(lang, debug=False):\n",
        "    # construct URL for API call\n",
        "    articles_url = f\"https://{lang}.wikipedia.org/w/api.php?action=query&list=random&format=json&rnnamespace=0&rnlimit=50&format=json\"\n",
        "\n",
        "    # grab data\n",
        "    url = urllib.request.urlopen(articles_url)\n",
        "\n",
        "    # read data\n",
        "    data = url.read()\n",
        "\n",
        "    # set encoding and load into obj\n",
        "    encoding = url.info().get_content_charset(\"utf-8\")\n",
        "    obj = json.loads(data.decode(encoding))\n",
        "\n",
        "    if \"query\" not in obj or \"random\" not in obj[\"query\"]:\n",
        "        if debug:\n",
        "            print(\n",
        "                f\"Unable to grab articles from {code_to_lang_dict[lang]} using URL {url}.\"\n",
        "            )\n",
        "        raise Exception\n",
        "\n",
        "    mappings = obj[\"query\"][\"random\"]\n",
        "    ids = {}\n",
        "    for m in mappings:\n",
        "        ids[m[\"id\"]] = m[\"title\"]\n",
        "\n",
        "    if debug:\n",
        "        print(f\"Fetched {len(ids)} articles from {code_to_lang_dict[lang]} wikipedia\")\n",
        "    return ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "id": "04273ef7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04273ef7",
        "outputId": "4e42e3a6-5059-4662-c37d-533a27c9f9ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 50 articles from Swedish wikipedia\n"
          ]
        }
      ],
      "source": [
        "info_to_check = get_wikipedia_pages(\"sv\", debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "id": "a8e4fa9d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8e4fa9d",
        "outputId": "fe6f78dc-e9cc-445b-e8f6-ef7105941ce6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{2654777: 'Peliococcus locustus',\n",
              " 4787206: 'Psychotria congesta',\n",
              " 6688944: 'Vakkasaari',\n",
              " 1992763: 'Rhopalonema',\n",
              " 1738491: 'Xylaria jaliscoensis',\n",
              " 1745540: 'Rhynchosporium secalis',\n",
              " 3022195: 'Aprionus svecicus',\n",
              " 1881134: 'Desmoris montanus',\n",
              " 4854466: 'Podonephelium homei',\n",
              " 6715298: \"St. Martin's (civil parish, Cornwall)\",\n",
              " 2792634: 'George N. Craig',\n",
              " 600927: 'Bengt af Geijerstam',\n",
              " 1776914: 'Puccinia umbilici',\n",
              " 6568182: 'Guardamar (ort i Spanien)',\n",
              " 3218059: 'Trichopalpus',\n",
              " 5080453: 'Hongqiao',\n",
              " 650175: 'Gudrun Norberg',\n",
              " 3765916: 'Eupogonius wickhami',\n",
              " 1704331: 'Vincent, Kalifornien',\n",
              " 4915632: 'Phil Lester',\n",
              " 6602207: 'Spáafelli',\n",
              " 8041855: 'Roger Vergé',\n",
              " 3865798: 'Ulkujärvi (Karesuando socken, Lappland, 759246-177778)',\n",
              " 2924062: 'Lambula aethalocis',\n",
              " 1754303: 'Lecanora achroa',\n",
              " 2631740: 'Tapiena stylata',\n",
              " 4309: 'Kaj Kindvall',\n",
              " 6232209: 'Världsmästerskapen i bågskytte 1971',\n",
              " 3455948: 'Aphytis mimosae',\n",
              " 4408717: 'Lobelia gracillima',\n",
              " 6950275: 'Donggang (köpinghuvudort i Kina, Guangdong Sheng, lat 22,99, long 115,93)',\n",
              " 3786831: 'Acanthoderes affinis',\n",
              " 1228088: 'Niklas Gudmundsson',\n",
              " 137827: 'Fotbollsallsvenskan 1962',\n",
              " 7131856: 'Desa Rowosari (administrativ by i Indonesien, Jawa Tengah, lat -6,88, long 109,57)',\n",
              " 1521258: 'Koka soppa på en spik',\n",
              " 1703886: 'Bell, Kalifornien',\n",
              " 3053376: 'Lasiochira',\n",
              " 3463864: 'Ropalidia dichroma',\n",
              " 3844865: 'Laccophilus aemulus',\n",
              " 1745458: 'Excipula',\n",
              " 2992033: 'Amauris lygia',\n",
              " 3045746: 'Culicoides choochotei',\n",
              " 4538124: 'Rubus infestisepalus',\n",
              " 4599832: 'Glochidion podocarpum',\n",
              " 5740215: 'Marechal Cândido Rondon (ort)',\n",
              " 8405431: 'Louisburg, Missouri',\n",
              " 3494734: 'Meroglossa soror',\n",
              " 4568497: 'Erythroxylum parvistipulatum',\n",
              " 1711233: 'Gnuplot'}"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ],
      "source": [
        "info_to_check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "id": "719d9d98",
      "metadata": {
        "id": "719d9d98"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "for an inputted article_id:title combination\n",
        "we want to hit:\n",
        "https://en.wikipedia.org/w/api.php?action=query&format=json&titles=Kerala&prop=extracts&explaintext\n",
        "good response - {\"batchcomplete\":\"\",\"query\":{\"pages\":{\"14958\":{\"pageid\":14958,\"ns\":0,\"title\":\"Kerala\"\n",
        "bad response  - {\"batchcomplete\":\"\",\"query\":{\"pages\":{\"-1\":{\"ns\":0,\"title\":\"Kerala\",\"missing\":\"\"}}}}\n",
        "\"\"\"\n",
        "\n",
        "def get_article_info(article_title, pageid, lang, code_to_wiki_cleanup_dict, debug=False):\n",
        "    # val\n",
        "    if article_title == \"\" or article_title is None:\n",
        "        if debug:\n",
        "            print(\"Can't parse empty title.\")\n",
        "        return {}\n",
        "\n",
        "    if lang == \"\" or lang is None:\n",
        "        if debug:\n",
        "            print(\"Input a language.\")\n",
        "        return {}\n",
        "\n",
        "    lang = lang.lower()\n",
        "\n",
        "    url = \"\"\n",
        "\n",
        "    # format title via quote escapes to ensure non-ascii chars can get handed off properly\n",
        "    quoted_title = urllib.parse.quote(article_title)\n",
        "\n",
        "    # construct url\n",
        "    # where lang is the language we are requested\n",
        "    # and quoted title refers to our article\n",
        "    info_url = f\"https://{lang}.wikipedia.org/w/api.php?action=query&format=json&titles={quoted_title}&prop=extracts&explaintext&format=json\"\n",
        "\n",
        "    if debug:\n",
        "        print(\n",
        "            f\"calling {info_url} to retrieve info about {article_title} from {lang} wiki.\"\n",
        "        )\n",
        "\n",
        "    # grab data\n",
        "    try:\n",
        "        url = urllib.request.urlopen(info_url)\n",
        "    except UnicodeDecodeError:\n",
        "        print(\n",
        "            f\"could not decode API call for {article_title} on {lang} wiki; url is {info_url}.\"\n",
        "        )\n",
        "        return {}\n",
        "\n",
        "    # read content\n",
        "    data = url.read()\n",
        "\n",
        "    # set encoding and load into obj\n",
        "    encoding = url.info().get_content_charset(\"utf-8\")\n",
        "    obj = json.loads(data.decode(encoding))\n",
        "\n",
        "    if \"query\" not in obj or \"pages\" not in obj[\"query\"]:\n",
        "        if debug:\n",
        "            print(f\"Error parsing response for {article_title} from {lang} wiki.\")\n",
        "        raise Exception\n",
        "\n",
        "    # check for a 'missing'/bad response\n",
        "    if -1 in obj[\"query\"][\"pages\"].keys():\n",
        "        if debug:\n",
        "            print(f\"No wiki data found for {article_title} on {lang} wiki.\")\n",
        "        return {}\n",
        "\n",
        "    # get pageid of the returned article\n",
        "    data_pageid = list(obj[\"query\"][\"pages\"].keys())[0]\n",
        "\n",
        "    # double check pageid matches the one returned by API\n",
        "    if data_pageid != pageid:\n",
        "        if debug:\n",
        "            print(\n",
        "                f\"id mismatch -- excpected {pageid} but retrieved {data_pageid} for {article_title} on {lang} wiki.\"\n",
        "            )\n",
        "        return {}\n",
        "\n",
        "    # check if text is properly returned\n",
        "    if \"extract\" not in obj[\"query\"][\"pages\"][data_pageid]:\n",
        "        if debug:\n",
        "            print(\n",
        "                f\"could not retrieve text from {pageid} {article_title} on {lang} wiki.\"\n",
        "            )\n",
        "        return {}\n",
        "\n",
        "    # get text\n",
        "    content = obj[\"query\"][\"pages\"][data_pageid][\"extract\"]\n",
        "\n",
        "    # fix text\n",
        "    content = fix_text(content)\n",
        "\n",
        "    # remove references and whatever is below that as well\n",
        "    references_line = code_to_wiki_cleanup_dict[lang]\n",
        "\n",
        "    if '\\n== ' + references_line in content:\n",
        "        content = content[0: content.find('\\n== ' + references_line)]\n",
        "    elif '\\n=== ' + references_line in content:\n",
        "        content = content[0: content.find('\\n=== ' + references_line)]\n",
        "    else:\n",
        "        if debug:\n",
        "            print(f\"Couldn't remove references for {article_title} with content {content} searching for {references_line}\")\n",
        "\n",
        "    # light string substitutions\n",
        "    content = content.replace(\"\\n\", \" \")\n",
        "    content = content.replace(\"=\", \" \")\n",
        "    content = re.sub(r\"\\s{2,}\", \"\", content)\n",
        "\n",
        "    return {article_title: content}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 271,
      "id": "b1588b08",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1588b08",
        "outputId": "de9adee7-a0df-4234-e5a8-cc068d822328"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "calling https://en.wikipedia.org/w/api.php?action=query&format=json&titles=Barack%20Obama&prop=extracts&explaintext&format=json to retrieve info about Barack Obama from en wiki.\n"
          ]
        }
      ],
      "source": [
        "# get_article_info('Скворцов Борис Дмитрович','3446530', 'uk', code_to_wiki_cleanup_dict, debug=True)\n",
        "obama_info = get_article_info(\"Barack Obama\", \"534366\", \"en\", code_to_wiki_cleanup_dict, debug=True)\n",
        "# swedish_aricle_info = get_article_info(\"Lambula aethalocis\", \"2924062\", \"sv\", code_to_wiki_cleanup_dict, debug=True)\n",
        "# catalan_article_info = get_article_info(\"Cúmul de l'Ànec Salvatge\", \"260276\", \"ca\", code_to_wiki_cleanup_dict, debug=True)\n",
        "# french_article_info = get_article_info('Angleterre', '4925', 'fr', code_to_wiki_cleanup_dict, debug=True)\n",
        "\n",
        "# get_article_info('Barack Obama','430434', 'es', debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for inputted article content\n",
        "# how many entities appear in the article?\n",
        "# (total as well as unique)\n",
        "# how many of our target entities appear in the text?\n",
        "# (total as well as unique)\n",
        "# how many words are in the article?\n",
        "\n",
        "# always search english and the native language in-case of translation inconsistencies\n",
        "def count_entities_in_article(target_entities_multiling, article_content, spacy_models, lang, debug=False):\n",
        "    nlp = spacy_models[lang]\n",
        "\n",
        "    all_entities = {}\n",
        "\n",
        "    if article_content is None:\n",
        "        if debug:\n",
        "            print(\"article content is empty.\")\n",
        "        return {}\n",
        "\n",
        "    article_title = list(article_content.keys())[0]\n",
        "    article_text = list(article_content.values())[0]\n",
        "\n",
        "    if article_title is None or article_title == '' or article_text is None or article_title == '':\n",
        "        if debug:\n",
        "            print(f\"Could not parse article content -- {article_content}\")\n",
        "        return {}\n",
        "\n",
        "    if debug:\n",
        "        print(f\"Parsing article {article_title}.\")\n",
        "    \n",
        "    doc = nlp(article_text)\n",
        "\n",
        "    word_count = 0\n",
        "    for token in doc:\n",
        "        if token.text not in punctuation:\n",
        "            word_count += 1\n",
        "\n",
        "    if debug:\n",
        "        print(f\"{article_title} has {word_count} words.\")\n",
        "\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ == 'MISC':\n",
        "            continue\n",
        "        formatted_entity = ent.text + \"___\" + ent.label_\n",
        "        if formatted_entity not in all_entities:\n",
        "            all_entities[formatted_entity] = 1 \n",
        "        else:\n",
        "            all_entities[formatted_entity] += 1\n",
        "\n",
        "    if debug:\n",
        "        print(f\"{article_title} mentions {len(all_entities)} unique entities.\")\n",
        "        print(f\"{article_title} includes {sum(list(all_entities.values()))} entity mentions\")\n",
        "\n",
        "    target_entities = {}\n",
        "\n",
        "    # look through our target entity mapping\n",
        "    # which connects an english entity to the languages its translated into and that form\n",
        "    for target_entity_english, translated_info in target_entities_multiling.items():\n",
        "        # for all the language / entity combos\n",
        "        for code, translated_entity in translated_info.items():\n",
        "            # get the data for the one we care about\n",
        "            if code == lang:\n",
        "                # for every entity that spacy tagged\n",
        "                for e in all_entities:\n",
        "                    # pull out the plain text form\n",
        "                    doc_entity = e.split(\"___\")[0]\n",
        "                    # if either the translated version (of lang <lang>) is in our target set\n",
        "                    # or the english version is in our target set \n",
        "                    # record that this article contains that target entity\n",
        "                    if translated_entity == doc_entity or target_entity_english == doc_entity:\n",
        "                        target_entities[target_entity_english] = all_entities[e]\n",
        "                    \n",
        "    if debug:\n",
        "        print(f\"{article_title} mentions {len(target_entities)} target entities.\")\n",
        "        print(f\"{article_title} includes {sum(list(target_entities.values()))} target entity mentions.\")\n",
        "\n",
        "    return word_count, all_entities, target_entities"
      ],
      "metadata": {
        "id": "YgklfbdItejH"
      },
      "id": "YgklfbdItejH",
      "execution_count": 272,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 273,
      "id": "59dcede6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59dcede6",
        "outputId": "b4d39b9c-ebc4-47d7-eb55-1a610a932603"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsing article Barack Obama.\n",
            "Barack Obama has 12853 words.\n",
            "Barack Obama mentions 1088 unique entities.\n",
            "Barack Obama includes 2018 entity mentions\n",
            "Barack Obama mentions 95 target entities.\n",
            "Barack Obama includes 236 target entity mentions.\n"
          ]
        }
      ],
      "source": [
        "obama_word_count, obama_article_entities, obama_target_entities = count_entities_in_article(target_entities_multiling, obama_info, spacy_models, 'en', debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 274,
      "id": "2d522b0e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d522b0e",
        "outputId": "9c3a6c19-140b-4213-d81a-e882adea7bf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iran 7\n",
            "Somalia 1\n",
            "USA 1\n",
            "Bill Clinton 6\n",
            "Israel 5\n",
            "France 1\n",
            "Russia 5\n",
            "Hawaii 9\n",
            "Cuba 6\n",
            "Benjamin Netanyahu 3\n"
          ]
        }
      ],
      "source": [
        "c = 0\n",
        "for k, v in obama_target_entities.items():\n",
        "    print(k, v)\n",
        "    c += 1\n",
        "    if c == 10:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aC3c9LAWOH0A"
      },
      "id": "aC3c9LAWOH0A",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}