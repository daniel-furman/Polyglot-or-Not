{"cells":[{"cell_type":"markdown","id":"656ef9cb","metadata":{},"source":["## Polyjuice: Generating Counterfactuals using Perturbations"]},{"cell_type":"markdown","id":"0771cef5","metadata":{},"source":["<a target=\"_blank\" href=\"https://colab.research.google.com/github/daniel-furman/Capstone/blob/main/notebooks/counterfact_generation_notebooks/polyjuice-exp.ipynb\">\n","  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n","</a>"]},{"cell_type":"code","execution_count":null,"id":"e1b7ed9a","metadata":{},"outputs":[],"source":["!git clone https://github.com/daniel-furman/C,sapstone.git\n","!pip install -e /content/Capstone/src/counterfact_generation_scripts"]},{"cell_type":"markdown","id":"1a64cd17","metadata":{"id":"1a64cd17"},"source":["# General setup and perturbation"]},{"cell_type":"code","execution_count":null,"id":"ITvzeAR_Q6AY","metadata":{"id":"ITvzeAR_Q6AY"},"outputs":[],"source":["if not torch.cuda.is_available():\n","    raise Exception(\"Change runtime type to include a GPU.\")"]},{"cell_type":"code","execution_count":null,"id":"5a8e1fd2","metadata":{"executionInfo":{"elapsed":33701,"status":"ok","timestamp":1679536918566,"user":{"displayName":"Shreshta Bhat Alevooru","userId":"06838044081666045825"},"user_tz":420},"id":"5a8e1fd2"},"outputs":[],"source":["# initiate a wrapper.\n","# model path is defaulted to our portable model:\n","# https://huggingface.co/uw-hai/polyjuice\n","# No need to change this unless you are using customized model\n","from polyjuice import Polyjuice\n","pj = Polyjuice(model_path=\"uw-hai/polyjuice\", is_cuda=torch.cuda.is_available())"]},{"cell_type":"code","execution_count":null,"id":"4c007e5b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10116,"status":"ok","timestamp":1679537236868,"user":{"displayName":"Shreshta Bhat Alevooru","userId":"06838044081666045825"},"user_tz":420},"id":"4c007e5b","outputId":"89118b39-4e52-440f-e039-1b898d4b526f"},"outputs":[],"source":["# the base sentence\n","text = \"Tom Brady plays football\"\n","\n","# perturb the sentence with one line:\n","# When running it for the first time, the wrapper will automatically\n","# load related models, e.g. the generator and the perplexity filter.\n","perturbations = pj.perturb(text, num_beams=50) # does not work without num_beams\n","perturbations #just gives perturbations, more random with decreasing number of beams"]},{"cell_type":"code","execution_count":null,"id":"d0e3e5b0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1582,"status":"ok","timestamp":1679537556287,"user":{"displayName":"Shreshta Bhat Alevooru","userId":"06838044081666045825"},"user_tz":420},"id":"d0e3e5b0","outputId":"2b11536b-69e8-4f83-f75a-b7dabef50b57"},"outputs":[],"source":["# To perturb with more controls\n","\n","perturbations = pj.perturb(\n","    orig_sent=text,\n","    # can specify where to put the blank. Otherwise, it's automatically selected.\n","    # Can be a list or a single sentence.\n","    blanked_sent=[\"Tom Brady plays [BLANK].\", \"[BLANK] plays football.\"],\n","    # can also specify the ctrl code (a list or a single code.)\n","    # The code should be from 'resemantic', 'restructure', 'negation', 'insert', 'lexical', 'shuffle', 'quantifier', 'delete'.\n","    ctrl_code=\"lexical\",\n","    # Customzie perplexity score. \n","    perplex_thred=20,\n","    # number of perturbations to return\n","    num_perturbations=3,\n","    # the function also takes in additional arguments for huggingface generators.\n","    num_beams=50\n",")\n","perturbations"]},{"cell_type":"code","execution_count":null,"id":"NUIq9HGzPWhi","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3426,"status":"ok","timestamp":1679537676020,"user":{"displayName":"Shreshta Bhat Alevooru","userId":"06838044081666045825"},"user_tz":420},"id":"NUIq9HGzPWhi","outputId":"1c3e4e6e-fc6e-4228-c06f-43221993a04d"},"outputs":[],"source":["# To perturb with more controls\n","text = \"Arab follows the religion of Muslim\"\n","perturbations = pj.perturb(\n","    orig_sent=text,\n","    # can specify where to put the blank. Otherwise, it's automatically selected.\n","    # Can be a list or a single sentence.\n","    blanked_sent=[\"Arab follows the religion of [BLANK].\", \"[BLANK] follows the religion of Muslim.\"],\n","    # can also specify the ctrl code (a list or a single code.)\n","    # The code should be from 'resemantic', 'restructure', 'negation', 'insert', 'lexical', 'shuffle', 'quantifier', 'delete'.\n","    ctrl_code=\"lexical\", #lexical for our use-case to generate more examples, can also use negation\n","    # Customzie perplexity score. \n","    perplex_thred=20,\n","    # number of perturbations to return\n","    num_perturbations=3, \n","    # the function also takes in additional arguments for huggingface generators.\n","    num_beams=50 #more random with decreasing number of beams\n",")\n","perturbations"]},{"cell_type":"markdown","id":"81bcc528","metadata":{"id":"81bcc528"},"source":["# Select for diversity\n","\n","Having each perturbation be represented by its token changes, control code, and dependency tree strcuture, we greedily select the ones that are least similar to those already selected. This tries to avoid redundancy in common perturbations such as black -> white.\n"]},{"cell_type":"code","execution_count":null,"id":"793f1239","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9423,"status":"ok","timestamp":1679537953007,"user":{"displayName":"Shreshta Bhat Alevooru","userId":"06838044081666045825"},"user_tz":420},"id":"793f1239","outputId":"c56da77a-2da7-4d86-f6dc-e4313cc514c8","scrolled":true},"outputs":[],"source":["# over-generate some examples, useful for our use-case to just get more examples in the neighbourhood\n","\n","orig_text = \"Arab is follower of Islam\"\n","perturb_texts = pj.perturb(\n","    orig_sent=orig_text, perplex_thred=10, num_perturbations=None, num_beams=10)\n","orig_and_perturb_pairs = [(orig_text, perturb_text) for perturb_text in perturb_texts]\n","orig_and_perturb_pairs"]},{"cell_type":"code","execution_count":null,"id":"85693442","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":249,"status":"ok","timestamp":1679537768583,"user":{"displayName":"Shreshta Bhat Alevooru","userId":"06838044081666045825"},"user_tz":420},"id":"85693442","outputId":"b919a539-61d7-4ce7-b75d-c162ff47fc10"},"outputs":[],"source":["sampled = pj.select_diverse_perturbations(\n","    orig_and_perturb_pairs=orig_and_perturb_pairs, nsamples=3)\n","sampled"]},{"cell_type":"markdown","id":"ca02b554","metadata":{"id":"ca02b554"},"source":["# Select surprising perturbations as counterfactual explanations - irrelevant/gives errors\n","\n","Because different models/explainers may have different forms of predictions/feature weight computation methods, Polyjuice selection expects all predictions and feature weights to be precomputed. Here, we give an example of Quora Question Pair Detection. \n"]},{"cell_type":"code","execution_count":null,"id":"64272c50","metadata":{"executionInfo":{"elapsed":149,"status":"ok","timestamp":1679537777644,"user":{"displayName":"Shreshta Bhat Alevooru","userId":"06838044081666045825"},"user_tz":420},"id":"64272c50"},"outputs":[],"source":["# set a perturbation base\n","orig = (\n","    \"How can I help a friend experiencing serious depression?\",\n","    \"How do I help a friend who is in depression?\"\n",")\n","orig_label = 1\n","\n","# we perturb the second question."]},{"cell_type":"code","execution_count":null,"id":"9c49bc50","metadata":{},"outputs":[],"source":["# get a model\n","from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n","import torch\n","model_name = \"textattack/bert-base-uncased-QQP\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForSequenceClassification.from_pretrained(model_name)\n","# sentiment analysis is a general name in Huggingface to load the pipeline for text classification tasks.\n","# set device=-1 if you don't have a gpu\n","pipe = pipeline(\n","    \"sentiment-analysis\", model=model, tokenizer=tokenizer, \n","    framework=\"pt\", device=0 if is_cuda else -1, return_all_scores=True)"]},{"cell_type":"code","execution_count":null,"id":"88f9456e","metadata":{},"outputs":[],"source":["# some wrapper for prediction\n","import numpy as np\n","def extract_predict_label(raw_pred):\n","    raw_pred = sorted(raw_pred, key=lambda r: -r[\"score\"])\n","    if raw_pred:\n","        return raw_pred[0][\"label\"]\n","    return None\n","def predict(examples, predictor, batch_size=128):\n","    raw_preds, preds, distribution = [], [], []\n","    with torch.no_grad():\n","        for e in (range(0, len(examples), batch_size)):\n","            raw_preds.extend(predictor(examples[e:e+batch_size]))\n","    for raw_pred in raw_preds:\n","        raw_pred = raw_pred if type(raw_pred) == list else [raw_pred]\n","        for m in raw_pred:\n","            m[\"label\"] = int(m[\"label\"].split(\"_\")[1])\n","    return raw_preds\n","\n","p = predict([orig], predictor=pipe)[0]\n","(p, extract_predict_label(p))"]},{"cell_type":"code","execution_count":null,"id":"893571aa","metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1679536993165,"user":{"displayName":"Shreshta Bhat Alevooru","userId":"06838044081666045825"},"user_tz":420},"id":"893571aa","scrolled":true},"outputs":[],"source":["## collect some base perturbations\n","from polyjuice.generations import ALL_CTRL_CODES\n","\n","# perturb the second question in orig.\n","perturb_idx = 1\n","perturb_texts = pj.perturb(\n","    orig[perturb_idx], \n","    ctrl_code=ALL_CTRL_CODES, \n","    num_perturbations=None, perplex_thred=10)\n","\n","perturb_texts\n"]},{"cell_type":"code","execution_count":null,"id":"1ee1ab28","metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1679536993165,"user":{"displayName":"Shreshta Bhat Alevooru","userId":"06838044081666045825"},"user_tz":420},"id":"1ee1ab28"},"outputs":[],"source":["# To estimate feature importance, we set up shap explainer\n","# install shap\n","!pip install shap"]},{"cell_type":"code","execution_count":null,"id":"f71b6d05","metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1679536993165,"user":{"displayName":"Shreshta Bhat Alevooru","userId":"06838044081666045825"},"user_tz":420},"id":"f71b6d05"},"outputs":[],"source":["import shap\n","import functools\n","from copy import deepcopy\n","# setup a prediction function for computing the shap feature importance\n","\n","def wrap_perturbed_instances(perturb_texts, orig, perturb_idx=1):\n","    perturbs = []\n","    for a in perturb_texts:\n","        curr_example = deepcopy(list(orig))\n","        curr_example[perturb_idx] = a\n","        perturbs.append(tuple(curr_example))\n","    return perturbs\n","\n","def predict_on_perturbs(perturb_texts, orig, predictor, perturb_idx=1):\n","    perturbs = wrap_perturbed_instances(perturb_texts, orig, perturb_idx)\n","    perturbs_preds = predict(perturbs, predictor=predictor)\n","    perturbs_pred_dicts = [{p[\"label\"]: p[\"score\"] for p in perturbs_pred} for perturbs_pred in perturbs_preds]\n","    orig_preds = predict([orig], predictor=predictor)\n","    orig_pred = extract_predict_label(orig_preds[0])\n","    # the return is probability of the originally predicted label\n","    return [pr_dict[orig_pred] for pr_dict in perturbs_pred_dicts]\n","def normalize_shap_importance(features, importances, is_use_abs=True):\n","    normalized_features = {}\n","    for idx, (f, v) in enumerate(zip(features, importances)):\n","        f = f.strip('Ġ')\n","        if not f.startswith(\"##\"): \n","            key, val = \"\", 0\n","        key += f.replace(\"#\", \"\").strip()\n","        val += v\n","        if (idx == len(features)-1 or (not features[idx+1].startswith(\"##\"))) and key != \"\":\n","            normalized_features[key] = abs(val) if is_use_abs else val\n","    return normalized_features\n","def explain_with_shap(orig, predictor=pipe, tokenzier=pipe.tokenizer, perturb_idx=1):\n","    predict_for_shap_func = functools.partial(\n","        predict_on_perturbs, orig=orig, predictor=predictor, perturb_idx=perturb_idx)\n","    shap_explainer = shap.Explainer(predict_for_shap_func, tokenizer) \n","    exp = shap_explainer([str(orig[perturb_idx])])\n","    return normalize_shap_importance(exp.data[0], exp.values[0])\n","\n","feature_importance_dict = explain_with_shap(orig)\n","feature_importance_dict"]},{"cell_type":"code","execution_count":null,"id":"569debb3","metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1679536993165,"user":{"displayName":"Shreshta Bhat Alevooru","userId":"06838044081666045825"},"user_tz":420},"id":"569debb3"},"outputs":[],"source":["# get the predictions for original and also new instances\n","orig_pred = predict([orig], predictor=pipe)[0]\n","\n","perturb_instances = wrap_perturbed_instances(perturb_texts, orig, perturb_idx)\n","perturb_preds = predict(perturb_instances, predictor=pipe)\n","\n","surprises = pj.select_surprise_explanations(\n","    orig_text=orig[perturb_idx], \n","    perturb_texts=perturb_texts, \n","    orig_pred=orig_pred, \n","    perturb_preds=perturb_preds, \n","    feature_importance_dict=feature_importance_dict)\n","surprises"]},{"cell_type":"code","execution_count":null,"id":"bc3215f1","metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1679536993166,"user":{"displayName":"Shreshta Bhat Alevooru","userId":"06838044081666045825"},"user_tz":420},"id":"bc3215f1"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["ca02b554"],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.8.2 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.2"},"vscode":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}}},"nbformat":4,"nbformat_minor":5}
